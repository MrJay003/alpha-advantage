{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc+vrAjHLqL6pbx7KMmnpU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrJay003/alpha-advantage/blob/lambda/alpha_avantage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNKVFVSXBy-m",
        "outputId": "a28ef895-5741-4a2a-9bea-a144b0c78088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting alpha_vantage\n",
            "  Downloading alpha_vantage-2.3.1-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from alpha_vantage) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->alpha_vantage) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->alpha_vantage) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->alpha_vantage) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->alpha_vantage) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->alpha_vantage) (3.4)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, alpha_vantage\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 alpha_vantage-2.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 yarl-1.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install alpha_vantage "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from alpha_vantage.timeseries import TimeSeries \n",
        "\n",
        "print(\"All libraries loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0ZlreMJtv_",
        "outputId": "cea79af1-dc6b-4d53-aec0-fe407a605c88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"alpha_vantage\": {\n",
        "        \"key\": \"7W5IQZO3II3V9J4U\", # you can use the demo API key for this project, but please make sure to get your own API key at https://www.alphavantage.co/support/#api-key\n",
        "        \"symbol\": \"tsla\",\n",
        "        \"outputsize\": \"full\",\n",
        "        \"key_adjusted_close\": \"5. adjusted close\",\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"window_size\": 20,\n",
        "        \"train_split_size\": 0.80,\n",
        "    }, \n",
        "    \"plots\": {\n",
        "        \"xticks_interval\": 90, # show a date every 90 days\n",
        "        \"color_actual\": \"#001f3f\",\n",
        "        \"color_train\": \"#3D9970\",\n",
        "        \"color_val\": \"#0074D9\",\n",
        "        \"color_pred_train\": \"#3D9970\",\n",
        "        \"color_pred_val\": \"#0074D9\",\n",
        "        \"color_pred_test\": \"#FF4136\",\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"input_size\": 1, # since we are only using 1 feature, close price\n",
        "        \"num_lstm_layers\": 128,\n",
        "        \"lstm_size\": 256,\n",
        "        \"dropout\": 0.2,\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"device\": \"cuda\", # \"cuda\" or \"cpu\"\n",
        "        \"batch_size\": 128,\n",
        "        \"num_epoch\": 10000,\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"scheduler_step_size\": 40,\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "DqY61uu_KgkQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(config):\n",
        "    ts = TimeSeries(key='7W5IQZO3II3V9J4U') #you can use the demo API key for this project, but please make sure to eventually get your own API key at https://www.alphavantage.co/support/#api-key. \n",
        "    data, meta_data = ts.get_daily_adjusted(config[\"alpha_vantage\"][\"symbol\"], outputsize=config[\"alpha_vantage\"][\"outputsize\"])\n",
        "\n",
        "    data_date = [date for date in data.keys()]\n",
        "    data_date.reverse()\n",
        "\n",
        "    data_close_price = [float(data[date][config[\"alpha_vantage\"][\"key_adjusted_close\"]]) for date in data.keys()]\n",
        "    data_close_price.reverse()\n",
        "    data_close_price = np.array(data_close_price)\n",
        "\n",
        "    num_data_points = len(data_date)\n",
        "    display_date_range = \"from \" + data_date[0] + \" to \" + data_date[num_data_points-1]\n",
        "    print(\"Number data points\", num_data_points, display_date_range)\n",
        "\n",
        "    return data_date, data_close_price, num_data_points, display_date_range\n",
        "\n",
        "data_date, data_close_price, num_data_points, display_date_range = download_data(config)\n",
        "\n",
        "# plot\n",
        "\n",
        "fig = figure(figsize=(25, 5), dpi=80)\n",
        "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "plt.plot(data_date, data_close_price, color=config[\"plots\"][\"color_actual\"])\n",
        "xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "x = np.arange(0,len(xticks))\n",
        "plt.xticks(x, xticks, rotation='vertical')\n",
        "plt.title(\"Daily close price for \" + config[\"alpha_vantage\"][\"symbol\"] + \", \" + display_date_range)\n",
        "plt.grid(True, which='major', axis='y', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "NZMxIDxQLT5f",
        "outputId": "8ffef5dd-7028-46ca-ee40-24bae9140390"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number data points 3227 from 2010-06-29 to 2023-04-24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Normalizer():\n",
        "    def __init__(self):\n",
        "        self.mu = None\n",
        "        self.sd = None\n",
        "\n",
        "    def fit_transform(self, x):\n",
        "        self.mu = np.mean(x, axis=(0), keepdims=True)\n",
        "        self.sd = np.std(x, axis=(0), keepdims=True)\n",
        "        normalized_x = (x - self.mu)/self.sd\n",
        "        return normalized_x\n",
        "\n",
        "    def inverse_transform(self, x):\n",
        "        return (x*self.sd) + self.mu\n",
        "\n",
        "# normalize\n",
        "scaler = Normalizer()\n",
        "normalized_data_close_price = scaler.fit_transform(data_close_price)"
      ],
      "metadata": {
        "id": "tatMZHWwMPsd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_x(x, window_size):\n",
        "    # perform windowing\n",
        "    n_row = x.shape[0] - window_size + 1\n",
        "    output = np.lib.stride_tricks.as_strided(x, shape=(n_row, window_size), strides=(x.strides[0], x.strides[0]))\n",
        "    return output[:-1], output[-1]\n",
        "\n",
        "\n",
        "def prepare_data_y(x, window_size):\n",
        "    # # perform simple moving average\n",
        "    # output = np.convolve(x, np.ones(window_size), 'valid') / window_size\n",
        "\n",
        "    # use the next day as label\n",
        "    output = x[window_size:]\n",
        "    return output\n",
        "\n",
        "data_x, data_x_unseen = prepare_data_x(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
        "data_y = prepare_data_y(normalized_data_close_price, window_size=config[\"data\"][\"window_size\"])\n",
        "\n",
        "# split dataset\n",
        "\n",
        "split_index = int(data_y.shape[0]*config[\"data\"][\"train_split_size\"])\n",
        "data_x_train = data_x[:split_index]\n",
        "data_x_val = data_x[split_index:]\n",
        "data_y_train = data_y[:split_index]\n",
        "data_y_val = data_y[split_index:]\n",
        "\n",
        "# prepare data for plotting\n",
        "\n",
        "to_plot_data_y_train = np.zeros(num_data_points)\n",
        "to_plot_data_y_val = np.zeros(num_data_points)\n",
        "\n",
        "to_plot_data_y_train[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(data_y_train)\n",
        "to_plot_data_y_val[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(data_y_val)\n",
        "\n",
        "to_plot_data_y_train = np.where(to_plot_data_y_train == 0, None, to_plot_data_y_train)\n",
        "to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
        "\n",
        "## plots\n",
        "\n",
        "fig = figure(figsize=(25, 5), dpi=80)\n",
        "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "plt.plot(data_date, to_plot_data_y_train, label=\"Prices (train)\", color=config[\"plots\"][\"color_train\"])\n",
        "plt.plot(data_date, to_plot_data_y_val, label=\"Prices (validation)\", color=config[\"plots\"][\"color_val\"])\n",
        "xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "x = np.arange(0,len(xticks))\n",
        "plt.xticks(x, xticks, rotation='vertical')\n",
        "plt.title(\"Daily close prices for \" + config[\"alpha_vantage\"][\"symbol\"] + \" - showing training and validation data\")\n",
        "plt.grid(True, which='major', axis='y', linestyle='--')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "mJG2sOBrP-Us",
        "outputId": "10c7212b-6ff0-4995-e8f5-4b7e90781ecc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        x = np.expand_dims(x, 2) # in our case, we have only 1 feature, so we need to convert `x` into [batch, sequence, features] for LSTM\n",
        "        self.x = x.astype(np.float32)\n",
        "        self.y = y.astype(np.float32)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.x[idx], self.y[idx])\n",
        "\n",
        "dataset_train = TimeSeriesDataset(data_x_train, data_y_train)\n",
        "dataset_val = TimeSeriesDataset(data_x_val, data_y_val)\n",
        "\n",
        "print(\"Train data shape\", dataset_train.x.shape, dataset_train.y.shape)\n",
        "print(\"Validation data shape\", dataset_val.x.shape, dataset_val.y.shape)\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtQEqpDtQiD7",
        "outputId": "a1e05c59-7604-42b2-9d54-9e1ea48f26cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape (2565, 20, 1) (2565,)\n",
            "Validation data shape (642, 20, 1) (642,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=32, num_layers=2, output_size=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lstm = nn.LSTM(hidden_layer_size, hidden_size=self.hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(num_layers*hidden_layer_size, output_size)\n",
        "        \n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                 nn.init.constant_(param, 0.0)\n",
        "            elif 'weight_ih' in name:\n",
        "                 nn.init.kaiming_normal_(param)\n",
        "            elif 'weight_hh' in name:\n",
        "                 nn.init.orthogonal_(param)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "\n",
        "        # layer 1\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        # LSTM layer\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "        # reshape output from hidden cell into [batch, features] for `linear_2`\n",
        "        x = h_n.permute(1, 0, 2).reshape(batchsize, -1) \n",
        "        \n",
        "        # layer 2\n",
        "        x = self.dropout(x)\n",
        "        predictions = self.linear_2(x)\n",
        "        return predictions[:,-1]"
      ],
      "metadata": {
        "id": "KU_omPkbQ8rR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(dataloader, is_training=False):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    if is_training:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    for idx, (x, y) in enumerate(dataloader):\n",
        "        if is_training:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        batchsize = x.shape[0]\n",
        "\n",
        "        x = x.to(config[\"training\"][\"device\"])\n",
        "        y = y.to(config[\"training\"][\"device\"])\n",
        "\n",
        "        out = model(x)\n",
        "        loss = criterion(out.contiguous(), y.contiguous())\n",
        "\n",
        "        if is_training:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        epoch_loss += (loss.detach().item() / batchsize)\n",
        "\n",
        "    lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "    return epoch_loss, lr\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
        "\n",
        "model = LSTMModel(input_size=config[\"model\"][\"input_size\"], hidden_layer_size=config[\"model\"][\"lstm_size\"], num_layers=config[\"model\"][\"num_lstm_layers\"], output_size=1, dropout=config[\"model\"][\"dropout\"])\n",
        "model = model.to(config[\"training\"][\"device\"])\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=(0.9, 0.98), eps=1e-9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"training\"][\"scheduler_step_size\"], gamma=0.1)\n",
        "\n",
        "for epoch in range(config[\"training\"][\"num_epoch\"]):\n",
        "    loss_train, lr_train = run_epoch(train_dataloader, is_training=True)\n",
        "    loss_val, lr_val = run_epoch(val_dataloader)\n",
        "    scheduler.step()\n",
        "    \n",
        "    print('Epoch[{}/{}] | loss train:{:.6f}, test:{:.6f} | lr:{:.6f}'\n",
        "              .format(epoch+1, config[\"training\"][\"num_epoch\"], loss_train, loss_val, lr_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqoev_rVRHiv",
        "outputId": "09743f52-9f75-46ca-ff7d-54face10eb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch[4959/10000] | loss train:1.754703, test:1.462709 | lr:0.000000\n",
            "Epoch[4960/10000] | loss train:0.805076, test:0.573650 | lr:0.000000\n",
            "Epoch[4961/10000] | loss train:0.883747, test:0.262257 | lr:0.000000\n",
            "Epoch[4962/10000] | loss train:0.913098, test:0.414000 | lr:0.000000\n",
            "Epoch[4963/10000] | loss train:0.764843, test:0.110821 | lr:0.000000\n",
            "Epoch[4964/10000] | loss train:1.978156, test:0.186649 | lr:0.000000\n",
            "Epoch[4965/10000] | loss train:1.497165, test:1.070779 | lr:0.000000\n",
            "Epoch[4966/10000] | loss train:0.808645, test:0.777471 | lr:0.000000\n",
            "Epoch[4967/10000] | loss train:0.982059, test:1.437405 | lr:0.000000\n",
            "Epoch[4968/10000] | loss train:0.861188, test:0.057167 | lr:0.000000\n",
            "Epoch[4969/10000] | loss train:1.255635, test:1.190493 | lr:0.000000\n",
            "Epoch[4970/10000] | loss train:1.400556, test:0.673583 | lr:0.000000\n",
            "Epoch[4971/10000] | loss train:1.185469, test:0.733434 | lr:0.000000\n",
            "Epoch[4972/10000] | loss train:0.691843, test:0.326332 | lr:0.000000\n",
            "Epoch[4973/10000] | loss train:0.851284, test:0.214601 | lr:0.000000\n",
            "Epoch[4974/10000] | loss train:0.689407, test:0.563746 | lr:0.000000\n",
            "Epoch[4975/10000] | loss train:0.729754, test:0.686938 | lr:0.000000\n",
            "Epoch[4976/10000] | loss train:0.943147, test:0.235193 | lr:0.000000\n",
            "Epoch[4977/10000] | loss train:1.263208, test:0.104968 | lr:0.000000\n",
            "Epoch[4978/10000] | loss train:1.185823, test:1.249819 | lr:0.000000\n",
            "Epoch[4979/10000] | loss train:1.440251, test:0.295758 | lr:0.000000\n",
            "Epoch[4980/10000] | loss train:0.856070, test:1.564594 | lr:0.000000\n",
            "Epoch[4981/10000] | loss train:0.893701, test:0.195346 | lr:0.000000\n",
            "Epoch[4982/10000] | loss train:1.286096, test:0.617809 | lr:0.000000\n",
            "Epoch[4983/10000] | loss train:2.467295, test:0.134298 | lr:0.000000\n",
            "Epoch[4984/10000] | loss train:0.638412, test:0.640950 | lr:0.000000\n",
            "Epoch[4985/10000] | loss train:1.127089, test:1.742696 | lr:0.000000\n",
            "Epoch[4986/10000] | loss train:0.707677, test:0.523554 | lr:0.000000\n",
            "Epoch[4987/10000] | loss train:1.070396, test:1.324100 | lr:0.000000\n",
            "Epoch[4988/10000] | loss train:0.932818, test:0.168141 | lr:0.000000\n",
            "Epoch[4989/10000] | loss train:0.899058, test:0.461299 | lr:0.000000\n",
            "Epoch[4990/10000] | loss train:1.508147, test:0.142265 | lr:0.000000\n",
            "Epoch[4991/10000] | loss train:1.146691, test:0.858662 | lr:0.000000\n",
            "Epoch[4992/10000] | loss train:1.110386, test:0.467884 | lr:0.000000\n",
            "Epoch[4993/10000] | loss train:1.639653, test:0.232509 | lr:0.000000\n",
            "Epoch[4994/10000] | loss train:1.394428, test:1.285579 | lr:0.000000\n",
            "Epoch[4995/10000] | loss train:1.032801, test:0.407250 | lr:0.000000\n",
            "Epoch[4996/10000] | loss train:0.781588, test:0.418085 | lr:0.000000\n",
            "Epoch[4997/10000] | loss train:1.423251, test:0.866181 | lr:0.000000\n",
            "Epoch[4998/10000] | loss train:1.522408, test:0.460886 | lr:0.000000\n",
            "Epoch[4999/10000] | loss train:1.752719, test:0.676791 | lr:0.000000\n",
            "Epoch[5000/10000] | loss train:1.292778, test:1.040400 | lr:0.000000\n",
            "Epoch[5001/10000] | loss train:1.221834, test:0.335139 | lr:0.000000\n",
            "Epoch[5002/10000] | loss train:0.988248, test:0.383936 | lr:0.000000\n",
            "Epoch[5003/10000] | loss train:2.106968, test:0.395994 | lr:0.000000\n",
            "Epoch[5004/10000] | loss train:2.028896, test:0.641302 | lr:0.000000\n",
            "Epoch[5005/10000] | loss train:1.983718, test:0.153961 | lr:0.000000\n",
            "Epoch[5006/10000] | loss train:1.617324, test:0.287798 | lr:0.000000\n",
            "Epoch[5007/10000] | loss train:1.149473, test:0.490164 | lr:0.000000\n",
            "Epoch[5008/10000] | loss train:1.300709, test:0.405824 | lr:0.000000\n",
            "Epoch[5009/10000] | loss train:0.781284, test:0.875092 | lr:0.000000\n",
            "Epoch[5010/10000] | loss train:0.899987, test:0.202483 | lr:0.000000\n",
            "Epoch[5011/10000] | loss train:1.060029, test:1.137196 | lr:0.000000\n",
            "Epoch[5012/10000] | loss train:1.457546, test:0.663224 | lr:0.000000\n",
            "Epoch[5013/10000] | loss train:1.129351, test:0.633595 | lr:0.000000\n",
            "Epoch[5014/10000] | loss train:1.886622, test:0.847292 | lr:0.000000\n",
            "Epoch[5015/10000] | loss train:1.304549, test:0.676405 | lr:0.000000\n",
            "Epoch[5016/10000] | loss train:0.872700, test:0.381572 | lr:0.000000\n",
            "Epoch[5017/10000] | loss train:0.889466, test:0.131479 | lr:0.000000\n",
            "Epoch[5018/10000] | loss train:1.251356, test:0.623721 | lr:0.000000\n",
            "Epoch[5019/10000] | loss train:2.905946, test:0.185061 | lr:0.000000\n",
            "Epoch[5020/10000] | loss train:1.053235, test:0.330818 | lr:0.000000\n",
            "Epoch[5021/10000] | loss train:0.857986, test:0.316940 | lr:0.000000\n",
            "Epoch[5022/10000] | loss train:1.872563, test:0.318036 | lr:0.000000\n",
            "Epoch[5023/10000] | loss train:1.587174, test:0.446031 | lr:0.000000\n",
            "Epoch[5024/10000] | loss train:0.974069, test:0.565176 | lr:0.000000\n",
            "Epoch[5025/10000] | loss train:0.857342, test:0.466165 | lr:0.000000\n",
            "Epoch[5026/10000] | loss train:1.118112, test:0.679163 | lr:0.000000\n",
            "Epoch[5027/10000] | loss train:1.218274, test:0.173584 | lr:0.000000\n",
            "Epoch[5028/10000] | loss train:0.904557, test:0.708047 | lr:0.000000\n",
            "Epoch[5029/10000] | loss train:1.934980, test:0.167466 | lr:0.000000\n",
            "Epoch[5030/10000] | loss train:0.777215, test:1.181843 | lr:0.000000\n",
            "Epoch[5031/10000] | loss train:1.231360, test:0.219962 | lr:0.000000\n",
            "Epoch[5032/10000] | loss train:1.463432, test:0.255257 | lr:0.000000\n",
            "Epoch[5033/10000] | loss train:0.964753, test:0.469388 | lr:0.000000\n",
            "Epoch[5034/10000] | loss train:0.935823, test:1.206974 | lr:0.000000\n",
            "Epoch[5035/10000] | loss train:0.828131, test:1.584396 | lr:0.000000\n",
            "Epoch[5036/10000] | loss train:0.728182, test:0.717481 | lr:0.000000\n",
            "Epoch[5037/10000] | loss train:1.022924, test:1.992080 | lr:0.000000\n",
            "Epoch[5038/10000] | loss train:1.287301, test:0.406751 | lr:0.000000\n",
            "Epoch[5039/10000] | loss train:1.595986, test:0.641212 | lr:0.000000\n",
            "Epoch[5040/10000] | loss train:1.491045, test:0.317739 | lr:0.000000\n",
            "Epoch[5041/10000] | loss train:0.765258, test:1.059333 | lr:0.000000\n",
            "Epoch[5042/10000] | loss train:1.289213, test:1.361188 | lr:0.000000\n",
            "Epoch[5043/10000] | loss train:1.837036, test:0.342956 | lr:0.000000\n",
            "Epoch[5044/10000] | loss train:0.687893, test:0.315906 | lr:0.000000\n",
            "Epoch[5045/10000] | loss train:1.113799, test:0.740690 | lr:0.000000\n",
            "Epoch[5046/10000] | loss train:0.955125, test:0.739938 | lr:0.000000\n",
            "Epoch[5047/10000] | loss train:1.550717, test:1.827702 | lr:0.000000\n",
            "Epoch[5048/10000] | loss train:2.931945, test:1.443113 | lr:0.000000\n",
            "Epoch[5049/10000] | loss train:0.625961, test:1.834278 | lr:0.000000\n",
            "Epoch[5050/10000] | loss train:2.553283, test:0.235136 | lr:0.000000\n",
            "Epoch[5051/10000] | loss train:1.780661, test:0.841490 | lr:0.000000\n",
            "Epoch[5052/10000] | loss train:0.642810, test:1.357254 | lr:0.000000\n",
            "Epoch[5053/10000] | loss train:1.389179, test:0.628912 | lr:0.000000\n",
            "Epoch[5054/10000] | loss train:1.892235, test:0.644885 | lr:0.000000\n",
            "Epoch[5055/10000] | loss train:1.489917, test:0.053376 | lr:0.000000\n",
            "Epoch[5056/10000] | loss train:0.860492, test:0.202711 | lr:0.000000\n",
            "Epoch[5057/10000] | loss train:1.574777, test:0.364705 | lr:0.000000\n",
            "Epoch[5058/10000] | loss train:1.071314, test:0.325993 | lr:0.000000\n",
            "Epoch[5059/10000] | loss train:1.321326, test:0.113426 | lr:0.000000\n",
            "Epoch[5060/10000] | loss train:1.143700, test:0.078411 | lr:0.000000\n",
            "Epoch[5061/10000] | loss train:0.733332, test:0.963908 | lr:0.000000\n",
            "Epoch[5062/10000] | loss train:1.750428, test:1.482943 | lr:0.000000\n",
            "Epoch[5063/10000] | loss train:2.231900, test:0.259690 | lr:0.000000\n",
            "Epoch[5064/10000] | loss train:1.103383, test:0.654856 | lr:0.000000\n",
            "Epoch[5065/10000] | loss train:0.670895, test:0.149796 | lr:0.000000\n",
            "Epoch[5066/10000] | loss train:1.052622, test:1.459555 | lr:0.000000\n",
            "Epoch[5067/10000] | loss train:0.813501, test:0.379558 | lr:0.000000\n",
            "Epoch[5068/10000] | loss train:1.083175, test:0.339346 | lr:0.000000\n",
            "Epoch[5069/10000] | loss train:0.742321, test:0.751651 | lr:0.000000\n",
            "Epoch[5070/10000] | loss train:0.941477, test:0.537237 | lr:0.000000\n",
            "Epoch[5071/10000] | loss train:0.582332, test:0.303293 | lr:0.000000\n",
            "Epoch[5072/10000] | loss train:1.745953, test:0.333959 | lr:0.000000\n",
            "Epoch[5073/10000] | loss train:1.545742, test:0.386113 | lr:0.000000\n",
            "Epoch[5074/10000] | loss train:1.669494, test:0.576745 | lr:0.000000\n",
            "Epoch[5075/10000] | loss train:1.412152, test:0.452971 | lr:0.000000\n",
            "Epoch[5076/10000] | loss train:1.645727, test:1.537268 | lr:0.000000\n",
            "Epoch[5077/10000] | loss train:0.995249, test:1.266956 | lr:0.000000\n",
            "Epoch[5078/10000] | loss train:0.729732, test:0.501873 | lr:0.000000\n",
            "Epoch[5079/10000] | loss train:1.209554, test:1.671046 | lr:0.000000\n",
            "Epoch[5080/10000] | loss train:1.519624, test:0.865547 | lr:0.000000\n",
            "Epoch[5081/10000] | loss train:1.850592, test:0.578539 | lr:0.000000\n",
            "Epoch[5082/10000] | loss train:1.111439, test:0.985539 | lr:0.000000\n",
            "Epoch[5083/10000] | loss train:2.931868, test:1.318456 | lr:0.000000\n",
            "Epoch[5084/10000] | loss train:0.784130, test:0.587300 | lr:0.000000\n",
            "Epoch[5085/10000] | loss train:1.541606, test:1.756996 | lr:0.000000\n",
            "Epoch[5086/10000] | loss train:1.798082, test:0.591018 | lr:0.000000\n",
            "Epoch[5087/10000] | loss train:0.831427, test:0.367823 | lr:0.000000\n",
            "Epoch[5088/10000] | loss train:0.937027, test:0.593749 | lr:0.000000\n",
            "Epoch[5089/10000] | loss train:1.614057, test:1.651553 | lr:0.000000\n",
            "Epoch[5090/10000] | loss train:0.939838, test:0.311298 | lr:0.000000\n",
            "Epoch[5091/10000] | loss train:1.185112, test:0.124568 | lr:0.000000\n",
            "Epoch[5092/10000] | loss train:1.597041, test:0.650074 | lr:0.000000\n",
            "Epoch[5093/10000] | loss train:2.309674, test:0.190904 | lr:0.000000\n",
            "Epoch[5094/10000] | loss train:1.732642, test:0.108134 | lr:0.000000\n",
            "Epoch[5095/10000] | loss train:1.420799, test:1.382191 | lr:0.000000\n",
            "Epoch[5096/10000] | loss train:0.967814, test:0.314942 | lr:0.000000\n",
            "Epoch[5097/10000] | loss train:1.194183, test:0.224914 | lr:0.000000\n",
            "Epoch[5098/10000] | loss train:1.167784, test:0.771107 | lr:0.000000\n",
            "Epoch[5099/10000] | loss train:1.387481, test:0.665970 | lr:0.000000\n",
            "Epoch[5100/10000] | loss train:0.946816, test:0.281499 | lr:0.000000\n",
            "Epoch[5101/10000] | loss train:0.716354, test:0.722080 | lr:0.000000\n",
            "Epoch[5102/10000] | loss train:2.357341, test:0.647480 | lr:0.000000\n",
            "Epoch[5103/10000] | loss train:1.263886, test:1.131596 | lr:0.000000\n",
            "Epoch[5104/10000] | loss train:1.675590, test:0.551547 | lr:0.000000\n",
            "Epoch[5105/10000] | loss train:1.163325, test:0.233662 | lr:0.000000\n",
            "Epoch[5106/10000] | loss train:1.867427, test:0.807456 | lr:0.000000\n",
            "Epoch[5107/10000] | loss train:1.402761, test:1.357020 | lr:0.000000\n",
            "Epoch[5108/10000] | loss train:1.079667, test:0.951625 | lr:0.000000\n",
            "Epoch[5109/10000] | loss train:1.575693, test:0.515858 | lr:0.000000\n",
            "Epoch[5110/10000] | loss train:1.035046, test:0.597062 | lr:0.000000\n",
            "Epoch[5111/10000] | loss train:1.383735, test:1.771148 | lr:0.000000\n",
            "Epoch[5112/10000] | loss train:1.339674, test:0.494748 | lr:0.000000\n",
            "Epoch[5113/10000] | loss train:0.886807, test:0.315986 | lr:0.000000\n",
            "Epoch[5114/10000] | loss train:2.282012, test:0.846849 | lr:0.000000\n",
            "Epoch[5115/10000] | loss train:0.963818, test:0.489087 | lr:0.000000\n",
            "Epoch[5116/10000] | loss train:1.280440, test:0.728585 | lr:0.000000\n",
            "Epoch[5117/10000] | loss train:1.647882, test:1.002556 | lr:0.000000\n",
            "Epoch[5118/10000] | loss train:1.204496, test:0.783466 | lr:0.000000\n",
            "Epoch[5119/10000] | loss train:1.129462, test:0.803258 | lr:0.000000\n",
            "Epoch[5120/10000] | loss train:0.900965, test:0.611051 | lr:0.000000\n",
            "Epoch[5121/10000] | loss train:0.911881, test:0.189032 | lr:0.000000\n",
            "Epoch[5122/10000] | loss train:1.571237, test:0.459251 | lr:0.000000\n",
            "Epoch[5123/10000] | loss train:0.755086, test:0.253734 | lr:0.000000\n",
            "Epoch[5124/10000] | loss train:1.699391, test:0.539021 | lr:0.000000\n",
            "Epoch[5125/10000] | loss train:1.247427, test:1.264478 | lr:0.000000\n",
            "Epoch[5126/10000] | loss train:1.987826, test:0.964975 | lr:0.000000\n",
            "Epoch[5127/10000] | loss train:1.068720, test:0.794100 | lr:0.000000\n",
            "Epoch[5128/10000] | loss train:0.673409, test:0.116719 | lr:0.000000\n",
            "Epoch[5129/10000] | loss train:0.890758, test:0.671925 | lr:0.000000\n",
            "Epoch[5130/10000] | loss train:1.455547, test:1.237558 | lr:0.000000\n",
            "Epoch[5131/10000] | loss train:0.856567, test:0.410899 | lr:0.000000\n",
            "Epoch[5132/10000] | loss train:0.998419, test:0.329226 | lr:0.000000\n",
            "Epoch[5133/10000] | loss train:1.944871, test:0.732971 | lr:0.000000\n",
            "Epoch[5134/10000] | loss train:0.917341, test:0.050656 | lr:0.000000\n",
            "Epoch[5135/10000] | loss train:1.366487, test:0.791443 | lr:0.000000\n",
            "Epoch[5136/10000] | loss train:1.816971, test:0.927347 | lr:0.000000\n",
            "Epoch[5137/10000] | loss train:0.828602, test:0.575768 | lr:0.000000\n",
            "Epoch[5138/10000] | loss train:1.067165, test:0.249017 | lr:0.000000\n",
            "Epoch[5139/10000] | loss train:1.831339, test:1.123566 | lr:0.000000\n",
            "Epoch[5140/10000] | loss train:1.834559, test:1.640741 | lr:0.000000\n",
            "Epoch[5141/10000] | loss train:0.728912, test:0.436624 | lr:0.000000\n",
            "Epoch[5142/10000] | loss train:0.859649, test:0.285686 | lr:0.000000\n",
            "Epoch[5143/10000] | loss train:1.056885, test:0.135215 | lr:0.000000\n",
            "Epoch[5144/10000] | loss train:1.386333, test:1.152727 | lr:0.000000\n",
            "Epoch[5145/10000] | loss train:1.086403, test:0.162757 | lr:0.000000\n",
            "Epoch[5146/10000] | loss train:0.911391, test:0.744618 | lr:0.000000\n",
            "Epoch[5147/10000] | loss train:1.436318, test:0.258556 | lr:0.000000\n",
            "Epoch[5148/10000] | loss train:1.870847, test:0.344470 | lr:0.000000\n",
            "Epoch[5149/10000] | loss train:1.922897, test:0.323570 | lr:0.000000\n",
            "Epoch[5150/10000] | loss train:1.669454, test:0.392173 | lr:0.000000\n",
            "Epoch[5151/10000] | loss train:1.854623, test:1.902389 | lr:0.000000\n",
            "Epoch[5152/10000] | loss train:1.177789, test:0.658488 | lr:0.000000\n",
            "Epoch[5153/10000] | loss train:0.744997, test:1.137399 | lr:0.000000\n",
            "Epoch[5154/10000] | loss train:1.604239, test:0.364048 | lr:0.000000\n",
            "Epoch[5155/10000] | loss train:1.192891, test:1.661139 | lr:0.000000\n",
            "Epoch[5156/10000] | loss train:1.374463, test:1.272675 | lr:0.000000\n",
            "Epoch[5157/10000] | loss train:0.946030, test:1.004640 | lr:0.000000\n",
            "Epoch[5158/10000] | loss train:0.903893, test:0.533921 | lr:0.000000\n",
            "Epoch[5159/10000] | loss train:1.210884, test:1.482516 | lr:0.000000\n",
            "Epoch[5160/10000] | loss train:0.907824, test:0.984682 | lr:0.000000\n",
            "Epoch[5161/10000] | loss train:1.441780, test:0.598742 | lr:0.000000\n",
            "Epoch[5162/10000] | loss train:0.935585, test:0.193870 | lr:0.000000\n",
            "Epoch[5163/10000] | loss train:2.863866, test:0.790233 | lr:0.000000\n",
            "Epoch[5164/10000] | loss train:1.435845, test:1.182003 | lr:0.000000\n",
            "Epoch[5165/10000] | loss train:1.232003, test:0.538432 | lr:0.000000\n",
            "Epoch[5166/10000] | loss train:1.552082, test:0.293554 | lr:0.000000\n",
            "Epoch[5167/10000] | loss train:0.884903, test:0.192421 | lr:0.000000\n",
            "Epoch[5168/10000] | loss train:0.749582, test:1.066730 | lr:0.000000\n",
            "Epoch[5169/10000] | loss train:2.073203, test:0.693042 | lr:0.000000\n",
            "Epoch[5170/10000] | loss train:0.992806, test:0.630496 | lr:0.000000\n",
            "Epoch[5171/10000] | loss train:1.492613, test:1.161779 | lr:0.000000\n",
            "Epoch[5172/10000] | loss train:2.514625, test:0.049847 | lr:0.000000\n",
            "Epoch[5173/10000] | loss train:1.076547, test:0.676009 | lr:0.000000\n",
            "Epoch[5174/10000] | loss train:1.318436, test:0.436775 | lr:0.000000\n",
            "Epoch[5175/10000] | loss train:1.162009, test:0.357720 | lr:0.000000\n",
            "Epoch[5176/10000] | loss train:1.886670, test:0.198022 | lr:0.000000\n",
            "Epoch[5177/10000] | loss train:0.970928, test:0.137171 | lr:0.000000\n",
            "Epoch[5178/10000] | loss train:1.409110, test:0.174044 | lr:0.000000\n",
            "Epoch[5179/10000] | loss train:0.831135, test:1.732287 | lr:0.000000\n",
            "Epoch[5180/10000] | loss train:0.882426, test:0.961805 | lr:0.000000\n",
            "Epoch[5181/10000] | loss train:1.123491, test:1.599839 | lr:0.000000\n",
            "Epoch[5182/10000] | loss train:1.006272, test:0.490675 | lr:0.000000\n",
            "Epoch[5183/10000] | loss train:2.220693, test:1.005628 | lr:0.000000\n",
            "Epoch[5184/10000] | loss train:1.410914, test:0.884209 | lr:0.000000\n",
            "Epoch[5185/10000] | loss train:0.967263, test:0.341003 | lr:0.000000\n",
            "Epoch[5186/10000] | loss train:1.139502, test:0.499923 | lr:0.000000\n",
            "Epoch[5187/10000] | loss train:0.993245, test:0.556980 | lr:0.000000\n",
            "Epoch[5188/10000] | loss train:0.673461, test:1.650998 | lr:0.000000\n",
            "Epoch[5189/10000] | loss train:0.923487, test:0.049712 | lr:0.000000\n",
            "Epoch[5190/10000] | loss train:1.282938, test:1.128643 | lr:0.000000\n",
            "Epoch[5191/10000] | loss train:1.064391, test:0.376362 | lr:0.000000\n",
            "Epoch[5192/10000] | loss train:1.253551, test:0.895339 | lr:0.000000\n",
            "Epoch[5193/10000] | loss train:2.954632, test:0.322484 | lr:0.000000\n",
            "Epoch[5194/10000] | loss train:1.596057, test:1.167144 | lr:0.000000\n",
            "Epoch[5195/10000] | loss train:1.189033, test:1.745378 | lr:0.000000\n",
            "Epoch[5196/10000] | loss train:0.981087, test:0.535425 | lr:0.000000\n",
            "Epoch[5197/10000] | loss train:1.631142, test:0.257312 | lr:0.000000\n",
            "Epoch[5198/10000] | loss train:1.536828, test:1.420264 | lr:0.000000\n",
            "Epoch[5199/10000] | loss train:1.599079, test:0.743348 | lr:0.000000\n",
            "Epoch[5200/10000] | loss train:0.991583, test:0.293121 | lr:0.000000\n",
            "Epoch[5201/10000] | loss train:1.257244, test:0.534845 | lr:0.000000\n",
            "Epoch[5202/10000] | loss train:1.178554, test:1.404633 | lr:0.000000\n",
            "Epoch[5203/10000] | loss train:0.748271, test:1.020226 | lr:0.000000\n",
            "Epoch[5204/10000] | loss train:1.383519, test:0.055900 | lr:0.000000\n",
            "Epoch[5205/10000] | loss train:0.877431, test:0.367743 | lr:0.000000\n",
            "Epoch[5206/10000] | loss train:0.942246, test:0.877274 | lr:0.000000\n",
            "Epoch[5207/10000] | loss train:0.704667, test:1.393172 | lr:0.000000\n",
            "Epoch[5208/10000] | loss train:1.581649, test:0.676973 | lr:0.000000\n",
            "Epoch[5209/10000] | loss train:2.045013, test:0.197178 | lr:0.000000\n",
            "Epoch[5210/10000] | loss train:0.836662, test:1.940415 | lr:0.000000\n",
            "Epoch[5211/10000] | loss train:1.515641, test:0.154077 | lr:0.000000\n",
            "Epoch[5212/10000] | loss train:1.355206, test:1.303040 | lr:0.000000\n",
            "Epoch[5213/10000] | loss train:1.597697, test:0.536426 | lr:0.000000\n",
            "Epoch[5214/10000] | loss train:1.580991, test:0.808459 | lr:0.000000\n",
            "Epoch[5215/10000] | loss train:1.102262, test:0.676732 | lr:0.000000\n",
            "Epoch[5216/10000] | loss train:1.034925, test:0.631372 | lr:0.000000\n",
            "Epoch[5217/10000] | loss train:1.837745, test:0.302037 | lr:0.000000\n",
            "Epoch[5218/10000] | loss train:0.676717, test:0.116790 | lr:0.000000\n",
            "Epoch[5219/10000] | loss train:1.116649, test:0.590285 | lr:0.000000\n",
            "Epoch[5220/10000] | loss train:1.169661, test:0.104136 | lr:0.000000\n",
            "Epoch[5221/10000] | loss train:1.578895, test:0.950765 | lr:0.000000\n",
            "Epoch[5222/10000] | loss train:0.980120, test:1.882615 | lr:0.000000\n",
            "Epoch[5223/10000] | loss train:1.409939, test:1.068225 | lr:0.000000\n",
            "Epoch[5224/10000] | loss train:1.124813, test:0.481809 | lr:0.000000\n",
            "Epoch[5225/10000] | loss train:0.972819, test:0.651007 | lr:0.000000\n",
            "Epoch[5226/10000] | loss train:0.934723, test:0.382621 | lr:0.000000\n",
            "Epoch[5227/10000] | loss train:1.009267, test:0.283139 | lr:0.000000\n",
            "Epoch[5228/10000] | loss train:1.481642, test:0.662321 | lr:0.000000\n",
            "Epoch[5229/10000] | loss train:0.941628, test:0.213223 | lr:0.000000\n",
            "Epoch[5230/10000] | loss train:0.860014, test:1.958953 | lr:0.000000\n",
            "Epoch[5231/10000] | loss train:1.971261, test:1.348094 | lr:0.000000\n",
            "Epoch[5232/10000] | loss train:1.047475, test:1.189733 | lr:0.000000\n",
            "Epoch[5233/10000] | loss train:1.190814, test:1.256481 | lr:0.000000\n",
            "Epoch[5234/10000] | loss train:1.019160, test:0.856987 | lr:0.000000\n",
            "Epoch[5235/10000] | loss train:1.382344, test:1.190568 | lr:0.000000\n",
            "Epoch[5236/10000] | loss train:1.059926, test:0.797311 | lr:0.000000\n",
            "Epoch[5237/10000] | loss train:1.417938, test:0.267092 | lr:0.000000\n",
            "Epoch[5238/10000] | loss train:1.774879, test:1.423350 | lr:0.000000\n",
            "Epoch[5239/10000] | loss train:1.444916, test:1.285178 | lr:0.000000\n",
            "Epoch[5240/10000] | loss train:0.995428, test:0.298783 | lr:0.000000\n",
            "Epoch[5241/10000] | loss train:1.481980, test:0.574767 | lr:0.000000\n",
            "Epoch[5242/10000] | loss train:1.312215, test:0.190045 | lr:0.000000\n",
            "Epoch[5243/10000] | loss train:1.891925, test:0.376677 | lr:0.000000\n",
            "Epoch[5244/10000] | loss train:2.146809, test:0.247915 | lr:0.000000\n",
            "Epoch[5245/10000] | loss train:0.919943, test:1.333354 | lr:0.000000\n",
            "Epoch[5246/10000] | loss train:0.847214, test:0.233277 | lr:0.000000\n",
            "Epoch[5247/10000] | loss train:1.386004, test:0.255113 | lr:0.000000\n",
            "Epoch[5248/10000] | loss train:1.613994, test:0.195939 | lr:0.000000\n",
            "Epoch[5249/10000] | loss train:1.571130, test:0.504571 | lr:0.000000\n",
            "Epoch[5250/10000] | loss train:1.646343, test:0.253614 | lr:0.000000\n",
            "Epoch[5251/10000] | loss train:1.384929, test:1.110356 | lr:0.000000\n",
            "Epoch[5252/10000] | loss train:1.229002, test:0.823269 | lr:0.000000\n",
            "Epoch[5253/10000] | loss train:0.753118, test:1.339373 | lr:0.000000\n",
            "Epoch[5254/10000] | loss train:0.992729, test:0.231776 | lr:0.000000\n",
            "Epoch[5255/10000] | loss train:1.311690, test:1.336424 | lr:0.000000\n",
            "Epoch[5256/10000] | loss train:0.866084, test:0.272531 | lr:0.000000\n",
            "Epoch[5257/10000] | loss train:1.155362, test:1.463584 | lr:0.000000\n",
            "Epoch[5258/10000] | loss train:1.584438, test:0.542432 | lr:0.000000\n",
            "Epoch[5259/10000] | loss train:1.276404, test:0.333323 | lr:0.000000\n",
            "Epoch[5260/10000] | loss train:0.945761, test:0.533477 | lr:0.000000\n",
            "Epoch[5261/10000] | loss train:1.552919, test:0.695556 | lr:0.000000\n",
            "Epoch[5262/10000] | loss train:1.825444, test:0.952998 | lr:0.000000\n",
            "Epoch[5263/10000] | loss train:1.833395, test:0.751651 | lr:0.000000\n",
            "Epoch[5264/10000] | loss train:2.089755, test:0.433818 | lr:0.000000\n",
            "Epoch[5265/10000] | loss train:3.197465, test:0.158476 | lr:0.000000\n",
            "Epoch[5266/10000] | loss train:1.967458, test:0.175213 | lr:0.000000\n",
            "Epoch[5267/10000] | loss train:1.291105, test:0.177556 | lr:0.000000\n",
            "Epoch[5268/10000] | loss train:1.148176, test:1.244381 | lr:0.000000\n",
            "Epoch[5269/10000] | loss train:1.793977, test:0.315510 | lr:0.000000\n",
            "Epoch[5270/10000] | loss train:1.314818, test:0.190045 | lr:0.000000\n",
            "Epoch[5271/10000] | loss train:0.925690, test:0.663659 | lr:0.000000\n",
            "Epoch[5272/10000] | loss train:1.422676, test:0.310669 | lr:0.000000\n",
            "Epoch[5273/10000] | loss train:1.297318, test:0.494355 | lr:0.000000\n",
            "Epoch[5274/10000] | loss train:1.054264, test:0.627128 | lr:0.000000\n",
            "Epoch[5275/10000] | loss train:1.120500, test:0.671271 | lr:0.000000\n",
            "Epoch[5276/10000] | loss train:0.692642, test:0.311042 | lr:0.000000\n",
            "Epoch[5277/10000] | loss train:1.306198, test:0.233940 | lr:0.000000\n",
            "Epoch[5278/10000] | loss train:1.201786, test:1.074435 | lr:0.000000\n",
            "Epoch[5279/10000] | loss train:1.721040, test:0.964795 | lr:0.000000\n",
            "Epoch[5280/10000] | loss train:2.078040, test:1.228605 | lr:0.000000\n",
            "Epoch[5281/10000] | loss train:1.822662, test:0.509167 | lr:0.000000\n",
            "Epoch[5282/10000] | loss train:1.145906, test:1.492019 | lr:0.000000\n",
            "Epoch[5283/10000] | loss train:1.653827, test:0.262315 | lr:0.000000\n",
            "Epoch[5284/10000] | loss train:0.987453, test:1.635192 | lr:0.000000\n",
            "Epoch[5285/10000] | loss train:1.550165, test:0.435624 | lr:0.000000\n",
            "Epoch[5286/10000] | loss train:1.060763, test:0.313822 | lr:0.000000\n",
            "Epoch[5287/10000] | loss train:1.485074, test:0.519824 | lr:0.000000\n",
            "Epoch[5288/10000] | loss train:1.351850, test:0.814964 | lr:0.000000\n",
            "Epoch[5289/10000] | loss train:1.174243, test:0.176878 | lr:0.000000\n",
            "Epoch[5290/10000] | loss train:0.976642, test:0.146970 | lr:0.000000\n",
            "Epoch[5291/10000] | loss train:1.927815, test:0.310470 | lr:0.000000\n",
            "Epoch[5292/10000] | loss train:0.995486, test:0.702419 | lr:0.000000\n",
            "Epoch[5293/10000] | loss train:0.662523, test:0.400123 | lr:0.000000\n",
            "Epoch[5294/10000] | loss train:2.386903, test:0.685135 | lr:0.000000\n",
            "Epoch[5295/10000] | loss train:1.115494, test:1.064584 | lr:0.000000\n",
            "Epoch[5296/10000] | loss train:1.332841, test:0.383598 | lr:0.000000\n",
            "Epoch[5297/10000] | loss train:0.952176, test:1.258372 | lr:0.000000\n",
            "Epoch[5298/10000] | loss train:1.225915, test:0.317696 | lr:0.000000\n",
            "Epoch[5299/10000] | loss train:1.819904, test:1.147732 | lr:0.000000\n",
            "Epoch[5300/10000] | loss train:0.682562, test:0.382983 | lr:0.000000\n",
            "Epoch[5301/10000] | loss train:1.029135, test:0.801609 | lr:0.000000\n",
            "Epoch[5302/10000] | loss train:1.510260, test:2.271779 | lr:0.000000\n",
            "Epoch[5303/10000] | loss train:1.321971, test:0.590870 | lr:0.000000\n",
            "Epoch[5304/10000] | loss train:1.131341, test:1.292619 | lr:0.000000\n",
            "Epoch[5305/10000] | loss train:0.838323, test:0.166232 | lr:0.000000\n",
            "Epoch[5306/10000] | loss train:1.219476, test:0.124177 | lr:0.000000\n",
            "Epoch[5307/10000] | loss train:1.145619, test:2.185545 | lr:0.000000\n",
            "Epoch[5308/10000] | loss train:3.462889, test:1.286902 | lr:0.000000\n",
            "Epoch[5309/10000] | loss train:1.337781, test:0.688995 | lr:0.000000\n",
            "Epoch[5310/10000] | loss train:0.876109, test:1.292422 | lr:0.000000\n",
            "Epoch[5311/10000] | loss train:0.808888, test:0.241978 | lr:0.000000\n",
            "Epoch[5312/10000] | loss train:0.655307, test:0.488608 | lr:0.000000\n",
            "Epoch[5313/10000] | loss train:2.407013, test:0.574753 | lr:0.000000\n",
            "Epoch[5314/10000] | loss train:1.184540, test:0.292470 | lr:0.000000\n",
            "Epoch[5315/10000] | loss train:1.375080, test:0.283680 | lr:0.000000\n",
            "Epoch[5316/10000] | loss train:1.346541, test:0.672483 | lr:0.000000\n",
            "Epoch[5317/10000] | loss train:0.932746, test:0.299423 | lr:0.000000\n",
            "Epoch[5318/10000] | loss train:0.786011, test:0.850893 | lr:0.000000\n",
            "Epoch[5319/10000] | loss train:2.121591, test:0.858467 | lr:0.000000\n",
            "Epoch[5320/10000] | loss train:1.065020, test:0.081898 | lr:0.000000\n",
            "Epoch[5321/10000] | loss train:1.187844, test:0.379293 | lr:0.000000\n",
            "Epoch[5322/10000] | loss train:1.218202, test:0.347672 | lr:0.000000\n",
            "Epoch[5323/10000] | loss train:1.457498, test:0.492282 | lr:0.000000\n",
            "Epoch[5324/10000] | loss train:0.663501, test:0.129385 | lr:0.000000\n",
            "Epoch[5325/10000] | loss train:0.706020, test:0.990537 | lr:0.000000\n",
            "Epoch[5326/10000] | loss train:1.352933, test:0.271320 | lr:0.000000\n",
            "Epoch[5327/10000] | loss train:0.810742, test:1.040688 | lr:0.000000\n",
            "Epoch[5328/10000] | loss train:0.983465, test:0.545154 | lr:0.000000\n",
            "Epoch[5329/10000] | loss train:1.134624, test:0.840249 | lr:0.000000\n",
            "Epoch[5330/10000] | loss train:0.876916, test:0.392584 | lr:0.000000\n",
            "Epoch[5331/10000] | loss train:1.079291, test:1.051348 | lr:0.000000\n",
            "Epoch[5332/10000] | loss train:1.286744, test:0.190845 | lr:0.000000\n",
            "Epoch[5333/10000] | loss train:1.687110, test:0.146397 | lr:0.000000\n",
            "Epoch[5334/10000] | loss train:1.926342, test:1.059592 | lr:0.000000\n",
            "Epoch[5335/10000] | loss train:1.190173, test:1.018522 | lr:0.000000\n",
            "Epoch[5336/10000] | loss train:0.707686, test:0.334778 | lr:0.000000\n",
            "Epoch[5337/10000] | loss train:0.724889, test:0.620094 | lr:0.000000\n",
            "Epoch[5338/10000] | loss train:1.769672, test:0.730625 | lr:0.000000\n",
            "Epoch[5339/10000] | loss train:1.975302, test:0.097018 | lr:0.000000\n",
            "Epoch[5340/10000] | loss train:1.472245, test:0.274781 | lr:0.000000\n",
            "Epoch[5341/10000] | loss train:0.774448, test:0.149748 | lr:0.000000\n",
            "Epoch[5342/10000] | loss train:0.811017, test:0.146402 | lr:0.000000\n",
            "Epoch[5343/10000] | loss train:1.080392, test:0.207928 | lr:0.000000\n",
            "Epoch[5344/10000] | loss train:1.313785, test:0.256063 | lr:0.000000\n",
            "Epoch[5345/10000] | loss train:1.082508, test:1.742233 | lr:0.000000\n",
            "Epoch[5346/10000] | loss train:0.794980, test:0.344763 | lr:0.000000\n",
            "Epoch[5347/10000] | loss train:1.082720, test:0.991914 | lr:0.000000\n",
            "Epoch[5348/10000] | loss train:2.335585, test:0.392356 | lr:0.000000\n",
            "Epoch[5349/10000] | loss train:1.342403, test:0.254126 | lr:0.000000\n",
            "Epoch[5350/10000] | loss train:1.652656, test:0.206419 | lr:0.000000\n",
            "Epoch[5351/10000] | loss train:1.538319, test:0.276216 | lr:0.000000\n",
            "Epoch[5352/10000] | loss train:1.963179, test:2.270687 | lr:0.000000\n",
            "Epoch[5353/10000] | loss train:1.063550, test:0.049382 | lr:0.000000\n",
            "Epoch[5354/10000] | loss train:1.841662, test:0.272897 | lr:0.000000\n",
            "Epoch[5355/10000] | loss train:1.143626, test:0.370081 | lr:0.000000\n",
            "Epoch[5356/10000] | loss train:0.721651, test:0.300401 | lr:0.000000\n",
            "Epoch[5357/10000] | loss train:1.260147, test:0.762167 | lr:0.000000\n",
            "Epoch[5358/10000] | loss train:0.895895, test:1.164179 | lr:0.000000\n",
            "Epoch[5359/10000] | loss train:0.960091, test:0.207935 | lr:0.000000\n",
            "Epoch[5360/10000] | loss train:0.975930, test:0.540185 | lr:0.000000\n",
            "Epoch[5361/10000] | loss train:0.666470, test:0.597674 | lr:0.000000\n",
            "Epoch[5362/10000] | loss train:1.787389, test:0.357871 | lr:0.000000\n",
            "Epoch[5363/10000] | loss train:1.695158, test:0.220719 | lr:0.000000\n",
            "Epoch[5364/10000] | loss train:0.780139, test:1.854608 | lr:0.000000\n",
            "Epoch[5365/10000] | loss train:0.903504, test:0.717284 | lr:0.000000\n",
            "Epoch[5366/10000] | loss train:1.342319, test:0.716169 | lr:0.000000\n",
            "Epoch[5367/10000] | loss train:0.822737, test:0.682032 | lr:0.000000\n",
            "Epoch[5368/10000] | loss train:0.834121, test:1.302904 | lr:0.000000\n",
            "Epoch[5369/10000] | loss train:2.071776, test:0.545204 | lr:0.000000\n",
            "Epoch[5370/10000] | loss train:1.831275, test:0.910604 | lr:0.000000\n",
            "Epoch[5371/10000] | loss train:0.869618, test:1.857416 | lr:0.000000\n",
            "Epoch[5372/10000] | loss train:0.856900, test:0.399310 | lr:0.000000\n",
            "Epoch[5373/10000] | loss train:1.634791, test:0.908126 | lr:0.000000\n",
            "Epoch[5374/10000] | loss train:0.744821, test:1.380627 | lr:0.000000\n",
            "Epoch[5375/10000] | loss train:1.134366, test:0.361306 | lr:0.000000\n",
            "Epoch[5376/10000] | loss train:1.196348, test:0.923728 | lr:0.000000\n",
            "Epoch[5377/10000] | loss train:1.074463, test:0.161153 | lr:0.000000\n",
            "Epoch[5378/10000] | loss train:0.982452, test:1.142808 | lr:0.000000\n",
            "Epoch[5379/10000] | loss train:0.925914, test:0.918082 | lr:0.000000\n",
            "Epoch[5380/10000] | loss train:2.525056, test:0.589952 | lr:0.000000\n",
            "Epoch[5381/10000] | loss train:0.675957, test:0.695236 | lr:0.000000\n",
            "Epoch[5382/10000] | loss train:1.785541, test:0.298623 | lr:0.000000\n",
            "Epoch[5383/10000] | loss train:1.052275, test:1.100108 | lr:0.000000\n",
            "Epoch[5384/10000] | loss train:1.306391, test:0.767215 | lr:0.000000\n",
            "Epoch[5385/10000] | loss train:2.569735, test:0.610107 | lr:0.000000\n",
            "Epoch[5386/10000] | loss train:1.063887, test:0.083898 | lr:0.000000\n",
            "Epoch[5387/10000] | loss train:0.857338, test:0.204370 | lr:0.000000\n",
            "Epoch[5388/10000] | loss train:0.842949, test:0.715786 | lr:0.000000\n",
            "Epoch[5389/10000] | loss train:2.020231, test:0.290378 | lr:0.000000\n",
            "Epoch[5390/10000] | loss train:0.862265, test:0.315573 | lr:0.000000\n",
            "Epoch[5391/10000] | loss train:0.900066, test:0.273457 | lr:0.000000\n",
            "Epoch[5392/10000] | loss train:0.896352, test:0.935966 | lr:0.000000\n",
            "Epoch[5393/10000] | loss train:1.833987, test:0.723260 | lr:0.000000\n",
            "Epoch[5394/10000] | loss train:1.029067, test:0.466152 | lr:0.000000\n",
            "Epoch[5395/10000] | loss train:1.918307, test:0.490390 | lr:0.000000\n",
            "Epoch[5396/10000] | loss train:1.039022, test:0.273039 | lr:0.000000\n",
            "Epoch[5397/10000] | loss train:1.075110, test:0.569931 | lr:0.000000\n",
            "Epoch[5398/10000] | loss train:1.306045, test:0.392389 | lr:0.000000\n",
            "Epoch[5399/10000] | loss train:1.587826, test:1.446570 | lr:0.000000\n",
            "Epoch[5400/10000] | loss train:1.971296, test:0.379056 | lr:0.000000\n",
            "Epoch[5401/10000] | loss train:1.283953, test:0.999357 | lr:0.000000\n",
            "Epoch[5402/10000] | loss train:1.061083, test:0.532083 | lr:0.000000\n",
            "Epoch[5403/10000] | loss train:1.124823, test:0.409076 | lr:0.000000\n",
            "Epoch[5404/10000] | loss train:0.967931, test:0.744352 | lr:0.000000\n",
            "Epoch[5405/10000] | loss train:1.098154, test:0.679485 | lr:0.000000\n",
            "Epoch[5406/10000] | loss train:0.976142, test:0.302618 | lr:0.000000\n",
            "Epoch[5407/10000] | loss train:1.429177, test:0.610211 | lr:0.000000\n",
            "Epoch[5408/10000] | loss train:1.167456, test:0.950867 | lr:0.000000\n",
            "Epoch[5409/10000] | loss train:1.034916, test:0.567452 | lr:0.000000\n",
            "Epoch[5410/10000] | loss train:0.897304, test:1.196052 | lr:0.000000\n",
            "Epoch[5411/10000] | loss train:0.848040, test:1.413264 | lr:0.000000\n",
            "Epoch[5412/10000] | loss train:1.418895, test:0.782727 | lr:0.000000\n",
            "Epoch[5413/10000] | loss train:1.339502, test:1.008558 | lr:0.000000\n",
            "Epoch[5414/10000] | loss train:1.314842, test:0.963362 | lr:0.000000\n",
            "Epoch[5415/10000] | loss train:0.780288, test:1.153372 | lr:0.000000\n",
            "Epoch[5416/10000] | loss train:1.337018, test:0.241417 | lr:0.000000\n",
            "Epoch[5417/10000] | loss train:1.378587, test:0.619181 | lr:0.000000\n",
            "Epoch[5418/10000] | loss train:1.162323, test:0.283042 | lr:0.000000\n",
            "Epoch[5419/10000] | loss train:1.106220, test:0.141673 | lr:0.000000\n",
            "Epoch[5420/10000] | loss train:1.820503, test:0.338067 | lr:0.000000\n",
            "Epoch[5421/10000] | loss train:1.004264, test:0.312227 | lr:0.000000\n",
            "Epoch[5422/10000] | loss train:1.293903, test:0.669801 | lr:0.000000\n",
            "Epoch[5423/10000] | loss train:0.645967, test:0.588310 | lr:0.000000\n",
            "Epoch[5424/10000] | loss train:0.999734, test:0.390825 | lr:0.000000\n",
            "Epoch[5425/10000] | loss train:0.913982, test:0.684568 | lr:0.000000\n",
            "Epoch[5426/10000] | loss train:1.176420, test:0.179250 | lr:0.000000\n",
            "Epoch[5427/10000] | loss train:2.214332, test:0.851303 | lr:0.000000\n",
            "Epoch[5428/10000] | loss train:1.989881, test:0.296009 | lr:0.000000\n",
            "Epoch[5429/10000] | loss train:1.909838, test:1.327174 | lr:0.000000\n",
            "Epoch[5430/10000] | loss train:1.653091, test:0.559798 | lr:0.000000\n",
            "Epoch[5431/10000] | loss train:1.198055, test:0.272284 | lr:0.000000\n",
            "Epoch[5432/10000] | loss train:1.071223, test:0.376466 | lr:0.000000\n",
            "Epoch[5433/10000] | loss train:0.824879, test:0.911364 | lr:0.000000\n",
            "Epoch[5434/10000] | loss train:1.131651, test:1.770722 | lr:0.000000\n",
            "Epoch[5435/10000] | loss train:1.073092, test:0.289024 | lr:0.000000\n",
            "Epoch[5436/10000] | loss train:1.265515, test:1.099307 | lr:0.000000\n",
            "Epoch[5437/10000] | loss train:1.252489, test:0.923035 | lr:0.000000\n",
            "Epoch[5438/10000] | loss train:1.677260, test:0.249531 | lr:0.000000\n",
            "Epoch[5439/10000] | loss train:0.769727, test:0.198910 | lr:0.000000\n",
            "Epoch[5440/10000] | loss train:1.596243, test:0.916770 | lr:0.000000\n",
            "Epoch[5441/10000] | loss train:1.467488, test:0.113606 | lr:0.000000\n",
            "Epoch[5442/10000] | loss train:1.133314, test:0.729640 | lr:0.000000\n",
            "Epoch[5443/10000] | loss train:1.449944, test:0.318673 | lr:0.000000\n",
            "Epoch[5444/10000] | loss train:0.898778, test:0.213260 | lr:0.000000\n",
            "Epoch[5445/10000] | loss train:0.886773, test:0.448744 | lr:0.000000\n",
            "Epoch[5446/10000] | loss train:1.250717, test:1.224992 | lr:0.000000\n",
            "Epoch[5447/10000] | loss train:0.815622, test:0.145067 | lr:0.000000\n",
            "Epoch[5448/10000] | loss train:1.198234, test:0.237381 | lr:0.000000\n",
            "Epoch[5449/10000] | loss train:1.344939, test:0.289364 | lr:0.000000\n",
            "Epoch[5450/10000] | loss train:0.782557, test:0.185441 | lr:0.000000\n",
            "Epoch[5451/10000] | loss train:1.232656, test:0.831901 | lr:0.000000\n",
            "Epoch[5452/10000] | loss train:1.382771, test:0.778640 | lr:0.000000\n",
            "Epoch[5453/10000] | loss train:0.822355, test:0.601679 | lr:0.000000\n",
            "Epoch[5454/10000] | loss train:0.692347, test:0.250536 | lr:0.000000\n",
            "Epoch[5455/10000] | loss train:1.115141, test:1.472340 | lr:0.000000\n",
            "Epoch[5456/10000] | loss train:1.209204, test:1.847971 | lr:0.000000\n",
            "Epoch[5457/10000] | loss train:1.161516, test:0.485700 | lr:0.000000\n",
            "Epoch[5458/10000] | loss train:0.934044, test:0.502635 | lr:0.000000\n",
            "Epoch[5459/10000] | loss train:0.967041, test:0.351337 | lr:0.000000\n",
            "Epoch[5460/10000] | loss train:2.221134, test:0.551148 | lr:0.000000\n",
            "Epoch[5461/10000] | loss train:1.308121, test:1.410926 | lr:0.000000\n",
            "Epoch[5462/10000] | loss train:1.786032, test:0.562497 | lr:0.000000\n",
            "Epoch[5463/10000] | loss train:1.471492, test:0.245808 | lr:0.000000\n",
            "Epoch[5464/10000] | loss train:2.007591, test:1.745210 | lr:0.000000\n",
            "Epoch[5465/10000] | loss train:1.254273, test:0.453995 | lr:0.000000\n",
            "Epoch[5466/10000] | loss train:2.198409, test:0.441953 | lr:0.000000\n",
            "Epoch[5467/10000] | loss train:0.675989, test:0.856595 | lr:0.000000\n",
            "Epoch[5468/10000] | loss train:1.417283, test:1.188720 | lr:0.000000\n",
            "Epoch[5469/10000] | loss train:0.975813, test:0.828281 | lr:0.000000\n",
            "Epoch[5470/10000] | loss train:1.134594, test:0.834109 | lr:0.000000\n",
            "Epoch[5471/10000] | loss train:1.258013, test:0.238189 | lr:0.000000\n",
            "Epoch[5472/10000] | loss train:1.024137, test:1.281900 | lr:0.000000\n",
            "Epoch[5473/10000] | loss train:1.518355, test:1.280529 | lr:0.000000\n",
            "Epoch[5474/10000] | loss train:2.333871, test:0.239824 | lr:0.000000\n",
            "Epoch[5475/10000] | loss train:0.939575, test:0.679467 | lr:0.000000\n",
            "Epoch[5476/10000] | loss train:1.522205, test:0.151728 | lr:0.000000\n",
            "Epoch[5477/10000] | loss train:2.064754, test:0.556508 | lr:0.000000\n",
            "Epoch[5478/10000] | loss train:0.763792, test:0.209432 | lr:0.000000\n",
            "Epoch[5479/10000] | loss train:0.898283, test:1.365796 | lr:0.000000\n",
            "Epoch[5480/10000] | loss train:0.736613, test:0.673410 | lr:0.000000\n",
            "Epoch[5481/10000] | loss train:0.769893, test:1.115140 | lr:0.000000\n",
            "Epoch[5482/10000] | loss train:1.488230, test:1.392426 | lr:0.000000\n",
            "Epoch[5483/10000] | loss train:1.287258, test:0.279090 | lr:0.000000\n",
            "Epoch[5484/10000] | loss train:1.424277, test:0.246637 | lr:0.000000\n",
            "Epoch[5485/10000] | loss train:1.175170, test:1.134170 | lr:0.000000\n",
            "Epoch[5486/10000] | loss train:1.741196, test:0.278308 | lr:0.000000\n",
            "Epoch[5487/10000] | loss train:0.991355, test:0.449628 | lr:0.000000\n",
            "Epoch[5488/10000] | loss train:0.705300, test:0.607073 | lr:0.000000\n",
            "Epoch[5489/10000] | loss train:1.577891, test:0.363602 | lr:0.000000\n",
            "Epoch[5490/10000] | loss train:2.486887, test:0.980903 | lr:0.000000\n",
            "Epoch[5491/10000] | loss train:0.913941, test:1.390453 | lr:0.000000\n",
            "Epoch[5492/10000] | loss train:1.157629, test:0.751349 | lr:0.000000\n",
            "Epoch[5493/10000] | loss train:1.151753, test:0.324179 | lr:0.000000\n",
            "Epoch[5494/10000] | loss train:0.983084, test:0.660280 | lr:0.000000\n",
            "Epoch[5495/10000] | loss train:0.699626, test:0.898103 | lr:0.000000\n",
            "Epoch[5496/10000] | loss train:1.733587, test:0.641179 | lr:0.000000\n",
            "Epoch[5497/10000] | loss train:1.258506, test:1.027176 | lr:0.000000\n",
            "Epoch[5498/10000] | loss train:1.151078, test:0.280102 | lr:0.000000\n",
            "Epoch[5499/10000] | loss train:2.046847, test:0.229788 | lr:0.000000\n",
            "Epoch[5500/10000] | loss train:1.421925, test:1.276402 | lr:0.000000\n",
            "Epoch[5501/10000] | loss train:0.657481, test:0.209081 | lr:0.000000\n",
            "Epoch[5502/10000] | loss train:1.422871, test:0.729365 | lr:0.000000\n",
            "Epoch[5503/10000] | loss train:1.548385, test:0.068274 | lr:0.000000\n",
            "Epoch[5504/10000] | loss train:1.754136, test:0.600620 | lr:0.000000\n",
            "Epoch[5505/10000] | loss train:1.342569, test:0.434771 | lr:0.000000\n",
            "Epoch[5506/10000] | loss train:1.451055, test:0.420476 | lr:0.000000\n",
            "Epoch[5507/10000] | loss train:1.483236, test:1.645856 | lr:0.000000\n",
            "Epoch[5508/10000] | loss train:1.041702, test:0.266516 | lr:0.000000\n",
            "Epoch[5509/10000] | loss train:1.848015, test:0.700813 | lr:0.000000\n",
            "Epoch[5510/10000] | loss train:0.731033, test:1.267213 | lr:0.000000\n",
            "Epoch[5511/10000] | loss train:1.517913, test:0.480967 | lr:0.000000\n",
            "Epoch[5512/10000] | loss train:0.710022, test:0.434610 | lr:0.000000\n",
            "Epoch[5513/10000] | loss train:0.791301, test:0.936830 | lr:0.000000\n",
            "Epoch[5514/10000] | loss train:1.364642, test:0.597918 | lr:0.000000\n",
            "Epoch[5515/10000] | loss train:1.497582, test:0.339860 | lr:0.000000\n",
            "Epoch[5516/10000] | loss train:3.367752, test:0.140317 | lr:0.000000\n",
            "Epoch[5517/10000] | loss train:1.066892, test:0.505955 | lr:0.000000\n",
            "Epoch[5518/10000] | loss train:2.380174, test:0.117639 | lr:0.000000\n",
            "Epoch[5519/10000] | loss train:0.887844, test:1.571493 | lr:0.000000\n",
            "Epoch[5520/10000] | loss train:1.135708, test:0.243085 | lr:0.000000\n",
            "Epoch[5521/10000] | loss train:1.474279, test:0.516818 | lr:0.000000\n",
            "Epoch[5522/10000] | loss train:0.941229, test:1.563836 | lr:0.000000\n",
            "Epoch[5523/10000] | loss train:1.282739, test:1.115464 | lr:0.000000\n",
            "Epoch[5524/10000] | loss train:0.787070, test:0.260542 | lr:0.000000\n",
            "Epoch[5525/10000] | loss train:1.374374, test:0.620771 | lr:0.000000\n",
            "Epoch[5526/10000] | loss train:2.551659, test:0.191967 | lr:0.000000\n",
            "Epoch[5527/10000] | loss train:1.109577, test:0.183313 | lr:0.000000\n",
            "Epoch[5528/10000] | loss train:1.530716, test:0.158960 | lr:0.000000\n",
            "Epoch[5529/10000] | loss train:1.624626, test:0.157179 | lr:0.000000\n",
            "Epoch[5530/10000] | loss train:1.005539, test:1.785170 | lr:0.000000\n",
            "Epoch[5531/10000] | loss train:1.013834, test:0.215490 | lr:0.000000\n",
            "Epoch[5532/10000] | loss train:1.221481, test:0.291442 | lr:0.000000\n",
            "Epoch[5533/10000] | loss train:0.910818, test:1.376618 | lr:0.000000\n",
            "Epoch[5534/10000] | loss train:1.833853, test:1.085762 | lr:0.000000\n",
            "Epoch[5535/10000] | loss train:1.335584, test:0.562714 | lr:0.000000\n",
            "Epoch[5536/10000] | loss train:0.921094, test:1.400717 | lr:0.000000\n",
            "Epoch[5537/10000] | loss train:2.739949, test:0.460820 | lr:0.000000\n",
            "Epoch[5538/10000] | loss train:2.155957, test:0.662476 | lr:0.000000\n",
            "Epoch[5539/10000] | loss train:1.885909, test:0.602643 | lr:0.000000\n",
            "Epoch[5540/10000] | loss train:1.146770, test:0.597381 | lr:0.000000\n",
            "Epoch[5541/10000] | loss train:2.072589, test:0.320656 | lr:0.000000\n",
            "Epoch[5542/10000] | loss train:1.518349, test:0.260582 | lr:0.000000\n",
            "Epoch[5543/10000] | loss train:1.686343, test:1.049579 | lr:0.000000\n",
            "Epoch[5544/10000] | loss train:0.961725, test:1.017142 | lr:0.000000\n",
            "Epoch[5545/10000] | loss train:0.853096, test:0.598796 | lr:0.000000\n",
            "Epoch[5546/10000] | loss train:0.739583, test:0.374169 | lr:0.000000\n",
            "Epoch[5547/10000] | loss train:0.937216, test:0.570179 | lr:0.000000\n",
            "Epoch[5548/10000] | loss train:0.944706, test:0.222832 | lr:0.000000\n",
            "Epoch[5549/10000] | loss train:1.376759, test:1.196193 | lr:0.000000\n",
            "Epoch[5550/10000] | loss train:1.396840, test:0.141091 | lr:0.000000\n",
            "Epoch[5551/10000] | loss train:0.657981, test:0.385004 | lr:0.000000\n",
            "Epoch[5552/10000] | loss train:1.195763, test:1.166417 | lr:0.000000\n",
            "Epoch[5553/10000] | loss train:1.963551, test:0.296513 | lr:0.000000\n",
            "Epoch[5554/10000] | loss train:1.146184, test:0.576793 | lr:0.000000\n",
            "Epoch[5555/10000] | loss train:2.525377, test:0.199268 | lr:0.000000\n",
            "Epoch[5556/10000] | loss train:1.194181, test:2.079632 | lr:0.000000\n",
            "Epoch[5557/10000] | loss train:0.823675, test:0.508913 | lr:0.000000\n",
            "Epoch[5558/10000] | loss train:1.575984, test:0.531942 | lr:0.000000\n",
            "Epoch[5559/10000] | loss train:1.070248, test:0.278492 | lr:0.000000\n",
            "Epoch[5560/10000] | loss train:1.669491, test:0.835512 | lr:0.000000\n",
            "Epoch[5561/10000] | loss train:1.615429, test:1.330892 | lr:0.000000\n",
            "Epoch[5562/10000] | loss train:0.786615, test:0.284940 | lr:0.000000\n",
            "Epoch[5563/10000] | loss train:0.895500, test:0.492723 | lr:0.000000\n",
            "Epoch[5564/10000] | loss train:1.524526, test:0.536240 | lr:0.000000\n",
            "Epoch[5565/10000] | loss train:1.806330, test:0.838698 | lr:0.000000\n",
            "Epoch[5566/10000] | loss train:1.089026, test:0.481418 | lr:0.000000\n",
            "Epoch[5567/10000] | loss train:1.331168, test:0.485218 | lr:0.000000\n",
            "Epoch[5568/10000] | loss train:0.778707, test:0.436316 | lr:0.000000\n",
            "Epoch[5569/10000] | loss train:1.147509, test:0.376411 | lr:0.000000\n",
            "Epoch[5570/10000] | loss train:0.837844, test:0.723127 | lr:0.000000\n",
            "Epoch[5571/10000] | loss train:1.456595, test:0.465523 | lr:0.000000\n",
            "Epoch[5572/10000] | loss train:0.905173, test:0.551378 | lr:0.000000\n",
            "Epoch[5573/10000] | loss train:1.811789, test:0.647551 | lr:0.000000\n",
            "Epoch[5574/10000] | loss train:1.185419, test:0.675216 | lr:0.000000\n",
            "Epoch[5575/10000] | loss train:1.883247, test:0.267822 | lr:0.000000\n",
            "Epoch[5576/10000] | loss train:0.760830, test:0.122626 | lr:0.000000\n",
            "Epoch[5577/10000] | loss train:1.710992, test:0.268082 | lr:0.000000\n",
            "Epoch[5578/10000] | loss train:1.363753, test:0.465486 | lr:0.000000\n",
            "Epoch[5579/10000] | loss train:1.204778, test:0.205164 | lr:0.000000\n",
            "Epoch[5580/10000] | loss train:0.701509, test:0.535505 | lr:0.000000\n",
            "Epoch[5581/10000] | loss train:0.789144, test:0.310581 | lr:0.000000\n",
            "Epoch[5582/10000] | loss train:0.775909, test:0.412744 | lr:0.000000\n",
            "Epoch[5583/10000] | loss train:0.921166, test:0.296295 | lr:0.000000\n",
            "Epoch[5584/10000] | loss train:1.349086, test:0.147134 | lr:0.000000\n",
            "Epoch[5585/10000] | loss train:1.329241, test:0.258093 | lr:0.000000\n",
            "Epoch[5586/10000] | loss train:1.058286, test:1.546883 | lr:0.000000\n",
            "Epoch[5587/10000] | loss train:0.844651, test:0.664257 | lr:0.000000\n",
            "Epoch[5588/10000] | loss train:1.217979, test:2.119906 | lr:0.000000\n",
            "Epoch[5589/10000] | loss train:1.840894, test:1.319661 | lr:0.000000\n",
            "Epoch[5590/10000] | loss train:1.292099, test:0.166299 | lr:0.000000\n",
            "Epoch[5591/10000] | loss train:2.364765, test:0.158406 | lr:0.000000\n",
            "Epoch[5592/10000] | loss train:1.572474, test:0.524091 | lr:0.000000\n",
            "Epoch[5593/10000] | loss train:1.019302, test:1.108307 | lr:0.000000\n",
            "Epoch[5594/10000] | loss train:0.824018, test:1.241348 | lr:0.000000\n",
            "Epoch[5595/10000] | loss train:1.021295, test:1.033704 | lr:0.000000\n",
            "Epoch[5596/10000] | loss train:0.820039, test:0.869001 | lr:0.000000\n",
            "Epoch[5597/10000] | loss train:1.370184, test:0.238682 | lr:0.000000\n",
            "Epoch[5598/10000] | loss train:1.568340, test:0.266881 | lr:0.000000\n",
            "Epoch[5599/10000] | loss train:1.345973, test:1.445927 | lr:0.000000\n",
            "Epoch[5600/10000] | loss train:1.370613, test:1.764036 | lr:0.000000\n",
            "Epoch[5601/10000] | loss train:1.253153, test:0.142604 | lr:0.000000\n",
            "Epoch[5602/10000] | loss train:1.498171, test:0.458309 | lr:0.000000\n",
            "Epoch[5603/10000] | loss train:0.707212, test:1.168001 | lr:0.000000\n",
            "Epoch[5604/10000] | loss train:1.959771, test:0.367370 | lr:0.000000\n",
            "Epoch[5605/10000] | loss train:1.019891, test:0.527505 | lr:0.000000\n",
            "Epoch[5606/10000] | loss train:1.566572, test:0.364768 | lr:0.000000\n",
            "Epoch[5607/10000] | loss train:3.001990, test:1.018000 | lr:0.000000\n",
            "Epoch[5608/10000] | loss train:0.953659, test:1.612588 | lr:0.000000\n",
            "Epoch[5609/10000] | loss train:0.933724, test:0.130982 | lr:0.000000\n",
            "Epoch[5610/10000] | loss train:0.662260, test:1.485591 | lr:0.000000\n",
            "Epoch[5611/10000] | loss train:0.752405, test:0.323377 | lr:0.000000\n",
            "Epoch[5612/10000] | loss train:0.922656, test:0.256241 | lr:0.000000\n",
            "Epoch[5613/10000] | loss train:1.714649, test:0.143663 | lr:0.000000\n",
            "Epoch[5614/10000] | loss train:1.578346, test:1.128982 | lr:0.000000\n",
            "Epoch[5615/10000] | loss train:1.171645, test:1.103368 | lr:0.000000\n",
            "Epoch[5616/10000] | loss train:1.899994, test:0.156284 | lr:0.000000\n",
            "Epoch[5617/10000] | loss train:1.291026, test:0.826105 | lr:0.000000\n",
            "Epoch[5618/10000] | loss train:1.191659, test:1.163281 | lr:0.000000\n",
            "Epoch[5619/10000] | loss train:1.218425, test:0.314989 | lr:0.000000\n",
            "Epoch[5620/10000] | loss train:1.239623, test:1.109044 | lr:0.000000\n",
            "Epoch[5621/10000] | loss train:0.827852, test:1.189252 | lr:0.000000\n",
            "Epoch[5622/10000] | loss train:1.316558, test:0.407415 | lr:0.000000\n",
            "Epoch[5623/10000] | loss train:0.835575, test:0.420208 | lr:0.000000\n",
            "Epoch[5624/10000] | loss train:0.771098, test:0.164590 | lr:0.000000\n",
            "Epoch[5625/10000] | loss train:1.199969, test:0.367290 | lr:0.000000\n",
            "Epoch[5626/10000] | loss train:1.057383, test:0.671991 | lr:0.000000\n",
            "Epoch[5627/10000] | loss train:1.613135, test:0.282353 | lr:0.000000\n",
            "Epoch[5628/10000] | loss train:1.394632, test:0.271914 | lr:0.000000\n",
            "Epoch[5629/10000] | loss train:1.309393, test:0.718049 | lr:0.000000\n",
            "Epoch[5630/10000] | loss train:1.947135, test:0.923521 | lr:0.000000\n",
            "Epoch[5631/10000] | loss train:1.359855, test:0.519316 | lr:0.000000\n",
            "Epoch[5632/10000] | loss train:1.378733, test:0.179071 | lr:0.000000\n",
            "Epoch[5633/10000] | loss train:0.744391, test:0.683524 | lr:0.000000\n",
            "Epoch[5634/10000] | loss train:0.896745, test:0.363479 | lr:0.000000\n",
            "Epoch[5635/10000] | loss train:1.296228, test:0.794015 | lr:0.000000\n",
            "Epoch[5636/10000] | loss train:2.316915, test:0.560941 | lr:0.000000\n",
            "Epoch[5637/10000] | loss train:0.991662, test:0.414512 | lr:0.000000\n",
            "Epoch[5638/10000] | loss train:0.611197, test:0.309248 | lr:0.000000\n",
            "Epoch[5639/10000] | loss train:1.021717, test:0.050665 | lr:0.000000\n",
            "Epoch[5640/10000] | loss train:1.354784, test:0.625811 | lr:0.000000\n",
            "Epoch[5641/10000] | loss train:1.363044, test:1.140347 | lr:0.000000\n",
            "Epoch[5642/10000] | loss train:2.042212, test:1.054456 | lr:0.000000\n",
            "Epoch[5643/10000] | loss train:1.467812, test:0.680895 | lr:0.000000\n",
            "Epoch[5644/10000] | loss train:1.108771, test:0.105502 | lr:0.000000\n",
            "Epoch[5645/10000] | loss train:1.658202, test:1.381706 | lr:0.000000\n",
            "Epoch[5646/10000] | loss train:1.153632, test:0.715562 | lr:0.000000\n",
            "Epoch[5647/10000] | loss train:2.076479, test:1.429016 | lr:0.000000\n",
            "Epoch[5648/10000] | loss train:1.821292, test:1.837900 | lr:0.000000\n",
            "Epoch[5649/10000] | loss train:1.854497, test:0.232708 | lr:0.000000\n",
            "Epoch[5650/10000] | loss train:0.773816, test:1.186555 | lr:0.000000\n",
            "Epoch[5651/10000] | loss train:1.488572, test:0.429541 | lr:0.000000\n",
            "Epoch[5652/10000] | loss train:0.926669, test:0.399876 | lr:0.000000\n",
            "Epoch[5653/10000] | loss train:1.436637, test:0.233599 | lr:0.000000\n",
            "Epoch[5654/10000] | loss train:0.746082, test:1.789882 | lr:0.000000\n",
            "Epoch[5655/10000] | loss train:1.355317, test:0.659007 | lr:0.000000\n",
            "Epoch[5656/10000] | loss train:0.851536, test:0.500981 | lr:0.000000\n",
            "Epoch[5657/10000] | loss train:1.048519, test:1.311599 | lr:0.000000\n",
            "Epoch[5658/10000] | loss train:2.981192, test:0.479528 | lr:0.000000\n",
            "Epoch[5659/10000] | loss train:1.363414, test:0.158551 | lr:0.000000\n",
            "Epoch[5660/10000] | loss train:1.034578, test:1.166954 | lr:0.000000\n",
            "Epoch[5661/10000] | loss train:1.400502, test:2.038665 | lr:0.000000\n",
            "Epoch[5662/10000] | loss train:1.055199, test:0.244462 | lr:0.000000\n",
            "Epoch[5663/10000] | loss train:0.900507, test:0.172318 | lr:0.000000\n",
            "Epoch[5664/10000] | loss train:1.326234, test:0.769708 | lr:0.000000\n",
            "Epoch[5665/10000] | loss train:0.938603, test:0.673256 | lr:0.000000\n",
            "Epoch[5666/10000] | loss train:1.562847, test:0.394650 | lr:0.000000\n",
            "Epoch[5667/10000] | loss train:0.878726, test:1.823631 | lr:0.000000\n",
            "Epoch[5668/10000] | loss train:0.871798, test:0.387279 | lr:0.000000\n",
            "Epoch[5669/10000] | loss train:0.840284, test:0.484200 | lr:0.000000\n",
            "Epoch[5670/10000] | loss train:1.118671, test:0.153916 | lr:0.000000\n",
            "Epoch[5671/10000] | loss train:0.970580, test:0.274659 | lr:0.000000\n",
            "Epoch[5672/10000] | loss train:1.466052, test:1.181677 | lr:0.000000\n",
            "Epoch[5673/10000] | loss train:1.105016, test:1.216366 | lr:0.000000\n",
            "Epoch[5674/10000] | loss train:1.840039, test:1.242212 | lr:0.000000\n",
            "Epoch[5675/10000] | loss train:0.609969, test:0.823707 | lr:0.000000\n",
            "Epoch[5676/10000] | loss train:1.782294, test:0.418861 | lr:0.000000\n",
            "Epoch[5677/10000] | loss train:1.384713, test:1.661063 | lr:0.000000\n",
            "Epoch[5678/10000] | loss train:0.968661, test:1.258870 | lr:0.000000\n",
            "Epoch[5679/10000] | loss train:0.869295, test:1.674558 | lr:0.000000\n",
            "Epoch[5680/10000] | loss train:1.411621, test:0.207848 | lr:0.000000\n",
            "Epoch[5681/10000] | loss train:1.700616, test:1.249078 | lr:0.000000\n",
            "Epoch[5682/10000] | loss train:0.924146, test:0.906683 | lr:0.000000\n",
            "Epoch[5683/10000] | loss train:1.576177, test:0.089308 | lr:0.000000\n",
            "Epoch[5684/10000] | loss train:0.710452, test:0.456060 | lr:0.000000\n",
            "Epoch[5685/10000] | loss train:0.935742, test:0.236951 | lr:0.000000\n",
            "Epoch[5686/10000] | loss train:1.172232, test:0.290548 | lr:0.000000\n",
            "Epoch[5687/10000] | loss train:1.128215, test:1.558728 | lr:0.000000\n",
            "Epoch[5688/10000] | loss train:1.209334, test:0.611511 | lr:0.000000\n",
            "Epoch[5689/10000] | loss train:1.618708, test:1.276433 | lr:0.000000\n",
            "Epoch[5690/10000] | loss train:1.169970, test:0.133044 | lr:0.000000\n",
            "Epoch[5691/10000] | loss train:1.046747, test:0.632454 | lr:0.000000\n",
            "Epoch[5692/10000] | loss train:1.393117, test:0.711451 | lr:0.000000\n",
            "Epoch[5693/10000] | loss train:0.903022, test:0.968669 | lr:0.000000\n",
            "Epoch[5694/10000] | loss train:1.427929, test:0.133267 | lr:0.000000\n",
            "Epoch[5695/10000] | loss train:1.534235, test:0.236559 | lr:0.000000\n",
            "Epoch[5696/10000] | loss train:1.526210, test:0.434350 | lr:0.000000\n",
            "Epoch[5697/10000] | loss train:1.527146, test:1.401912 | lr:0.000000\n",
            "Epoch[5698/10000] | loss train:1.334662, test:0.611754 | lr:0.000000\n",
            "Epoch[5699/10000] | loss train:2.649165, test:1.007513 | lr:0.000000\n",
            "Epoch[5700/10000] | loss train:1.499831, test:0.601319 | lr:0.000000\n",
            "Epoch[5701/10000] | loss train:2.221843, test:0.228225 | lr:0.000000\n",
            "Epoch[5702/10000] | loss train:1.178523, test:0.171038 | lr:0.000000\n",
            "Epoch[5703/10000] | loss train:1.235559, test:0.049111 | lr:0.000000\n",
            "Epoch[5704/10000] | loss train:1.592799, test:0.280644 | lr:0.000000\n",
            "Epoch[5705/10000] | loss train:0.973406, test:0.265427 | lr:0.000000\n",
            "Epoch[5706/10000] | loss train:2.792859, test:0.145882 | lr:0.000000\n",
            "Epoch[5707/10000] | loss train:1.087808, test:0.145687 | lr:0.000000\n",
            "Epoch[5708/10000] | loss train:1.747692, test:0.386627 | lr:0.000000\n",
            "Epoch[5709/10000] | loss train:1.483412, test:0.881865 | lr:0.000000\n",
            "Epoch[5710/10000] | loss train:1.036454, test:1.386964 | lr:0.000000\n",
            "Epoch[5711/10000] | loss train:1.496372, test:1.685804 | lr:0.000000\n",
            "Epoch[5712/10000] | loss train:1.587490, test:0.424215 | lr:0.000000\n",
            "Epoch[5713/10000] | loss train:1.417750, test:1.186380 | lr:0.000000\n",
            "Epoch[5714/10000] | loss train:1.476994, test:0.366856 | lr:0.000000\n",
            "Epoch[5715/10000] | loss train:1.787566, test:0.506723 | lr:0.000000\n",
            "Epoch[5716/10000] | loss train:1.087444, test:1.391319 | lr:0.000000\n",
            "Epoch[5717/10000] | loss train:1.900929, test:0.505155 | lr:0.000000\n",
            "Epoch[5718/10000] | loss train:1.095422, test:0.382540 | lr:0.000000\n",
            "Epoch[5719/10000] | loss train:1.570157, test:0.411193 | lr:0.000000\n",
            "Epoch[5720/10000] | loss train:0.872184, test:0.268551 | lr:0.000000\n",
            "Epoch[5721/10000] | loss train:0.990301, test:0.207811 | lr:0.000000\n",
            "Epoch[5722/10000] | loss train:1.245418, test:0.959740 | lr:0.000000\n",
            "Epoch[5723/10000] | loss train:1.468170, test:0.788548 | lr:0.000000\n",
            "Epoch[5724/10000] | loss train:1.530999, test:0.548220 | lr:0.000000\n",
            "Epoch[5725/10000] | loss train:1.340083, test:0.053440 | lr:0.000000\n",
            "Epoch[5726/10000] | loss train:1.984786, test:2.914751 | lr:0.000000\n",
            "Epoch[5727/10000] | loss train:1.016208, test:0.078071 | lr:0.000000\n",
            "Epoch[5728/10000] | loss train:1.036743, test:0.514058 | lr:0.000000\n",
            "Epoch[5729/10000] | loss train:0.786775, test:0.154700 | lr:0.000000\n",
            "Epoch[5730/10000] | loss train:1.024350, test:0.234757 | lr:0.000000\n",
            "Epoch[5731/10000] | loss train:1.579779, test:0.658367 | lr:0.000000\n",
            "Epoch[5732/10000] | loss train:1.125825, test:0.050613 | lr:0.000000\n",
            "Epoch[5733/10000] | loss train:1.416819, test:0.290456 | lr:0.000000\n",
            "Epoch[5734/10000] | loss train:1.594457, test:0.683496 | lr:0.000000\n",
            "Epoch[5735/10000] | loss train:0.831163, test:0.207311 | lr:0.000000\n",
            "Epoch[5736/10000] | loss train:1.267110, test:0.063913 | lr:0.000000\n",
            "Epoch[5737/10000] | loss train:1.474689, test:0.284682 | lr:0.000000\n",
            "Epoch[5738/10000] | loss train:0.849615, test:0.425769 | lr:0.000000\n",
            "Epoch[5739/10000] | loss train:0.892037, test:0.336194 | lr:0.000000\n",
            "Epoch[5740/10000] | loss train:1.253374, test:0.287485 | lr:0.000000\n",
            "Epoch[5741/10000] | loss train:1.793200, test:0.408214 | lr:0.000000\n",
            "Epoch[5742/10000] | loss train:1.401469, test:0.727220 | lr:0.000000\n",
            "Epoch[5743/10000] | loss train:1.362233, test:1.995396 | lr:0.000000\n",
            "Epoch[5744/10000] | loss train:0.753501, test:1.707384 | lr:0.000000\n",
            "Epoch[5745/10000] | loss train:1.499811, test:0.521318 | lr:0.000000\n",
            "Epoch[5746/10000] | loss train:1.280086, test:0.687005 | lr:0.000000\n",
            "Epoch[5747/10000] | loss train:1.567373, test:0.887938 | lr:0.000000\n",
            "Epoch[5748/10000] | loss train:1.342746, test:0.411647 | lr:0.000000\n",
            "Epoch[5749/10000] | loss train:1.890709, test:0.167055 | lr:0.000000\n",
            "Epoch[5750/10000] | loss train:0.807060, test:0.912821 | lr:0.000000\n",
            "Epoch[5751/10000] | loss train:1.237078, test:1.424797 | lr:0.000000\n",
            "Epoch[5752/10000] | loss train:1.505562, test:0.198557 | lr:0.000000\n",
            "Epoch[5753/10000] | loss train:0.651318, test:0.688499 | lr:0.000000\n",
            "Epoch[5754/10000] | loss train:1.118762, test:1.323846 | lr:0.000000\n",
            "Epoch[5755/10000] | loss train:1.452774, test:0.750201 | lr:0.000000\n",
            "Epoch[5756/10000] | loss train:1.045036, test:0.402258 | lr:0.000000\n",
            "Epoch[5757/10000] | loss train:1.899358, test:0.638481 | lr:0.000000\n",
            "Epoch[5758/10000] | loss train:1.581557, test:0.063311 | lr:0.000000\n",
            "Epoch[5759/10000] | loss train:1.027901, test:0.593123 | lr:0.000000\n",
            "Epoch[5760/10000] | loss train:0.641140, test:0.476377 | lr:0.000000\n",
            "Epoch[5761/10000] | loss train:0.636164, test:0.471927 | lr:0.000000\n",
            "Epoch[5762/10000] | loss train:2.718828, test:0.948317 | lr:0.000000\n",
            "Epoch[5763/10000] | loss train:1.064202, test:1.115133 | lr:0.000000\n",
            "Epoch[5764/10000] | loss train:1.104225, test:0.717809 | lr:0.000000\n",
            "Epoch[5765/10000] | loss train:1.411417, test:1.448036 | lr:0.000000\n",
            "Epoch[5766/10000] | loss train:1.649850, test:1.097260 | lr:0.000000\n",
            "Epoch[5767/10000] | loss train:0.952139, test:1.221446 | lr:0.000000\n",
            "Epoch[5768/10000] | loss train:0.799085, test:0.914401 | lr:0.000000\n",
            "Epoch[5769/10000] | loss train:1.804431, test:0.269889 | lr:0.000000\n",
            "Epoch[5770/10000] | loss train:1.174550, test:0.589332 | lr:0.000000\n",
            "Epoch[5771/10000] | loss train:1.800425, test:0.589886 | lr:0.000000\n",
            "Epoch[5772/10000] | loss train:1.080514, test:0.086105 | lr:0.000000\n",
            "Epoch[5773/10000] | loss train:0.818044, test:0.158568 | lr:0.000000\n",
            "Epoch[5774/10000] | loss train:2.249380, test:0.319306 | lr:0.000000\n",
            "Epoch[5775/10000] | loss train:1.029185, test:0.722817 | lr:0.000000\n",
            "Epoch[5776/10000] | loss train:1.637682, test:0.089881 | lr:0.000000\n",
            "Epoch[5777/10000] | loss train:0.981425, test:0.433160 | lr:0.000000\n",
            "Epoch[5778/10000] | loss train:1.168065, test:2.387994 | lr:0.000000\n",
            "Epoch[5779/10000] | loss train:2.368736, test:1.527774 | lr:0.000000\n",
            "Epoch[5780/10000] | loss train:0.744923, test:1.945587 | lr:0.000000\n",
            "Epoch[5781/10000] | loss train:0.685378, test:0.362860 | lr:0.000000\n",
            "Epoch[5782/10000] | loss train:1.178116, test:0.217498 | lr:0.000000\n",
            "Epoch[5783/10000] | loss train:1.257439, test:0.730433 | lr:0.000000\n",
            "Epoch[5784/10000] | loss train:1.189425, test:0.451362 | lr:0.000000\n",
            "Epoch[5785/10000] | loss train:0.717025, test:0.902043 | lr:0.000000\n",
            "Epoch[5786/10000] | loss train:1.248918, test:0.324164 | lr:0.000000\n",
            "Epoch[5787/10000] | loss train:1.548884, test:1.063211 | lr:0.000000\n",
            "Epoch[5788/10000] | loss train:0.690708, test:0.188811 | lr:0.000000\n",
            "Epoch[5789/10000] | loss train:1.261046, test:0.710326 | lr:0.000000\n",
            "Epoch[5790/10000] | loss train:1.334973, test:0.122186 | lr:0.000000\n",
            "Epoch[5791/10000] | loss train:2.111689, test:0.534821 | lr:0.000000\n",
            "Epoch[5792/10000] | loss train:2.008053, test:0.476595 | lr:0.000000\n",
            "Epoch[5793/10000] | loss train:0.906276, test:1.315673 | lr:0.000000\n",
            "Epoch[5794/10000] | loss train:1.431576, test:0.576880 | lr:0.000000\n",
            "Epoch[5795/10000] | loss train:1.993899, test:0.650299 | lr:0.000000\n",
            "Epoch[5796/10000] | loss train:1.125060, test:0.538441 | lr:0.000000\n",
            "Epoch[5797/10000] | loss train:1.066644, test:0.662956 | lr:0.000000\n",
            "Epoch[5798/10000] | loss train:0.847918, test:0.098250 | lr:0.000000\n",
            "Epoch[5799/10000] | loss train:0.879114, test:0.688798 | lr:0.000000\n",
            "Epoch[5800/10000] | loss train:1.512382, test:2.534321 | lr:0.000000\n",
            "Epoch[5801/10000] | loss train:0.766767, test:0.433432 | lr:0.000000\n",
            "Epoch[5802/10000] | loss train:1.451500, test:0.232534 | lr:0.000000\n",
            "Epoch[5803/10000] | loss train:1.091342, test:0.341007 | lr:0.000000\n",
            "Epoch[5804/10000] | loss train:1.722694, test:0.705725 | lr:0.000000\n",
            "Epoch[5805/10000] | loss train:1.590942, test:0.716576 | lr:0.000000\n",
            "Epoch[5806/10000] | loss train:1.359266, test:0.584544 | lr:0.000000\n",
            "Epoch[5807/10000] | loss train:1.399202, test:1.054546 | lr:0.000000\n",
            "Epoch[5808/10000] | loss train:0.771143, test:0.311567 | lr:0.000000\n",
            "Epoch[5809/10000] | loss train:1.401969, test:1.545068 | lr:0.000000\n",
            "Epoch[5810/10000] | loss train:1.233888, test:0.546558 | lr:0.000000\n",
            "Epoch[5811/10000] | loss train:1.653991, test:0.701877 | lr:0.000000\n",
            "Epoch[5812/10000] | loss train:1.815638, test:0.138760 | lr:0.000000\n",
            "Epoch[5813/10000] | loss train:0.966340, test:1.161537 | lr:0.000000\n",
            "Epoch[5814/10000] | loss train:1.069322, test:0.357108 | lr:0.000000\n",
            "Epoch[5815/10000] | loss train:1.436172, test:1.911366 | lr:0.000000\n",
            "Epoch[5816/10000] | loss train:1.588457, test:0.277692 | lr:0.000000\n",
            "Epoch[5817/10000] | loss train:1.801148, test:0.786798 | lr:0.000000\n",
            "Epoch[5818/10000] | loss train:1.232474, test:0.244827 | lr:0.000000\n",
            "Epoch[5819/10000] | loss train:1.257587, test:0.341000 | lr:0.000000\n",
            "Epoch[5820/10000] | loss train:0.763521, test:0.566996 | lr:0.000000\n",
            "Epoch[5821/10000] | loss train:1.353987, test:0.957381 | lr:0.000000\n",
            "Epoch[5822/10000] | loss train:1.391501, test:1.718920 | lr:0.000000\n",
            "Epoch[5823/10000] | loss train:0.952591, test:1.147884 | lr:0.000000\n",
            "Epoch[5824/10000] | loss train:1.713993, test:0.433115 | lr:0.000000\n",
            "Epoch[5825/10000] | loss train:1.053302, test:0.534948 | lr:0.000000\n",
            "Epoch[5826/10000] | loss train:1.913105, test:0.936042 | lr:0.000000\n",
            "Epoch[5827/10000] | loss train:1.192313, test:0.491994 | lr:0.000000\n",
            "Epoch[5828/10000] | loss train:1.188891, test:0.167823 | lr:0.000000\n",
            "Epoch[5829/10000] | loss train:1.089171, test:0.232589 | lr:0.000000\n",
            "Epoch[5830/10000] | loss train:1.636629, test:1.405527 | lr:0.000000\n",
            "Epoch[5831/10000] | loss train:1.129142, test:0.564469 | lr:0.000000\n",
            "Epoch[5832/10000] | loss train:1.469816, test:0.272200 | lr:0.000000\n",
            "Epoch[5833/10000] | loss train:2.198429, test:1.067744 | lr:0.000000\n",
            "Epoch[5834/10000] | loss train:1.305802, test:0.545234 | lr:0.000000\n",
            "Epoch[5835/10000] | loss train:1.061673, test:0.192887 | lr:0.000000\n",
            "Epoch[5836/10000] | loss train:1.669014, test:1.063482 | lr:0.000000\n",
            "Epoch[5837/10000] | loss train:1.359126, test:0.243728 | lr:0.000000\n",
            "Epoch[5838/10000] | loss train:1.769678, test:0.382927 | lr:0.000000\n",
            "Epoch[5839/10000] | loss train:1.607228, test:0.604291 | lr:0.000000\n",
            "Epoch[5840/10000] | loss train:1.245126, test:2.171781 | lr:0.000000\n",
            "Epoch[5841/10000] | loss train:1.147186, test:1.421997 | lr:0.000000\n",
            "Epoch[5842/10000] | loss train:0.667948, test:1.129081 | lr:0.000000\n",
            "Epoch[5843/10000] | loss train:1.116547, test:1.617008 | lr:0.000000\n",
            "Epoch[5844/10000] | loss train:0.781672, test:0.172497 | lr:0.000000\n",
            "Epoch[5845/10000] | loss train:1.468810, test:0.379516 | lr:0.000000\n",
            "Epoch[5846/10000] | loss train:0.950452, test:0.164311 | lr:0.000000\n",
            "Epoch[5847/10000] | loss train:0.900818, test:0.291782 | lr:0.000000\n",
            "Epoch[5848/10000] | loss train:1.076306, test:0.346981 | lr:0.000000\n",
            "Epoch[5849/10000] | loss train:3.201803, test:0.594467 | lr:0.000000\n",
            "Epoch[5850/10000] | loss train:0.682486, test:0.183574 | lr:0.000000\n",
            "Epoch[5851/10000] | loss train:0.823264, test:1.165337 | lr:0.000000\n",
            "Epoch[5852/10000] | loss train:1.056449, test:1.226466 | lr:0.000000\n",
            "Epoch[5853/10000] | loss train:2.235208, test:0.763258 | lr:0.000000\n",
            "Epoch[5854/10000] | loss train:2.193530, test:0.273150 | lr:0.000000\n",
            "Epoch[5855/10000] | loss train:0.659312, test:0.399218 | lr:0.000000\n",
            "Epoch[5856/10000] | loss train:1.186533, test:1.637060 | lr:0.000000\n",
            "Epoch[5857/10000] | loss train:1.418168, test:0.291022 | lr:0.000000\n",
            "Epoch[5858/10000] | loss train:3.174651, test:1.258653 | lr:0.000000\n",
            "Epoch[5859/10000] | loss train:1.709855, test:1.051885 | lr:0.000000\n",
            "Epoch[5860/10000] | loss train:1.336555, test:1.909730 | lr:0.000000\n",
            "Epoch[5861/10000] | loss train:1.281628, test:0.140018 | lr:0.000000\n",
            "Epoch[5862/10000] | loss train:1.517621, test:0.276865 | lr:0.000000\n",
            "Epoch[5863/10000] | loss train:2.143848, test:0.430783 | lr:0.000000\n",
            "Epoch[5864/10000] | loss train:1.416760, test:1.355905 | lr:0.000000\n",
            "Epoch[5865/10000] | loss train:0.945266, test:0.789903 | lr:0.000000\n",
            "Epoch[5866/10000] | loss train:1.247394, test:0.218277 | lr:0.000000\n",
            "Epoch[5867/10000] | loss train:2.710150, test:0.863743 | lr:0.000000\n",
            "Epoch[5868/10000] | loss train:1.276058, test:1.582668 | lr:0.000000\n",
            "Epoch[5869/10000] | loss train:0.809241, test:1.344278 | lr:0.000000\n",
            "Epoch[5870/10000] | loss train:0.795019, test:0.463491 | lr:0.000000\n",
            "Epoch[5871/10000] | loss train:1.949635, test:0.429729 | lr:0.000000\n",
            "Epoch[5872/10000] | loss train:1.687270, test:0.507083 | lr:0.000000\n",
            "Epoch[5873/10000] | loss train:0.842456, test:0.691282 | lr:0.000000\n",
            "Epoch[5874/10000] | loss train:1.060480, test:0.118889 | lr:0.000000\n",
            "Epoch[5875/10000] | loss train:1.249537, test:0.478897 | lr:0.000000\n",
            "Epoch[5876/10000] | loss train:0.960823, test:1.293040 | lr:0.000000\n",
            "Epoch[5877/10000] | loss train:1.335813, test:0.146473 | lr:0.000000\n",
            "Epoch[5878/10000] | loss train:0.662972, test:0.104849 | lr:0.000000\n",
            "Epoch[5879/10000] | loss train:1.697972, test:1.448609 | lr:0.000000\n",
            "Epoch[5880/10000] | loss train:1.151144, test:2.108788 | lr:0.000000\n",
            "Epoch[5881/10000] | loss train:1.476562, test:0.930882 | lr:0.000000\n",
            "Epoch[5882/10000] | loss train:1.634143, test:0.763629 | lr:0.000000\n",
            "Epoch[5883/10000] | loss train:1.335644, test:0.121965 | lr:0.000000\n",
            "Epoch[5884/10000] | loss train:2.425960, test:0.163917 | lr:0.000000\n",
            "Epoch[5885/10000] | loss train:1.428722, test:0.311264 | lr:0.000000\n",
            "Epoch[5886/10000] | loss train:1.910959, test:0.467438 | lr:0.000000\n",
            "Epoch[5887/10000] | loss train:0.935386, test:0.157440 | lr:0.000000\n",
            "Epoch[5888/10000] | loss train:1.646963, test:0.783466 | lr:0.000000\n",
            "Epoch[5889/10000] | loss train:0.853769, test:1.143962 | lr:0.000000\n",
            "Epoch[5890/10000] | loss train:2.465392, test:1.022555 | lr:0.000000\n",
            "Epoch[5891/10000] | loss train:0.843615, test:0.355225 | lr:0.000000\n",
            "Epoch[5892/10000] | loss train:0.993892, test:0.966964 | lr:0.000000\n",
            "Epoch[5893/10000] | loss train:0.814663, test:0.513477 | lr:0.000000\n",
            "Epoch[5894/10000] | loss train:0.993278, test:0.332869 | lr:0.000000\n",
            "Epoch[5895/10000] | loss train:1.611368, test:0.530596 | lr:0.000000\n",
            "Epoch[5896/10000] | loss train:0.914781, test:0.302603 | lr:0.000000\n",
            "Epoch[5897/10000] | loss train:1.460676, test:0.333526 | lr:0.000000\n",
            "Epoch[5898/10000] | loss train:0.634481, test:0.714721 | lr:0.000000\n",
            "Epoch[5899/10000] | loss train:0.932851, test:0.318641 | lr:0.000000\n",
            "Epoch[5900/10000] | loss train:2.060843, test:0.737792 | lr:0.000000\n",
            "Epoch[5901/10000] | loss train:1.562566, test:0.251231 | lr:0.000000\n",
            "Epoch[5902/10000] | loss train:0.879577, test:0.210979 | lr:0.000000\n",
            "Epoch[5903/10000] | loss train:1.243556, test:0.787473 | lr:0.000000\n",
            "Epoch[5904/10000] | loss train:1.857788, test:0.158666 | lr:0.000000\n",
            "Epoch[5905/10000] | loss train:1.438966, test:1.254184 | lr:0.000000\n",
            "Epoch[5906/10000] | loss train:2.304635, test:0.249128 | lr:0.000000\n",
            "Epoch[5907/10000] | loss train:2.025243, test:1.094068 | lr:0.000000\n",
            "Epoch[5908/10000] | loss train:1.472627, test:0.258623 | lr:0.000000\n",
            "Epoch[5909/10000] | loss train:1.228089, test:0.718139 | lr:0.000000\n",
            "Epoch[5910/10000] | loss train:1.279210, test:1.225058 | lr:0.000000\n",
            "Epoch[5911/10000] | loss train:1.497954, test:0.232428 | lr:0.000000\n",
            "Epoch[5912/10000] | loss train:1.473533, test:0.353490 | lr:0.000000\n",
            "Epoch[5913/10000] | loss train:1.631219, test:0.126936 | lr:0.000000\n",
            "Epoch[5914/10000] | loss train:1.378477, test:0.637776 | lr:0.000000\n",
            "Epoch[5915/10000] | loss train:1.357651, test:0.618684 | lr:0.000000\n",
            "Epoch[5916/10000] | loss train:1.527082, test:0.501053 | lr:0.000000\n",
            "Epoch[5917/10000] | loss train:1.406643, test:0.489306 | lr:0.000000\n",
            "Epoch[5918/10000] | loss train:1.528863, test:0.743437 | lr:0.000000\n",
            "Epoch[5919/10000] | loss train:2.086473, test:0.237593 | lr:0.000000\n",
            "Epoch[5920/10000] | loss train:1.460809, test:0.907680 | lr:0.000000\n",
            "Epoch[5921/10000] | loss train:1.088157, test:0.490589 | lr:0.000000\n",
            "Epoch[5922/10000] | loss train:1.185265, test:0.430918 | lr:0.000000\n",
            "Epoch[5923/10000] | loss train:0.955057, test:1.910347 | lr:0.000000\n",
            "Epoch[5924/10000] | loss train:0.916902, test:1.058225 | lr:0.000000\n",
            "Epoch[5925/10000] | loss train:1.484057, test:0.590138 | lr:0.000000\n",
            "Epoch[5926/10000] | loss train:2.639543, test:0.266710 | lr:0.000000\n",
            "Epoch[5927/10000] | loss train:1.774392, test:0.166286 | lr:0.000000\n",
            "Epoch[5928/10000] | loss train:0.931152, test:0.342260 | lr:0.000000\n",
            "Epoch[5929/10000] | loss train:1.938617, test:0.126993 | lr:0.000000\n",
            "Epoch[5930/10000] | loss train:1.016723, test:0.513539 | lr:0.000000\n",
            "Epoch[5931/10000] | loss train:1.019565, test:0.126639 | lr:0.000000\n",
            "Epoch[5932/10000] | loss train:1.407493, test:0.095291 | lr:0.000000\n",
            "Epoch[5933/10000] | loss train:1.327345, test:0.396874 | lr:0.000000\n",
            "Epoch[5934/10000] | loss train:1.643842, test:0.264002 | lr:0.000000\n",
            "Epoch[5935/10000] | loss train:0.838222, test:0.903554 | lr:0.000000\n",
            "Epoch[5936/10000] | loss train:1.150964, test:1.328992 | lr:0.000000\n",
            "Epoch[5937/10000] | loss train:1.801955, test:1.417512 | lr:0.000000\n",
            "Epoch[5938/10000] | loss train:1.032188, test:2.030486 | lr:0.000000\n",
            "Epoch[5939/10000] | loss train:0.958517, test:0.057040 | lr:0.000000\n",
            "Epoch[5940/10000] | loss train:1.231743, test:0.597840 | lr:0.000000\n",
            "Epoch[5941/10000] | loss train:1.170968, test:1.123815 | lr:0.000000\n",
            "Epoch[5942/10000] | loss train:0.721583, test:0.694515 | lr:0.000000\n",
            "Epoch[5943/10000] | loss train:1.191443, test:0.256254 | lr:0.000000\n",
            "Epoch[5944/10000] | loss train:1.249101, test:0.292912 | lr:0.000000\n",
            "Epoch[5945/10000] | loss train:0.792787, test:0.287995 | lr:0.000000\n",
            "Epoch[5946/10000] | loss train:0.787467, test:0.841461 | lr:0.000000\n",
            "Epoch[5947/10000] | loss train:1.558812, test:0.526181 | lr:0.000000\n",
            "Epoch[5948/10000] | loss train:1.895621, test:0.267225 | lr:0.000000\n",
            "Epoch[5949/10000] | loss train:1.500467, test:0.609061 | lr:0.000000\n",
            "Epoch[5950/10000] | loss train:1.053967, test:0.496753 | lr:0.000000\n",
            "Epoch[5951/10000] | loss train:1.373667, test:0.101576 | lr:0.000000\n",
            "Epoch[5952/10000] | loss train:1.437152, test:0.311738 | lr:0.000000\n",
            "Epoch[5953/10000] | loss train:1.487472, test:0.850111 | lr:0.000000\n",
            "Epoch[5954/10000] | loss train:0.980128, test:0.221799 | lr:0.000000\n",
            "Epoch[5955/10000] | loss train:1.121418, test:0.674157 | lr:0.000000\n",
            "Epoch[5956/10000] | loss train:1.186398, test:0.192693 | lr:0.000000\n",
            "Epoch[5957/10000] | loss train:1.594532, test:1.026874 | lr:0.000000\n",
            "Epoch[5958/10000] | loss train:1.563651, test:0.375208 | lr:0.000000\n",
            "Epoch[5959/10000] | loss train:1.012333, test:0.641964 | lr:0.000000\n",
            "Epoch[5960/10000] | loss train:0.977404, test:0.211155 | lr:0.000000\n",
            "Epoch[5961/10000] | loss train:1.060405, test:0.505513 | lr:0.000000\n",
            "Epoch[5962/10000] | loss train:1.130069, test:0.252407 | lr:0.000000\n",
            "Epoch[5963/10000] | loss train:1.188536, test:0.262913 | lr:0.000000\n",
            "Epoch[5964/10000] | loss train:0.988371, test:0.235970 | lr:0.000000\n",
            "Epoch[5965/10000] | loss train:0.982933, test:0.581306 | lr:0.000000\n",
            "Epoch[5966/10000] | loss train:1.110112, test:0.438399 | lr:0.000000\n",
            "Epoch[5967/10000] | loss train:1.711251, test:0.153093 | lr:0.000000\n",
            "Epoch[5968/10000] | loss train:1.226726, test:0.458473 | lr:0.000000\n",
            "Epoch[5969/10000] | loss train:1.030499, test:0.960095 | lr:0.000000\n",
            "Epoch[5970/10000] | loss train:1.264811, test:1.173418 | lr:0.000000\n",
            "Epoch[5971/10000] | loss train:1.176395, test:0.236441 | lr:0.000000\n",
            "Epoch[5972/10000] | loss train:1.255084, test:1.132619 | lr:0.000000\n",
            "Epoch[5973/10000] | loss train:0.733573, test:0.234610 | lr:0.000000\n",
            "Epoch[5974/10000] | loss train:1.193946, test:1.199479 | lr:0.000000\n",
            "Epoch[5975/10000] | loss train:1.906559, test:0.442437 | lr:0.000000\n",
            "Epoch[5976/10000] | loss train:1.362541, test:0.446880 | lr:0.000000\n",
            "Epoch[5977/10000] | loss train:1.131094, test:0.166335 | lr:0.000000\n",
            "Epoch[5978/10000] | loss train:0.931008, test:0.436775 | lr:0.000000\n",
            "Epoch[5979/10000] | loss train:1.753506, test:0.052904 | lr:0.000000\n",
            "Epoch[5980/10000] | loss train:1.363097, test:0.496351 | lr:0.000000\n",
            "Epoch[5981/10000] | loss train:3.304922, test:1.035599 | lr:0.000000\n",
            "Epoch[5982/10000] | loss train:1.274665, test:0.233700 | lr:0.000000\n",
            "Epoch[5983/10000] | loss train:1.352954, test:1.467063 | lr:0.000000\n",
            "Epoch[5984/10000] | loss train:2.539826, test:0.898040 | lr:0.000000\n",
            "Epoch[5985/10000] | loss train:0.952868, test:0.195600 | lr:0.000000\n",
            "Epoch[5986/10000] | loss train:1.209938, test:0.237756 | lr:0.000000\n",
            "Epoch[5987/10000] | loss train:1.246053, test:0.771138 | lr:0.000000\n",
            "Epoch[5988/10000] | loss train:2.895430, test:1.734051 | lr:0.000000\n",
            "Epoch[5989/10000] | loss train:1.659233, test:1.182800 | lr:0.000000\n",
            "Epoch[5990/10000] | loss train:0.813061, test:1.225965 | lr:0.000000\n",
            "Epoch[5991/10000] | loss train:1.189120, test:1.369213 | lr:0.000000\n",
            "Epoch[5992/10000] | loss train:1.516934, test:1.025702 | lr:0.000000\n",
            "Epoch[5993/10000] | loss train:1.086593, test:0.841621 | lr:0.000000\n",
            "Epoch[5994/10000] | loss train:1.628877, test:0.220088 | lr:0.000000\n",
            "Epoch[5995/10000] | loss train:1.187478, test:1.615922 | lr:0.000000\n",
            "Epoch[5996/10000] | loss train:0.722476, test:1.379456 | lr:0.000000\n",
            "Epoch[5997/10000] | loss train:2.446517, test:0.369066 | lr:0.000000\n",
            "Epoch[5998/10000] | loss train:1.061993, test:0.512758 | lr:0.000000\n",
            "Epoch[5999/10000] | loss train:1.455286, test:0.418267 | lr:0.000000\n",
            "Epoch[6000/10000] | loss train:1.042963, test:0.166934 | lr:0.000000\n",
            "Epoch[6001/10000] | loss train:0.895692, test:0.898129 | lr:0.000000\n",
            "Epoch[6002/10000] | loss train:1.063611, test:0.430012 | lr:0.000000\n",
            "Epoch[6003/10000] | loss train:0.890184, test:0.657677 | lr:0.000000\n",
            "Epoch[6004/10000] | loss train:0.634047, test:0.326775 | lr:0.000000\n",
            "Epoch[6005/10000] | loss train:1.381562, test:0.269774 | lr:0.000000\n",
            "Epoch[6006/10000] | loss train:1.032809, test:0.987513 | lr:0.000000\n",
            "Epoch[6007/10000] | loss train:1.759421, test:1.216552 | lr:0.000000\n",
            "Epoch[6008/10000] | loss train:1.370388, test:0.698115 | lr:0.000000\n",
            "Epoch[6009/10000] | loss train:0.778942, test:0.295247 | lr:0.000000\n",
            "Epoch[6010/10000] | loss train:0.854881, test:0.727393 | lr:0.000000\n",
            "Epoch[6011/10000] | loss train:1.679537, test:0.113619 | lr:0.000000\n",
            "Epoch[6012/10000] | loss train:1.617795, test:0.720107 | lr:0.000000\n",
            "Epoch[6013/10000] | loss train:0.773081, test:0.341070 | lr:0.000000\n",
            "Epoch[6014/10000] | loss train:4.093960, test:0.285442 | lr:0.000000\n",
            "Epoch[6015/10000] | loss train:1.571909, test:1.347033 | lr:0.000000\n",
            "Epoch[6016/10000] | loss train:1.140546, test:0.450242 | lr:0.000000\n",
            "Epoch[6017/10000] | loss train:1.313085, test:0.216020 | lr:0.000000\n",
            "Epoch[6018/10000] | loss train:1.518089, test:1.275753 | lr:0.000000\n",
            "Epoch[6019/10000] | loss train:1.360382, test:1.823824 | lr:0.000000\n",
            "Epoch[6020/10000] | loss train:0.981833, test:0.226404 | lr:0.000000\n",
            "Epoch[6021/10000] | loss train:0.792335, test:0.829545 | lr:0.000000\n",
            "Epoch[6022/10000] | loss train:1.550831, test:0.593069 | lr:0.000000\n",
            "Epoch[6023/10000] | loss train:1.148156, test:0.391895 | lr:0.000000\n",
            "Epoch[6024/10000] | loss train:1.080042, test:0.258899 | lr:0.000000\n",
            "Epoch[6025/10000] | loss train:1.530342, test:0.447469 | lr:0.000000\n",
            "Epoch[6026/10000] | loss train:1.613895, test:0.954479 | lr:0.000000\n",
            "Epoch[6027/10000] | loss train:1.859107, test:0.299715 | lr:0.000000\n",
            "Epoch[6028/10000] | loss train:1.476684, test:0.898546 | lr:0.000000\n",
            "Epoch[6029/10000] | loss train:1.752544, test:1.064459 | lr:0.000000\n",
            "Epoch[6030/10000] | loss train:1.046755, test:0.976940 | lr:0.000000\n",
            "Epoch[6031/10000] | loss train:2.121561, test:1.697887 | lr:0.000000\n",
            "Epoch[6032/10000] | loss train:1.318253, test:0.442581 | lr:0.000000\n",
            "Epoch[6033/10000] | loss train:0.994736, test:0.416423 | lr:0.000000\n",
            "Epoch[6034/10000] | loss train:2.008096, test:0.460986 | lr:0.000000\n",
            "Epoch[6035/10000] | loss train:1.555909, test:0.376289 | lr:0.000000\n",
            "Epoch[6036/10000] | loss train:1.877424, test:0.399434 | lr:0.000000\n",
            "Epoch[6037/10000] | loss train:0.570877, test:0.579958 | lr:0.000000\n",
            "Epoch[6038/10000] | loss train:1.766211, test:0.512806 | lr:0.000000\n",
            "Epoch[6039/10000] | loss train:1.208847, test:1.558854 | lr:0.000000\n",
            "Epoch[6040/10000] | loss train:1.023870, test:0.872917 | lr:0.000000\n",
            "Epoch[6041/10000] | loss train:1.607380, test:0.318337 | lr:0.000000\n",
            "Epoch[6042/10000] | loss train:2.979517, test:0.303361 | lr:0.000000\n",
            "Epoch[6043/10000] | loss train:1.348854, test:0.366623 | lr:0.000000\n",
            "Epoch[6044/10000] | loss train:0.896054, test:2.039055 | lr:0.000000\n",
            "Epoch[6045/10000] | loss train:0.671464, test:0.689530 | lr:0.000000\n",
            "Epoch[6046/10000] | loss train:0.928843, test:0.882310 | lr:0.000000\n",
            "Epoch[6047/10000] | loss train:0.783665, test:0.672500 | lr:0.000000\n",
            "Epoch[6048/10000] | loss train:1.961554, test:0.463678 | lr:0.000000\n",
            "Epoch[6049/10000] | loss train:1.192104, test:0.176445 | lr:0.000000\n",
            "Epoch[6050/10000] | loss train:1.041647, test:0.833916 | lr:0.000000\n",
            "Epoch[6051/10000] | loss train:0.830837, test:0.200568 | lr:0.000000\n",
            "Epoch[6052/10000] | loss train:1.220365, test:0.257062 | lr:0.000000\n",
            "Epoch[6053/10000] | loss train:1.195228, test:0.662253 | lr:0.000000\n",
            "Epoch[6054/10000] | loss train:0.792542, test:0.957650 | lr:0.000000\n",
            "Epoch[6055/10000] | loss train:0.895733, test:0.740159 | lr:0.000000\n",
            "Epoch[6056/10000] | loss train:1.145241, test:0.427078 | lr:0.000000\n",
            "Epoch[6057/10000] | loss train:1.690860, test:1.444733 | lr:0.000000\n",
            "Epoch[6058/10000] | loss train:0.901425, test:0.827511 | lr:0.000000\n",
            "Epoch[6059/10000] | loss train:0.690336, test:0.233425 | lr:0.000000\n",
            "Epoch[6060/10000] | loss train:1.285640, test:1.046677 | lr:0.000000\n",
            "Epoch[6061/10000] | loss train:1.364615, test:0.061776 | lr:0.000000\n",
            "Epoch[6062/10000] | loss train:0.784693, test:0.542093 | lr:0.000000\n",
            "Epoch[6063/10000] | loss train:1.461012, test:0.089509 | lr:0.000000\n",
            "Epoch[6064/10000] | loss train:0.664344, test:1.368617 | lr:0.000000\n",
            "Epoch[6065/10000] | loss train:0.734350, test:0.464101 | lr:0.000000\n",
            "Epoch[6066/10000] | loss train:0.777167, test:0.445180 | lr:0.000000\n",
            "Epoch[6067/10000] | loss train:1.100340, test:0.168385 | lr:0.000000\n",
            "Epoch[6068/10000] | loss train:0.953581, test:0.443903 | lr:0.000000\n",
            "Epoch[6069/10000] | loss train:1.763783, test:0.384580 | lr:0.000000\n",
            "Epoch[6070/10000] | loss train:0.915171, test:0.230040 | lr:0.000000\n",
            "Epoch[6071/10000] | loss train:2.116075, test:0.637354 | lr:0.000000\n",
            "Epoch[6072/10000] | loss train:0.912114, test:0.357314 | lr:0.000000\n",
            "Epoch[6073/10000] | loss train:2.703579, test:1.697550 | lr:0.000000\n",
            "Epoch[6074/10000] | loss train:0.879651, test:0.908987 | lr:0.000000\n",
            "Epoch[6075/10000] | loss train:1.626007, test:1.301312 | lr:0.000000\n",
            "Epoch[6076/10000] | loss train:0.887619, test:0.270178 | lr:0.000000\n",
            "Epoch[6077/10000] | loss train:0.910851, test:0.632662 | lr:0.000000\n",
            "Epoch[6078/10000] | loss train:1.140670, test:0.713209 | lr:0.000000\n",
            "Epoch[6079/10000] | loss train:1.371048, test:0.763286 | lr:0.000000\n",
            "Epoch[6080/10000] | loss train:0.837454, test:0.712835 | lr:0.000000\n",
            "Epoch[6081/10000] | loss train:1.279640, test:0.628914 | lr:0.000000\n",
            "Epoch[6082/10000] | loss train:1.731727, test:0.477393 | lr:0.000000\n",
            "Epoch[6083/10000] | loss train:1.038450, test:0.919567 | lr:0.000000\n",
            "Epoch[6084/10000] | loss train:1.814318, test:0.927720 | lr:0.000000\n",
            "Epoch[6085/10000] | loss train:0.831879, test:0.510380 | lr:0.000000\n",
            "Epoch[6086/10000] | loss train:0.767940, test:0.627992 | lr:0.000000\n",
            "Epoch[6087/10000] | loss train:1.092537, test:0.089454 | lr:0.000000\n",
            "Epoch[6088/10000] | loss train:0.705068, test:0.291794 | lr:0.000000\n",
            "Epoch[6089/10000] | loss train:1.151201, test:0.538772 | lr:0.000000\n",
            "Epoch[6090/10000] | loss train:1.412121, test:0.147065 | lr:0.000000\n",
            "Epoch[6091/10000] | loss train:1.456772, test:0.253690 | lr:0.000000\n",
            "Epoch[6092/10000] | loss train:1.646091, test:1.084261 | lr:0.000000\n",
            "Epoch[6093/10000] | loss train:2.696379, test:0.343910 | lr:0.000000\n",
            "Epoch[6094/10000] | loss train:0.856871, test:0.488466 | lr:0.000000\n",
            "Epoch[6095/10000] | loss train:1.138003, test:1.330892 | lr:0.000000\n",
            "Epoch[6096/10000] | loss train:0.875762, test:1.127985 | lr:0.000000\n",
            "Epoch[6097/10000] | loss train:1.265991, test:0.857195 | lr:0.000000\n",
            "Epoch[6098/10000] | loss train:1.164815, test:1.061053 | lr:0.000000\n",
            "Epoch[6099/10000] | loss train:0.854891, test:0.280652 | lr:0.000000\n",
            "Epoch[6100/10000] | loss train:1.568018, test:0.202788 | lr:0.000000\n",
            "Epoch[6101/10000] | loss train:1.455477, test:0.583658 | lr:0.000000\n",
            "Epoch[6102/10000] | loss train:1.176969, test:1.258451 | lr:0.000000\n",
            "Epoch[6103/10000] | loss train:1.210553, test:0.945075 | lr:0.000000\n",
            "Epoch[6104/10000] | loss train:1.309069, test:1.336185 | lr:0.000000\n",
            "Epoch[6105/10000] | loss train:0.827587, test:1.060525 | lr:0.000000\n",
            "Epoch[6106/10000] | loss train:0.868523, test:1.122675 | lr:0.000000\n",
            "Epoch[6107/10000] | loss train:1.134800, test:0.617695 | lr:0.000000\n",
            "Epoch[6108/10000] | loss train:1.288089, test:0.687623 | lr:0.000000\n",
            "Epoch[6109/10000] | loss train:1.197533, test:1.488750 | lr:0.000000\n",
            "Epoch[6110/10000] | loss train:1.878237, test:0.848515 | lr:0.000000\n",
            "Epoch[6111/10000] | loss train:1.034987, test:2.212919 | lr:0.000000\n",
            "Epoch[6112/10000] | loss train:0.722799, test:0.667428 | lr:0.000000\n",
            "Epoch[6113/10000] | loss train:0.667528, test:0.172559 | lr:0.000000\n",
            "Epoch[6114/10000] | loss train:0.978797, test:0.830870 | lr:0.000000\n",
            "Epoch[6115/10000] | loss train:0.840437, test:0.210171 | lr:0.000000\n",
            "Epoch[6116/10000] | loss train:0.928473, test:0.447572 | lr:0.000000\n",
            "Epoch[6117/10000] | loss train:0.995922, test:0.988828 | lr:0.000000\n",
            "Epoch[6118/10000] | loss train:0.725288, test:0.422562 | lr:0.000000\n",
            "Epoch[6119/10000] | loss train:0.959164, test:0.143178 | lr:0.000000\n",
            "Epoch[6120/10000] | loss train:2.114586, test:0.099027 | lr:0.000000\n",
            "Epoch[6121/10000] | loss train:0.944819, test:0.295888 | lr:0.000000\n",
            "Epoch[6122/10000] | loss train:1.510786, test:0.050902 | lr:0.000000\n",
            "Epoch[6123/10000] | loss train:1.289625, test:0.253308 | lr:0.000000\n",
            "Epoch[6124/10000] | loss train:1.572417, test:1.593449 | lr:0.000000\n",
            "Epoch[6125/10000] | loss train:1.636776, test:0.336011 | lr:0.000000\n",
            "Epoch[6126/10000] | loss train:1.306353, test:0.340755 | lr:0.000000\n",
            "Epoch[6127/10000] | loss train:1.475426, test:1.022435 | lr:0.000000\n",
            "Epoch[6128/10000] | loss train:1.276580, test:0.480294 | lr:0.000000\n",
            "Epoch[6129/10000] | loss train:1.054867, test:0.521822 | lr:0.000000\n",
            "Epoch[6130/10000] | loss train:0.722926, test:0.146607 | lr:0.000000\n",
            "Epoch[6131/10000] | loss train:1.579654, test:0.561485 | lr:0.000000\n",
            "Epoch[6132/10000] | loss train:1.459272, test:0.699294 | lr:0.000000\n",
            "Epoch[6133/10000] | loss train:1.119681, test:0.639921 | lr:0.000000\n",
            "Epoch[6134/10000] | loss train:1.658127, test:0.255571 | lr:0.000000\n",
            "Epoch[6135/10000] | loss train:1.042592, test:0.962481 | lr:0.000000\n",
            "Epoch[6136/10000] | loss train:1.292893, test:1.416926 | lr:0.000000\n",
            "Epoch[6137/10000] | loss train:1.702669, test:0.538479 | lr:0.000000\n",
            "Epoch[6138/10000] | loss train:1.121416, test:0.711660 | lr:0.000000\n",
            "Epoch[6139/10000] | loss train:0.770546, test:0.682070 | lr:0.000000\n",
            "Epoch[6140/10000] | loss train:0.984839, test:2.143104 | lr:0.000000\n",
            "Epoch[6141/10000] | loss train:1.297274, test:0.522115 | lr:0.000000\n",
            "Epoch[6142/10000] | loss train:0.841041, test:0.705689 | lr:0.000000\n",
            "Epoch[6143/10000] | loss train:0.946750, test:0.365557 | lr:0.000000\n",
            "Epoch[6144/10000] | loss train:0.658783, test:0.587640 | lr:0.000000\n",
            "Epoch[6145/10000] | loss train:1.529971, test:0.257105 | lr:0.000000\n",
            "Epoch[6146/10000] | loss train:2.213573, test:1.157811 | lr:0.000000\n",
            "Epoch[6147/10000] | loss train:1.537682, test:1.954818 | lr:0.000000\n",
            "Epoch[6148/10000] | loss train:1.220778, test:0.182079 | lr:0.000000\n",
            "Epoch[6149/10000] | loss train:0.940821, test:0.229860 | lr:0.000000\n",
            "Epoch[6150/10000] | loss train:1.144727, test:1.409991 | lr:0.000000\n",
            "Epoch[6151/10000] | loss train:1.133907, test:0.322396 | lr:0.000000\n",
            "Epoch[6152/10000] | loss train:0.808786, test:0.234022 | lr:0.000000\n",
            "Epoch[6153/10000] | loss train:0.730440, test:0.113945 | lr:0.000000\n",
            "Epoch[6154/10000] | loss train:1.913043, test:0.272209 | lr:0.000000\n",
            "Epoch[6155/10000] | loss train:1.985561, test:0.677442 | lr:0.000000\n",
            "Epoch[6156/10000] | loss train:1.170792, test:0.605821 | lr:0.000000\n",
            "Epoch[6157/10000] | loss train:1.607057, test:0.461288 | lr:0.000000\n",
            "Epoch[6158/10000] | loss train:1.056018, test:0.227645 | lr:0.000000\n",
            "Epoch[6159/10000] | loss train:0.673764, test:0.145497 | lr:0.000000\n",
            "Epoch[6160/10000] | loss train:1.190323, test:0.479716 | lr:0.000000\n",
            "Epoch[6161/10000] | loss train:1.177188, test:0.190625 | lr:0.000000\n",
            "Epoch[6162/10000] | loss train:1.785574, test:0.301434 | lr:0.000000\n",
            "Epoch[6163/10000] | loss train:0.981213, test:0.223995 | lr:0.000000\n",
            "Epoch[6164/10000] | loss train:1.129489, test:1.429116 | lr:0.000000\n",
            "Epoch[6165/10000] | loss train:1.437559, test:1.225154 | lr:0.000000\n",
            "Epoch[6166/10000] | loss train:1.978335, test:0.663372 | lr:0.000000\n",
            "Epoch[6167/10000] | loss train:1.134745, test:0.477557 | lr:0.000000\n",
            "Epoch[6168/10000] | loss train:1.592610, test:1.067173 | lr:0.000000\n",
            "Epoch[6169/10000] | loss train:0.930978, test:0.222087 | lr:0.000000\n",
            "Epoch[6170/10000] | loss train:0.864353, test:0.414498 | lr:0.000000\n",
            "Epoch[6171/10000] | loss train:1.283384, test:0.150098 | lr:0.000000\n",
            "Epoch[6172/10000] | loss train:1.074230, test:0.913693 | lr:0.000000\n",
            "Epoch[6173/10000] | loss train:1.222889, test:0.386752 | lr:0.000000\n",
            "Epoch[6174/10000] | loss train:2.334603, test:0.906092 | lr:0.000000\n",
            "Epoch[6175/10000] | loss train:1.244770, test:1.177788 | lr:0.000000\n",
            "Epoch[6176/10000] | loss train:1.206951, test:0.339101 | lr:0.000000\n",
            "Epoch[6177/10000] | loss train:0.887683, test:1.275689 | lr:0.000000\n",
            "Epoch[6178/10000] | loss train:1.351127, test:1.836437 | lr:0.000000\n",
            "Epoch[6179/10000] | loss train:0.737701, test:1.138207 | lr:0.000000\n",
            "Epoch[6180/10000] | loss train:1.203493, test:1.706223 | lr:0.000000\n",
            "Epoch[6181/10000] | loss train:0.780232, test:0.049431 | lr:0.000000\n",
            "Epoch[6182/10000] | loss train:1.681371, test:0.287461 | lr:0.000000\n",
            "Epoch[6183/10000] | loss train:1.974771, test:0.138948 | lr:0.000000\n",
            "Epoch[6184/10000] | loss train:1.759810, test:0.275894 | lr:0.000000\n",
            "Epoch[6185/10000] | loss train:1.444865, test:0.165290 | lr:0.000000\n",
            "Epoch[6186/10000] | loss train:0.885281, test:0.945569 | lr:0.000000\n",
            "Epoch[6187/10000] | loss train:0.653053, test:0.285199 | lr:0.000000\n",
            "Epoch[6188/10000] | loss train:1.121926, test:0.126116 | lr:0.000000\n",
            "Epoch[6189/10000] | loss train:0.945497, test:0.198402 | lr:0.000000\n",
            "Epoch[6190/10000] | loss train:1.123998, test:0.390782 | lr:0.000000\n",
            "Epoch[6191/10000] | loss train:1.535030, test:0.170544 | lr:0.000000\n",
            "Epoch[6192/10000] | loss train:1.215894, test:0.863750 | lr:0.000000\n",
            "Epoch[6193/10000] | loss train:1.340547, test:1.131447 | lr:0.000000\n",
            "Epoch[6194/10000] | loss train:1.020835, test:1.189191 | lr:0.000000\n",
            "Epoch[6195/10000] | loss train:0.898403, test:0.370079 | lr:0.000000\n",
            "Epoch[6196/10000] | loss train:1.326284, test:0.166774 | lr:0.000000\n",
            "Epoch[6197/10000] | loss train:1.668984, test:0.743471 | lr:0.000000\n",
            "Epoch[6198/10000] | loss train:1.933456, test:0.658082 | lr:0.000000\n",
            "Epoch[6199/10000] | loss train:1.460450, test:0.448209 | lr:0.000000\n",
            "Epoch[6200/10000] | loss train:2.449676, test:1.443841 | lr:0.000000\n",
            "Epoch[6201/10000] | loss train:1.176595, test:0.273123 | lr:0.000000\n",
            "Epoch[6202/10000] | loss train:2.220784, test:0.278831 | lr:0.000000\n",
            "Epoch[6203/10000] | loss train:0.746349, test:0.273648 | lr:0.000000\n",
            "Epoch[6204/10000] | loss train:1.990490, test:0.493608 | lr:0.000000\n",
            "Epoch[6205/10000] | loss train:1.708694, test:1.066860 | lr:0.000000\n",
            "Epoch[6206/10000] | loss train:0.843921, test:1.152222 | lr:0.000000\n",
            "Epoch[6207/10000] | loss train:1.693247, test:0.673950 | lr:0.000000\n",
            "Epoch[6208/10000] | loss train:1.374977, test:0.706960 | lr:0.000000\n",
            "Epoch[6209/10000] | loss train:1.713655, test:0.335941 | lr:0.000000\n",
            "Epoch[6210/10000] | loss train:1.225759, test:0.271925 | lr:0.000000\n",
            "Epoch[6211/10000] | loss train:1.173769, test:0.666676 | lr:0.000000\n",
            "Epoch[6212/10000] | loss train:1.414153, test:1.812482 | lr:0.000000\n",
            "Epoch[6213/10000] | loss train:0.765702, test:0.241114 | lr:0.000000\n",
            "Epoch[6214/10000] | loss train:0.962334, test:0.884799 | lr:0.000000\n",
            "Epoch[6215/10000] | loss train:1.824926, test:1.160725 | lr:0.000000\n",
            "Epoch[6216/10000] | loss train:1.086943, test:2.802480 | lr:0.000000\n",
            "Epoch[6217/10000] | loss train:1.722190, test:0.722119 | lr:0.000000\n",
            "Epoch[6218/10000] | loss train:1.157975, test:0.188719 | lr:0.000000\n",
            "Epoch[6219/10000] | loss train:1.350759, test:0.457954 | lr:0.000000\n",
            "Epoch[6220/10000] | loss train:0.802131, test:0.248229 | lr:0.000000\n",
            "Epoch[6221/10000] | loss train:1.268071, test:0.423186 | lr:0.000000\n",
            "Epoch[6222/10000] | loss train:1.006734, test:0.287006 | lr:0.000000\n",
            "Epoch[6223/10000] | loss train:1.178738, test:0.918227 | lr:0.000000\n",
            "Epoch[6224/10000] | loss train:1.279516, test:0.210357 | lr:0.000000\n",
            "Epoch[6225/10000] | loss train:0.796525, test:0.383997 | lr:0.000000\n",
            "Epoch[6226/10000] | loss train:0.937651, test:0.185034 | lr:0.000000\n",
            "Epoch[6227/10000] | loss train:1.453005, test:1.433611 | lr:0.000000\n",
            "Epoch[6228/10000] | loss train:1.791507, test:0.924630 | lr:0.000000\n",
            "Epoch[6229/10000] | loss train:1.114322, test:0.748785 | lr:0.000000\n",
            "Epoch[6230/10000] | loss train:0.912247, test:0.277484 | lr:0.000000\n",
            "Epoch[6231/10000] | loss train:1.145376, test:0.174621 | lr:0.000000\n",
            "Epoch[6232/10000] | loss train:0.913502, test:0.784572 | lr:0.000000\n",
            "Epoch[6233/10000] | loss train:1.256516, test:3.052899 | lr:0.000000\n",
            "Epoch[6234/10000] | loss train:1.146279, test:0.165659 | lr:0.000000\n",
            "Epoch[6235/10000] | loss train:0.967680, test:0.770931 | lr:0.000000\n",
            "Epoch[6236/10000] | loss train:0.937184, test:0.128093 | lr:0.000000\n",
            "Epoch[6237/10000] | loss train:1.330711, test:1.288250 | lr:0.000000\n",
            "Epoch[6238/10000] | loss train:1.538055, test:0.577132 | lr:0.000000\n",
            "Epoch[6239/10000] | loss train:1.875124, test:0.182188 | lr:0.000000\n",
            "Epoch[6240/10000] | loss train:0.986844, test:1.219082 | lr:0.000000\n",
            "Epoch[6241/10000] | loss train:1.242627, test:0.466226 | lr:0.000000\n",
            "Epoch[6242/10000] | loss train:0.800281, test:0.478287 | lr:0.000000\n",
            "Epoch[6243/10000] | loss train:1.715142, test:0.207023 | lr:0.000000\n",
            "Epoch[6244/10000] | loss train:0.901035, test:0.236035 | lr:0.000000\n",
            "Epoch[6245/10000] | loss train:1.076173, test:0.371122 | lr:0.000000\n",
            "Epoch[6246/10000] | loss train:1.426209, test:0.419137 | lr:0.000000\n",
            "Epoch[6247/10000] | loss train:1.733392, test:0.910775 | lr:0.000000\n",
            "Epoch[6248/10000] | loss train:1.501368, test:1.320143 | lr:0.000000\n",
            "Epoch[6249/10000] | loss train:0.712901, test:0.642837 | lr:0.000000\n",
            "Epoch[6250/10000] | loss train:1.211454, test:0.300216 | lr:0.000000\n",
            "Epoch[6251/10000] | loss train:1.041031, test:0.244539 | lr:0.000000\n",
            "Epoch[6252/10000] | loss train:1.518378, test:0.451992 | lr:0.000000\n",
            "Epoch[6253/10000] | loss train:1.352336, test:0.955854 | lr:0.000000\n",
            "Epoch[6254/10000] | loss train:2.188595, test:0.429933 | lr:0.000000\n",
            "Epoch[6255/10000] | loss train:1.284650, test:1.285856 | lr:0.000000\n",
            "Epoch[6256/10000] | loss train:1.077132, test:0.353869 | lr:0.000000\n",
            "Epoch[6257/10000] | loss train:0.822434, test:0.232585 | lr:0.000000\n",
            "Epoch[6258/10000] | loss train:1.380884, test:0.649988 | lr:0.000000\n",
            "Epoch[6259/10000] | loss train:1.697410, test:0.838682 | lr:0.000000\n",
            "Epoch[6260/10000] | loss train:1.361945, test:0.520829 | lr:0.000000\n",
            "Epoch[6261/10000] | loss train:1.361771, test:0.358691 | lr:0.000000\n",
            "Epoch[6262/10000] | loss train:1.692145, test:1.844680 | lr:0.000000\n",
            "Epoch[6263/10000] | loss train:2.192791, test:1.745755 | lr:0.000000\n",
            "Epoch[6264/10000] | loss train:0.673279, test:1.430322 | lr:0.000000\n",
            "Epoch[6265/10000] | loss train:2.563409, test:0.573342 | lr:0.000000\n",
            "Epoch[6266/10000] | loss train:0.916808, test:0.817413 | lr:0.000000\n",
            "Epoch[6267/10000] | loss train:1.134155, test:0.615516 | lr:0.000000\n",
            "Epoch[6268/10000] | loss train:1.488443, test:0.321911 | lr:0.000000\n",
            "Epoch[6269/10000] | loss train:1.166058, test:2.293286 | lr:0.000000\n",
            "Epoch[6270/10000] | loss train:1.145766, test:0.213250 | lr:0.000000\n",
            "Epoch[6271/10000] | loss train:3.041919, test:0.373255 | lr:0.000000\n",
            "Epoch[6272/10000] | loss train:1.047073, test:0.388806 | lr:0.000000\n",
            "Epoch[6273/10000] | loss train:2.687536, test:0.769705 | lr:0.000000\n",
            "Epoch[6274/10000] | loss train:1.329167, test:0.518969 | lr:0.000000\n",
            "Epoch[6275/10000] | loss train:0.817758, test:0.102102 | lr:0.000000\n",
            "Epoch[6276/10000] | loss train:1.157183, test:0.249467 | lr:0.000000\n",
            "Epoch[6277/10000] | loss train:0.868929, test:0.188494 | lr:0.000000\n",
            "Epoch[6278/10000] | loss train:2.209892, test:1.883531 | lr:0.000000\n",
            "Epoch[6279/10000] | loss train:1.344606, test:0.202626 | lr:0.000000\n",
            "Epoch[6280/10000] | loss train:1.362507, test:0.936279 | lr:0.000000\n",
            "Epoch[6281/10000] | loss train:1.265221, test:0.166478 | lr:0.000000\n",
            "Epoch[6282/10000] | loss train:0.899199, test:0.330318 | lr:0.000000\n",
            "Epoch[6283/10000] | loss train:1.033068, test:0.510158 | lr:0.000000\n",
            "Epoch[6284/10000] | loss train:1.503793, test:1.283790 | lr:0.000000\n",
            "Epoch[6285/10000] | loss train:1.051854, test:0.210950 | lr:0.000000\n",
            "Epoch[6286/10000] | loss train:0.908247, test:0.528064 | lr:0.000000\n",
            "Epoch[6287/10000] | loss train:1.364130, test:0.297170 | lr:0.000000\n",
            "Epoch[6288/10000] | loss train:1.062068, test:0.399248 | lr:0.000000\n",
            "Epoch[6289/10000] | loss train:2.513353, test:0.361643 | lr:0.000000\n",
            "Epoch[6290/10000] | loss train:0.832433, test:0.902058 | lr:0.000000\n",
            "Epoch[6291/10000] | loss train:1.123326, test:1.499330 | lr:0.000000\n",
            "Epoch[6292/10000] | loss train:2.268849, test:1.491859 | lr:0.000000\n",
            "Epoch[6293/10000] | loss train:1.261660, test:0.323230 | lr:0.000000\n",
            "Epoch[6294/10000] | loss train:1.193554, test:0.600731 | lr:0.000000\n",
            "Epoch[6295/10000] | loss train:1.766341, test:0.176277 | lr:0.000000\n",
            "Epoch[6296/10000] | loss train:2.093486, test:0.789079 | lr:0.000000\n",
            "Epoch[6297/10000] | loss train:1.261056, test:1.829079 | lr:0.000000\n",
            "Epoch[6298/10000] | loss train:0.858622, test:0.432670 | lr:0.000000\n",
            "Epoch[6299/10000] | loss train:1.013714, test:0.397813 | lr:0.000000\n",
            "Epoch[6300/10000] | loss train:1.006966, test:0.379054 | lr:0.000000\n",
            "Epoch[6301/10000] | loss train:0.785501, test:0.083886 | lr:0.000000\n",
            "Epoch[6302/10000] | loss train:0.953988, test:0.716998 | lr:0.000000\n",
            "Epoch[6303/10000] | loss train:1.028709, test:0.163975 | lr:0.000000\n",
            "Epoch[6304/10000] | loss train:1.734690, test:0.421932 | lr:0.000000\n",
            "Epoch[6305/10000] | loss train:1.786136, test:0.558098 | lr:0.000000\n",
            "Epoch[6306/10000] | loss train:1.977000, test:1.662983 | lr:0.000000\n",
            "Epoch[6307/10000] | loss train:1.746664, test:1.216486 | lr:0.000000\n",
            "Epoch[6308/10000] | loss train:0.723475, test:0.983562 | lr:0.000000\n",
            "Epoch[6309/10000] | loss train:1.318981, test:0.051017 | lr:0.000000\n",
            "Epoch[6310/10000] | loss train:1.164344, test:1.018490 | lr:0.000000\n",
            "Epoch[6311/10000] | loss train:1.126147, test:0.610552 | lr:0.000000\n",
            "Epoch[6312/10000] | loss train:1.006071, test:0.556377 | lr:0.000000\n",
            "Epoch[6313/10000] | loss train:1.081548, test:0.163284 | lr:0.000000\n",
            "Epoch[6314/10000] | loss train:0.969196, test:0.259438 | lr:0.000000\n",
            "Epoch[6315/10000] | loss train:0.643322, test:0.252243 | lr:0.000000\n",
            "Epoch[6316/10000] | loss train:0.925503, test:1.988573 | lr:0.000000\n",
            "Epoch[6317/10000] | loss train:0.648643, test:0.588242 | lr:0.000000\n",
            "Epoch[6318/10000] | loss train:1.421537, test:2.429168 | lr:0.000000\n",
            "Epoch[6319/10000] | loss train:1.089784, test:0.524068 | lr:0.000000\n",
            "Epoch[6320/10000] | loss train:0.866740, test:2.269549 | lr:0.000000\n",
            "Epoch[6321/10000] | loss train:1.290052, test:1.138579 | lr:0.000000\n",
            "Epoch[6322/10000] | loss train:1.178589, test:0.746537 | lr:0.000000\n",
            "Epoch[6323/10000] | loss train:0.725210, test:0.394269 | lr:0.000000\n",
            "Epoch[6324/10000] | loss train:1.504520, test:0.292865 | lr:0.000000\n",
            "Epoch[6325/10000] | loss train:1.880864, test:0.132733 | lr:0.000000\n",
            "Epoch[6326/10000] | loss train:1.168591, test:0.136631 | lr:0.000000\n",
            "Epoch[6327/10000] | loss train:2.052578, test:1.042927 | lr:0.000000\n",
            "Epoch[6328/10000] | loss train:0.942814, test:0.518261 | lr:0.000000\n",
            "Epoch[6329/10000] | loss train:1.138471, test:0.376543 | lr:0.000000\n",
            "Epoch[6330/10000] | loss train:1.176810, test:0.881507 | lr:0.000000\n",
            "Epoch[6331/10000] | loss train:1.360076, test:2.074670 | lr:0.000000\n",
            "Epoch[6332/10000] | loss train:0.813197, test:0.232090 | lr:0.000000\n",
            "Epoch[6333/10000] | loss train:1.678612, test:1.967986 | lr:0.000000\n",
            "Epoch[6334/10000] | loss train:2.462047, test:0.637197 | lr:0.000000\n",
            "Epoch[6335/10000] | loss train:1.489479, test:0.656007 | lr:0.000000\n",
            "Epoch[6336/10000] | loss train:1.003023, test:1.165566 | lr:0.000000\n",
            "Epoch[6337/10000] | loss train:1.015401, test:0.623547 | lr:0.000000\n",
            "Epoch[6338/10000] | loss train:1.206804, test:0.714276 | lr:0.000000\n",
            "Epoch[6339/10000] | loss train:1.537317, test:0.959890 | lr:0.000000\n",
            "Epoch[6340/10000] | loss train:0.948217, test:0.934313 | lr:0.000000\n",
            "Epoch[6341/10000] | loss train:2.352345, test:0.421120 | lr:0.000000\n",
            "Epoch[6342/10000] | loss train:1.493520, test:0.082263 | lr:0.000000\n",
            "Epoch[6343/10000] | loss train:1.451096, test:1.298050 | lr:0.000000\n",
            "Epoch[6344/10000] | loss train:1.336399, test:0.476763 | lr:0.000000\n",
            "Epoch[6345/10000] | loss train:1.421750, test:0.177334 | lr:0.000000\n",
            "Epoch[6346/10000] | loss train:0.806562, test:0.460070 | lr:0.000000\n",
            "Epoch[6347/10000] | loss train:0.923999, test:0.446141 | lr:0.000000\n",
            "Epoch[6348/10000] | loss train:1.053447, test:0.675440 | lr:0.000000\n",
            "Epoch[6349/10000] | loss train:1.533106, test:0.137761 | lr:0.000000\n",
            "Epoch[6350/10000] | loss train:1.885164, test:1.066591 | lr:0.000000\n",
            "Epoch[6351/10000] | loss train:1.179121, test:1.007209 | lr:0.000000\n",
            "Epoch[6352/10000] | loss train:1.121553, test:0.209709 | lr:0.000000\n",
            "Epoch[6353/10000] | loss train:1.004153, test:1.043935 | lr:0.000000\n",
            "Epoch[6354/10000] | loss train:1.564245, test:0.241328 | lr:0.000000\n",
            "Epoch[6355/10000] | loss train:1.133457, test:0.077538 | lr:0.000000\n",
            "Epoch[6356/10000] | loss train:1.063454, test:0.656232 | lr:0.000000\n",
            "Epoch[6357/10000] | loss train:0.846861, test:0.484910 | lr:0.000000\n",
            "Epoch[6358/10000] | loss train:0.939354, test:0.779478 | lr:0.000000\n",
            "Epoch[6359/10000] | loss train:1.594567, test:0.344604 | lr:0.000000\n",
            "Epoch[6360/10000] | loss train:1.241275, test:1.434800 | lr:0.000000\n",
            "Epoch[6361/10000] | loss train:1.416594, test:0.933437 | lr:0.000000\n",
            "Epoch[6362/10000] | loss train:2.278202, test:0.240351 | lr:0.000000\n",
            "Epoch[6363/10000] | loss train:0.769244, test:0.688499 | lr:0.000000\n",
            "Epoch[6364/10000] | loss train:0.707445, test:0.362255 | lr:0.000000\n",
            "Epoch[6365/10000] | loss train:1.244365, test:0.509298 | lr:0.000000\n",
            "Epoch[6366/10000] | loss train:0.841680, test:0.299445 | lr:0.000000\n",
            "Epoch[6367/10000] | loss train:1.369291, test:0.584756 | lr:0.000000\n",
            "Epoch[6368/10000] | loss train:1.201370, test:0.258204 | lr:0.000000\n",
            "Epoch[6369/10000] | loss train:0.766913, test:0.331622 | lr:0.000000\n",
            "Epoch[6370/10000] | loss train:2.178644, test:0.421319 | lr:0.000000\n",
            "Epoch[6371/10000] | loss train:1.668539, test:0.544897 | lr:0.000000\n",
            "Epoch[6372/10000] | loss train:0.976479, test:1.476234 | lr:0.000000\n",
            "Epoch[6373/10000] | loss train:1.161361, test:0.175375 | lr:0.000000\n",
            "Epoch[6374/10000] | loss train:1.875872, test:0.275140 | lr:0.000000\n",
            "Epoch[6375/10000] | loss train:1.222082, test:1.472329 | lr:0.000000\n",
            "Epoch[6376/10000] | loss train:1.776587, test:0.056871 | lr:0.000000\n",
            "Epoch[6377/10000] | loss train:1.398799, test:0.175500 | lr:0.000000\n",
            "Epoch[6378/10000] | loss train:1.614347, test:0.619618 | lr:0.000000\n",
            "Epoch[6379/10000] | loss train:1.331127, test:0.333186 | lr:0.000000\n",
            "Epoch[6380/10000] | loss train:1.072807, test:0.556024 | lr:0.000000\n",
            "Epoch[6381/10000] | loss train:0.793788, test:0.217245 | lr:0.000000\n",
            "Epoch[6382/10000] | loss train:1.455094, test:0.163484 | lr:0.000000\n",
            "Epoch[6383/10000] | loss train:1.192604, test:0.922361 | lr:0.000000\n",
            "Epoch[6384/10000] | loss train:1.009148, test:0.973904 | lr:0.000000\n",
            "Epoch[6385/10000] | loss train:1.245832, test:0.453301 | lr:0.000000\n",
            "Epoch[6386/10000] | loss train:0.643510, test:0.333190 | lr:0.000000\n",
            "Epoch[6387/10000] | loss train:1.228401, test:0.652725 | lr:0.000000\n",
            "Epoch[6388/10000] | loss train:1.231066, test:1.313375 | lr:0.000000\n",
            "Epoch[6389/10000] | loss train:0.913667, test:0.286364 | lr:0.000000\n",
            "Epoch[6390/10000] | loss train:2.069179, test:0.655963 | lr:0.000000\n",
            "Epoch[6391/10000] | loss train:1.106915, test:0.408723 | lr:0.000000\n",
            "Epoch[6392/10000] | loss train:1.281490, test:0.814674 | lr:0.000000\n",
            "Epoch[6393/10000] | loss train:1.048369, test:0.129162 | lr:0.000000\n",
            "Epoch[6394/10000] | loss train:1.426435, test:0.381506 | lr:0.000000\n",
            "Epoch[6395/10000] | loss train:1.434419, test:0.106697 | lr:0.000000\n",
            "Epoch[6396/10000] | loss train:0.914076, test:1.078936 | lr:0.000000\n",
            "Epoch[6397/10000] | loss train:1.095786, test:0.354888 | lr:0.000000\n",
            "Epoch[6398/10000] | loss train:0.729827, test:0.171596 | lr:0.000000\n",
            "Epoch[6399/10000] | loss train:1.465956, test:0.336536 | lr:0.000000\n",
            "Epoch[6400/10000] | loss train:0.756288, test:0.924163 | lr:0.000000\n",
            "Epoch[6401/10000] | loss train:0.888141, test:0.235764 | lr:0.000000\n",
            "Epoch[6402/10000] | loss train:1.400649, test:0.519907 | lr:0.000000\n",
            "Epoch[6403/10000] | loss train:1.221607, test:1.809554 | lr:0.000000\n",
            "Epoch[6404/10000] | loss train:1.475053, test:0.619285 | lr:0.000000\n",
            "Epoch[6405/10000] | loss train:2.756665, test:0.172312 | lr:0.000000\n",
            "Epoch[6406/10000] | loss train:1.896551, test:0.566283 | lr:0.000000\n",
            "Epoch[6407/10000] | loss train:0.993004, test:1.160996 | lr:0.000000\n",
            "Epoch[6408/10000] | loss train:1.227833, test:0.239911 | lr:0.000000\n",
            "Epoch[6409/10000] | loss train:1.191453, test:0.783372 | lr:0.000000\n",
            "Epoch[6410/10000] | loss train:1.449622, test:0.470853 | lr:0.000000\n",
            "Epoch[6411/10000] | loss train:1.279167, test:0.931406 | lr:0.000000\n",
            "Epoch[6412/10000] | loss train:1.592665, test:0.535346 | lr:0.000000\n",
            "Epoch[6413/10000] | loss train:1.772092, test:0.150644 | lr:0.000000\n",
            "Epoch[6414/10000] | loss train:1.882427, test:0.158339 | lr:0.000000\n",
            "Epoch[6415/10000] | loss train:1.117959, test:1.039362 | lr:0.000000\n",
            "Epoch[6416/10000] | loss train:0.841455, test:0.729879 | lr:0.000000\n",
            "Epoch[6417/10000] | loss train:1.080455, test:0.494065 | lr:0.000000\n",
            "Epoch[6418/10000] | loss train:0.810401, test:1.201915 | lr:0.000000\n",
            "Epoch[6419/10000] | loss train:2.184881, test:0.520364 | lr:0.000000\n",
            "Epoch[6420/10000] | loss train:1.376389, test:0.720607 | lr:0.000000\n",
            "Epoch[6421/10000] | loss train:2.029249, test:0.981057 | lr:0.000000\n",
            "Epoch[6422/10000] | loss train:1.500733, test:1.024858 | lr:0.000000\n",
            "Epoch[6423/10000] | loss train:0.805681, test:1.157847 | lr:0.000000\n",
            "Epoch[6424/10000] | loss train:1.853818, test:0.676436 | lr:0.000000\n",
            "Epoch[6425/10000] | loss train:0.769707, test:0.519432 | lr:0.000000\n",
            "Epoch[6426/10000] | loss train:1.331614, test:3.282879 | lr:0.000000\n",
            "Epoch[6427/10000] | loss train:1.355036, test:0.477126 | lr:0.000000\n",
            "Epoch[6428/10000] | loss train:1.648399, test:1.111751 | lr:0.000000\n",
            "Epoch[6429/10000] | loss train:1.339884, test:0.237968 | lr:0.000000\n",
            "Epoch[6430/10000] | loss train:1.431358, test:0.185123 | lr:0.000000\n",
            "Epoch[6431/10000] | loss train:1.542232, test:0.289373 | lr:0.000000\n",
            "Epoch[6432/10000] | loss train:0.897401, test:0.414515 | lr:0.000000\n",
            "Epoch[6433/10000] | loss train:2.095164, test:1.261053 | lr:0.000000\n",
            "Epoch[6434/10000] | loss train:1.086780, test:0.447469 | lr:0.000000\n",
            "Epoch[6435/10000] | loss train:1.705328, test:0.280584 | lr:0.000000\n",
            "Epoch[6436/10000] | loss train:2.005154, test:0.428641 | lr:0.000000\n",
            "Epoch[6437/10000] | loss train:0.823660, test:0.165720 | lr:0.000000\n",
            "Epoch[6438/10000] | loss train:1.316820, test:0.518381 | lr:0.000000\n",
            "Epoch[6439/10000] | loss train:0.648170, test:1.304549 | lr:0.000000\n",
            "Epoch[6440/10000] | loss train:2.494431, test:0.119485 | lr:0.000000\n",
            "Epoch[6441/10000] | loss train:1.033548, test:2.128375 | lr:0.000000\n",
            "Epoch[6442/10000] | loss train:0.719631, test:0.415056 | lr:0.000000\n",
            "Epoch[6443/10000] | loss train:0.875277, test:0.591554 | lr:0.000000\n",
            "Epoch[6444/10000] | loss train:0.680002, test:0.170391 | lr:0.000000\n",
            "Epoch[6445/10000] | loss train:2.255091, test:0.635108 | lr:0.000000\n",
            "Epoch[6446/10000] | loss train:1.362804, test:0.909768 | lr:0.000000\n",
            "Epoch[6447/10000] | loss train:0.739613, test:0.537183 | lr:0.000000\n",
            "Epoch[6448/10000] | loss train:1.548568, test:0.235493 | lr:0.000000\n",
            "Epoch[6449/10000] | loss train:1.305703, test:0.116641 | lr:0.000000\n",
            "Epoch[6450/10000] | loss train:1.278348, test:0.736552 | lr:0.000000\n",
            "Epoch[6451/10000] | loss train:1.414896, test:1.551681 | lr:0.000000\n",
            "Epoch[6452/10000] | loss train:0.873390, test:0.442513 | lr:0.000000\n",
            "Epoch[6453/10000] | loss train:1.349418, test:0.533223 | lr:0.000000\n",
            "Epoch[6454/10000] | loss train:1.654353, test:0.664197 | lr:0.000000\n",
            "Epoch[6455/10000] | loss train:1.546745, test:0.393309 | lr:0.000000\n",
            "Epoch[6456/10000] | loss train:1.111017, test:1.277071 | lr:0.000000\n",
            "Epoch[6457/10000] | loss train:1.203239, test:0.401348 | lr:0.000000\n",
            "Epoch[6458/10000] | loss train:1.033524, test:1.153363 | lr:0.000000\n",
            "Epoch[6459/10000] | loss train:1.651911, test:0.268655 | lr:0.000000\n",
            "Epoch[6460/10000] | loss train:1.526958, test:1.761387 | lr:0.000000\n",
            "Epoch[6461/10000] | loss train:1.133275, test:0.968489 | lr:0.000000\n",
            "Epoch[6462/10000] | loss train:1.051446, test:1.175051 | lr:0.000000\n",
            "Epoch[6463/10000] | loss train:0.834388, test:0.249835 | lr:0.000000\n",
            "Epoch[6464/10000] | loss train:1.238692, test:1.256320 | lr:0.000000\n",
            "Epoch[6465/10000] | loss train:1.723798, test:0.887260 | lr:0.000000\n",
            "Epoch[6466/10000] | loss train:0.967589, test:1.091825 | lr:0.000000\n",
            "Epoch[6467/10000] | loss train:0.860852, test:1.672778 | lr:0.000000\n",
            "Epoch[6468/10000] | loss train:0.938043, test:0.717044 | lr:0.000000\n",
            "Epoch[6469/10000] | loss train:1.139497, test:1.247728 | lr:0.000000\n",
            "Epoch[6470/10000] | loss train:0.760173, test:2.163886 | lr:0.000000\n",
            "Epoch[6471/10000] | loss train:1.232461, test:0.159828 | lr:0.000000\n",
            "Epoch[6472/10000] | loss train:1.141481, test:0.554862 | lr:0.000000\n",
            "Epoch[6473/10000] | loss train:1.866111, test:1.338650 | lr:0.000000\n",
            "Epoch[6474/10000] | loss train:1.739689, test:0.122687 | lr:0.000000\n",
            "Epoch[6475/10000] | loss train:2.025739, test:0.414063 | lr:0.000000\n",
            "Epoch[6476/10000] | loss train:1.939182, test:0.607269 | lr:0.000000\n",
            "Epoch[6477/10000] | loss train:0.980308, test:0.355339 | lr:0.000000\n",
            "Epoch[6478/10000] | loss train:2.706379, test:0.490106 | lr:0.000000\n",
            "Epoch[6479/10000] | loss train:2.475830, test:0.181785 | lr:0.000000\n",
            "Epoch[6480/10000] | loss train:1.443021, test:0.543513 | lr:0.000000\n",
            "Epoch[6481/10000] | loss train:1.685053, test:0.980070 | lr:0.000000\n",
            "Epoch[6482/10000] | loss train:0.759782, test:0.290661 | lr:0.000000\n",
            "Epoch[6483/10000] | loss train:1.340061, test:1.693500 | lr:0.000000\n",
            "Epoch[6484/10000] | loss train:0.730949, test:0.538209 | lr:0.000000\n",
            "Epoch[6485/10000] | loss train:0.812388, test:0.337395 | lr:0.000000\n",
            "Epoch[6486/10000] | loss train:1.248581, test:0.494079 | lr:0.000000\n",
            "Epoch[6487/10000] | loss train:1.611882, test:0.271192 | lr:0.000000\n",
            "Epoch[6488/10000] | loss train:1.029633, test:0.966475 | lr:0.000000\n",
            "Epoch[6489/10000] | loss train:0.990587, test:0.269096 | lr:0.000000\n",
            "Epoch[6490/10000] | loss train:0.958435, test:0.338369 | lr:0.000000\n",
            "Epoch[6491/10000] | loss train:0.982615, test:0.316221 | lr:0.000000\n",
            "Epoch[6492/10000] | loss train:0.896918, test:0.980513 | lr:0.000000\n",
            "Epoch[6493/10000] | loss train:1.444730, test:0.151473 | lr:0.000000\n",
            "Epoch[6494/10000] | loss train:0.853248, test:1.183239 | lr:0.000000\n",
            "Epoch[6495/10000] | loss train:0.747242, test:0.141694 | lr:0.000000\n",
            "Epoch[6496/10000] | loss train:0.772398, test:0.613778 | lr:0.000000\n",
            "Epoch[6497/10000] | loss train:1.332995, test:0.209527 | lr:0.000000\n",
            "Epoch[6498/10000] | loss train:1.024723, test:0.409730 | lr:0.000000\n",
            "Epoch[6499/10000] | loss train:1.450861, test:0.822732 | lr:0.000000\n",
            "Epoch[6500/10000] | loss train:1.149146, test:0.188235 | lr:0.000000\n",
            "Epoch[6501/10000] | loss train:1.438862, test:1.275796 | lr:0.000000\n",
            "Epoch[6502/10000] | loss train:0.946834, test:0.568743 | lr:0.000000\n",
            "Epoch[6503/10000] | loss train:0.826177, test:0.949332 | lr:0.000000\n",
            "Epoch[6504/10000] | loss train:1.285567, test:0.298654 | lr:0.000000\n",
            "Epoch[6505/10000] | loss train:1.637192, test:0.674817 | lr:0.000000\n",
            "Epoch[6506/10000] | loss train:0.723344, test:0.234560 | lr:0.000000\n",
            "Epoch[6507/10000] | loss train:0.906732, test:0.212605 | lr:0.000000\n",
            "Epoch[6508/10000] | loss train:1.281887, test:0.486537 | lr:0.000000\n",
            "Epoch[6509/10000] | loss train:0.786476, test:0.619578 | lr:0.000000\n",
            "Epoch[6510/10000] | loss train:1.375383, test:0.607246 | lr:0.000000\n",
            "Epoch[6511/10000] | loss train:0.952796, test:1.168415 | lr:0.000000\n",
            "Epoch[6512/10000] | loss train:1.514470, test:0.249572 | lr:0.000000\n",
            "Epoch[6513/10000] | loss train:1.147060, test:0.253466 | lr:0.000000\n",
            "Epoch[6514/10000] | loss train:1.791435, test:0.133854 | lr:0.000000\n",
            "Epoch[6515/10000] | loss train:1.076471, test:0.056889 | lr:0.000000\n",
            "Epoch[6516/10000] | loss train:0.824364, test:0.410055 | lr:0.000000\n",
            "Epoch[6517/10000] | loss train:0.933648, test:1.852698 | lr:0.000000\n",
            "Epoch[6518/10000] | loss train:1.292415, test:0.623537 | lr:0.000000\n",
            "Epoch[6519/10000] | loss train:1.222638, test:0.360968 | lr:0.000000\n",
            "Epoch[6520/10000] | loss train:1.439104, test:1.121168 | lr:0.000000\n",
            "Epoch[6521/10000] | loss train:0.730455, test:0.166787 | lr:0.000000\n",
            "Epoch[6522/10000] | loss train:1.939238, test:1.143156 | lr:0.000000\n",
            "Epoch[6523/10000] | loss train:1.586086, test:0.125956 | lr:0.000000\n",
            "Epoch[6524/10000] | loss train:1.460531, test:0.833049 | lr:0.000000\n",
            "Epoch[6525/10000] | loss train:1.389814, test:0.393402 | lr:0.000000\n",
            "Epoch[6526/10000] | loss train:1.328384, test:0.248866 | lr:0.000000\n",
            "Epoch[6527/10000] | loss train:1.277858, test:0.994126 | lr:0.000000\n",
            "Epoch[6528/10000] | loss train:2.830091, test:0.339089 | lr:0.000000\n",
            "Epoch[6529/10000] | loss train:1.310800, test:0.755409 | lr:0.000000\n",
            "Epoch[6530/10000] | loss train:0.920811, test:1.745355 | lr:0.000000\n",
            "Epoch[6531/10000] | loss train:0.619314, test:0.942296 | lr:0.000000\n",
            "Epoch[6532/10000] | loss train:0.754342, test:0.833429 | lr:0.000000\n",
            "Epoch[6533/10000] | loss train:2.934346, test:0.230831 | lr:0.000000\n",
            "Epoch[6534/10000] | loss train:0.977889, test:0.917379 | lr:0.000000\n",
            "Epoch[6535/10000] | loss train:1.231153, test:0.610263 | lr:0.000000\n",
            "Epoch[6536/10000] | loss train:1.261549, test:0.484668 | lr:0.000000\n",
            "Epoch[6537/10000] | loss train:0.976512, test:0.629134 | lr:0.000000\n",
            "Epoch[6538/10000] | loss train:0.656992, test:0.539815 | lr:0.000000\n",
            "Epoch[6539/10000] | loss train:1.298988, test:0.212090 | lr:0.000000\n",
            "Epoch[6540/10000] | loss train:0.626433, test:0.302325 | lr:0.000000\n",
            "Epoch[6541/10000] | loss train:1.583451, test:0.247417 | lr:0.000000\n",
            "Epoch[6542/10000] | loss train:2.049719, test:1.443485 | lr:0.000000\n",
            "Epoch[6543/10000] | loss train:0.748638, test:1.564243 | lr:0.000000\n",
            "Epoch[6544/10000] | loss train:0.959413, test:0.321169 | lr:0.000000\n",
            "Epoch[6545/10000] | loss train:1.121863, test:0.340636 | lr:0.000000\n",
            "Epoch[6546/10000] | loss train:1.272978, test:0.161277 | lr:0.000000\n",
            "Epoch[6547/10000] | loss train:1.079986, test:1.529282 | lr:0.000000\n",
            "Epoch[6548/10000] | loss train:0.977527, test:0.624058 | lr:0.000000\n",
            "Epoch[6549/10000] | loss train:1.316739, test:0.296695 | lr:0.000000\n",
            "Epoch[6550/10000] | loss train:0.752662, test:0.101648 | lr:0.000000\n",
            "Epoch[6551/10000] | loss train:1.315582, test:0.772955 | lr:0.000000\n",
            "Epoch[6552/10000] | loss train:1.170060, test:0.326965 | lr:0.000000\n",
            "Epoch[6553/10000] | loss train:1.703058, test:0.360281 | lr:0.000000\n",
            "Epoch[6554/10000] | loss train:0.662029, test:0.654272 | lr:0.000000\n",
            "Epoch[6555/10000] | loss train:0.877250, test:1.400739 | lr:0.000000\n",
            "Epoch[6556/10000] | loss train:1.181537, test:0.154109 | lr:0.000000\n",
            "Epoch[6557/10000] | loss train:2.001585, test:0.371021 | lr:0.000000\n",
            "Epoch[6558/10000] | loss train:0.720047, test:0.473427 | lr:0.000000\n",
            "Epoch[6559/10000] | loss train:1.194739, test:0.343446 | lr:0.000000\n",
            "Epoch[6560/10000] | loss train:1.189841, test:0.599061 | lr:0.000000\n",
            "Epoch[6561/10000] | loss train:1.877328, test:0.229998 | lr:0.000000\n",
            "Epoch[6562/10000] | loss train:1.069896, test:0.922935 | lr:0.000000\n",
            "Epoch[6563/10000] | loss train:1.957272, test:1.311666 | lr:0.000000\n",
            "Epoch[6564/10000] | loss train:1.469523, test:0.244172 | lr:0.000000\n",
            "Epoch[6565/10000] | loss train:1.045925, test:1.069131 | lr:0.000000\n",
            "Epoch[6566/10000] | loss train:0.854417, test:0.622767 | lr:0.000000\n",
            "Epoch[6567/10000] | loss train:0.848905, test:0.431445 | lr:0.000000\n",
            "Epoch[6568/10000] | loss train:0.933127, test:1.656173 | lr:0.000000\n",
            "Epoch[6569/10000] | loss train:1.465114, test:0.944757 | lr:0.000000\n",
            "Epoch[6570/10000] | loss train:1.020115, test:0.293645 | lr:0.000000\n",
            "Epoch[6571/10000] | loss train:0.850606, test:0.052808 | lr:0.000000\n",
            "Epoch[6572/10000] | loss train:3.255430, test:1.213724 | lr:0.000000\n",
            "Epoch[6573/10000] | loss train:1.209147, test:1.151235 | lr:0.000000\n",
            "Epoch[6574/10000] | loss train:1.502915, test:0.109983 | lr:0.000000\n",
            "Epoch[6575/10000] | loss train:1.014070, test:0.685879 | lr:0.000000\n",
            "Epoch[6576/10000] | loss train:1.651998, test:0.175806 | lr:0.000000\n",
            "Epoch[6577/10000] | loss train:0.931469, test:0.262706 | lr:0.000000\n",
            "Epoch[6578/10000] | loss train:1.329059, test:0.257239 | lr:0.000000\n",
            "Epoch[6579/10000] | loss train:1.729775, test:1.939837 | lr:0.000000\n",
            "Epoch[6580/10000] | loss train:0.726079, test:0.183544 | lr:0.000000\n",
            "Epoch[6581/10000] | loss train:0.756326, test:0.699763 | lr:0.000000\n",
            "Epoch[6582/10000] | loss train:1.525750, test:0.495230 | lr:0.000000\n",
            "Epoch[6583/10000] | loss train:1.974647, test:0.798711 | lr:0.000000\n",
            "Epoch[6584/10000] | loss train:0.722466, test:0.339559 | lr:0.000000\n",
            "Epoch[6585/10000] | loss train:1.037986, test:0.680686 | lr:0.000000\n",
            "Epoch[6586/10000] | loss train:1.384634, test:0.174761 | lr:0.000000\n",
            "Epoch[6587/10000] | loss train:1.503036, test:0.292319 | lr:0.000000\n",
            "Epoch[6588/10000] | loss train:1.057173, test:0.966881 | lr:0.000000\n",
            "Epoch[6589/10000] | loss train:0.729403, test:1.774399 | lr:0.000000\n",
            "Epoch[6590/10000] | loss train:1.215812, test:0.865263 | lr:0.000000\n",
            "Epoch[6591/10000] | loss train:1.247455, test:0.290268 | lr:0.000000\n",
            "Epoch[6592/10000] | loss train:1.948243, test:1.170188 | lr:0.000000\n",
            "Epoch[6593/10000] | loss train:0.920723, test:0.302296 | lr:0.000000\n",
            "Epoch[6594/10000] | loss train:1.068740, test:0.725128 | lr:0.000000\n",
            "Epoch[6595/10000] | loss train:1.305654, test:0.286528 | lr:0.000000\n",
            "Epoch[6596/10000] | loss train:1.610641, test:0.944172 | lr:0.000000\n",
            "Epoch[6597/10000] | loss train:1.997152, test:0.420746 | lr:0.000000\n",
            "Epoch[6598/10000] | loss train:1.029008, test:0.676029 | lr:0.000000\n",
            "Epoch[6599/10000] | loss train:0.869023, test:0.094637 | lr:0.000000\n",
            "Epoch[6600/10000] | loss train:0.987115, test:0.304027 | lr:0.000000\n",
            "Epoch[6601/10000] | loss train:1.112176, test:2.191653 | lr:0.000000\n",
            "Epoch[6602/10000] | loss train:1.352224, test:0.241254 | lr:0.000000\n",
            "Epoch[6603/10000] | loss train:1.320825, test:0.371356 | lr:0.000000\n",
            "Epoch[6604/10000] | loss train:1.668651, test:1.224369 | lr:0.000000\n",
            "Epoch[6605/10000] | loss train:1.431321, test:0.935831 | lr:0.000000\n",
            "Epoch[6606/10000] | loss train:0.978586, test:0.345089 | lr:0.000000\n",
            "Epoch[6607/10000] | loss train:1.508684, test:0.277887 | lr:0.000000\n",
            "Epoch[6608/10000] | loss train:0.718528, test:0.519160 | lr:0.000000\n",
            "Epoch[6609/10000] | loss train:0.945754, test:0.282804 | lr:0.000000\n",
            "Epoch[6610/10000] | loss train:2.562191, test:0.393691 | lr:0.000000\n",
            "Epoch[6611/10000] | loss train:1.476735, test:0.610477 | lr:0.000000\n",
            "Epoch[6612/10000] | loss train:1.229576, test:0.648050 | lr:0.000000\n",
            "Epoch[6613/10000] | loss train:1.705067, test:1.044171 | lr:0.000000\n",
            "Epoch[6614/10000] | loss train:1.290362, test:0.452335 | lr:0.000000\n",
            "Epoch[6615/10000] | loss train:2.945810, test:3.243524 | lr:0.000000\n",
            "Epoch[6616/10000] | loss train:0.896669, test:0.282789 | lr:0.000000\n",
            "Epoch[6617/10000] | loss train:0.958131, test:0.709603 | lr:0.000000\n",
            "Epoch[6618/10000] | loss train:1.423929, test:1.284818 | lr:0.000000\n",
            "Epoch[6619/10000] | loss train:1.027728, test:0.304993 | lr:0.000000\n",
            "Epoch[6620/10000] | loss train:1.162246, test:0.547952 | lr:0.000000\n",
            "Epoch[6621/10000] | loss train:1.432314, test:1.461998 | lr:0.000000\n",
            "Epoch[6622/10000] | loss train:1.569342, test:0.870610 | lr:0.000000\n",
            "Epoch[6623/10000] | loss train:1.764981, test:0.148492 | lr:0.000000\n",
            "Epoch[6624/10000] | loss train:2.780369, test:0.526833 | lr:0.000000\n",
            "Epoch[6625/10000] | loss train:1.196526, test:0.107501 | lr:0.000000\n",
            "Epoch[6626/10000] | loss train:1.368403, test:0.633522 | lr:0.000000\n",
            "Epoch[6627/10000] | loss train:2.097534, test:0.439242 | lr:0.000000\n",
            "Epoch[6628/10000] | loss train:1.238391, test:1.024940 | lr:0.000000\n",
            "Epoch[6629/10000] | loss train:0.968399, test:1.271381 | lr:0.000000\n",
            "Epoch[6630/10000] | loss train:1.635031, test:0.819616 | lr:0.000000\n",
            "Epoch[6631/10000] | loss train:1.022322, test:0.805422 | lr:0.000000\n",
            "Epoch[6632/10000] | loss train:0.861769, test:0.282535 | lr:0.000000\n",
            "Epoch[6633/10000] | loss train:1.854777, test:0.317775 | lr:0.000000\n",
            "Epoch[6634/10000] | loss train:1.528837, test:1.365395 | lr:0.000000\n",
            "Epoch[6635/10000] | loss train:1.253592, test:0.315448 | lr:0.000000\n",
            "Epoch[6636/10000] | loss train:1.261076, test:0.193853 | lr:0.000000\n",
            "Epoch[6637/10000] | loss train:1.758668, test:0.731069 | lr:0.000000\n",
            "Epoch[6638/10000] | loss train:1.002905, test:0.928304 | lr:0.000000\n",
            "Epoch[6639/10000] | loss train:0.829021, test:0.208831 | lr:0.000000\n",
            "Epoch[6640/10000] | loss train:1.305287, test:1.525844 | lr:0.000000\n",
            "Epoch[6641/10000] | loss train:1.664699, test:0.779718 | lr:0.000000\n",
            "Epoch[6642/10000] | loss train:1.143643, test:0.334335 | lr:0.000000\n",
            "Epoch[6643/10000] | loss train:0.766038, test:0.747271 | lr:0.000000\n",
            "Epoch[6644/10000] | loss train:0.994873, test:0.365906 | lr:0.000000\n",
            "Epoch[6645/10000] | loss train:0.735962, test:0.560789 | lr:0.000000\n",
            "Epoch[6646/10000] | loss train:1.098995, test:0.276974 | lr:0.000000\n",
            "Epoch[6647/10000] | loss train:2.476238, test:1.313092 | lr:0.000000\n",
            "Epoch[6648/10000] | loss train:1.689592, test:0.285472 | lr:0.000000\n",
            "Epoch[6649/10000] | loss train:1.074189, test:1.502009 | lr:0.000000\n",
            "Epoch[6650/10000] | loss train:2.293842, test:0.621748 | lr:0.000000\n",
            "Epoch[6651/10000] | loss train:1.435989, test:0.313164 | lr:0.000000\n",
            "Epoch[6652/10000] | loss train:2.702212, test:0.657269 | lr:0.000000\n",
            "Epoch[6653/10000] | loss train:0.779665, test:1.254276 | lr:0.000000\n",
            "Epoch[6654/10000] | loss train:1.246185, test:0.950716 | lr:0.000000\n",
            "Epoch[6655/10000] | loss train:1.290848, test:0.263507 | lr:0.000000\n",
            "Epoch[6656/10000] | loss train:1.639811, test:0.214892 | lr:0.000000\n",
            "Epoch[6657/10000] | loss train:1.320912, test:0.716387 | lr:0.000000\n",
            "Epoch[6658/10000] | loss train:0.924104, test:0.149172 | lr:0.000000\n",
            "Epoch[6659/10000] | loss train:1.070881, test:0.246645 | lr:0.000000\n",
            "Epoch[6660/10000] | loss train:1.696190, test:0.669208 | lr:0.000000\n",
            "Epoch[6661/10000] | loss train:2.724791, test:0.175424 | lr:0.000000\n",
            "Epoch[6662/10000] | loss train:1.237803, test:0.200365 | lr:0.000000\n",
            "Epoch[6663/10000] | loss train:0.799658, test:0.692087 | lr:0.000000\n",
            "Epoch[6664/10000] | loss train:0.943815, test:0.465840 | lr:0.000000\n",
            "Epoch[6665/10000] | loss train:0.977837, test:0.263638 | lr:0.000000\n",
            "Epoch[6666/10000] | loss train:0.977694, test:1.364823 | lr:0.000000\n",
            "Epoch[6667/10000] | loss train:1.262579, test:0.360968 | lr:0.000000\n",
            "Epoch[6668/10000] | loss train:1.421252, test:0.432038 | lr:0.000000\n",
            "Epoch[6669/10000] | loss train:1.745232, test:0.236865 | lr:0.000000\n",
            "Epoch[6670/10000] | loss train:0.858785, test:0.515618 | lr:0.000000\n",
            "Epoch[6671/10000] | loss train:1.054012, test:1.112892 | lr:0.000000\n",
            "Epoch[6672/10000] | loss train:0.973552, test:0.303519 | lr:0.000000\n",
            "Epoch[6673/10000] | loss train:0.905551, test:1.803872 | lr:0.000000\n",
            "Epoch[6674/10000] | loss train:1.096357, test:0.307046 | lr:0.000000\n",
            "Epoch[6675/10000] | loss train:1.481362, test:1.398528 | lr:0.000000\n",
            "Epoch[6676/10000] | loss train:0.746889, test:0.143052 | lr:0.000000\n",
            "Epoch[6677/10000] | loss train:1.732297, test:0.367308 | lr:0.000000\n",
            "Epoch[6678/10000] | loss train:1.986239, test:0.445040 | lr:0.000000\n",
            "Epoch[6679/10000] | loss train:2.233700, test:1.352420 | lr:0.000000\n",
            "Epoch[6680/10000] | loss train:1.317034, test:0.235233 | lr:0.000000\n",
            "Epoch[6681/10000] | loss train:2.654394, test:0.339016 | lr:0.000000\n",
            "Epoch[6682/10000] | loss train:1.025661, test:1.840846 | lr:0.000000\n",
            "Epoch[6683/10000] | loss train:1.429098, test:0.334515 | lr:0.000000\n",
            "Epoch[6684/10000] | loss train:1.495650, test:0.308248 | lr:0.000000\n",
            "Epoch[6685/10000] | loss train:1.189184, test:0.304611 | lr:0.000000\n",
            "Epoch[6686/10000] | loss train:1.302486, test:1.171153 | lr:0.000000\n",
            "Epoch[6687/10000] | loss train:0.798681, test:0.757411 | lr:0.000000\n",
            "Epoch[6688/10000] | loss train:1.050540, test:0.657447 | lr:0.000000\n",
            "Epoch[6689/10000] | loss train:3.071468, test:1.625178 | lr:0.000000\n",
            "Epoch[6690/10000] | loss train:0.987621, test:0.958132 | lr:0.000000\n",
            "Epoch[6691/10000] | loss train:1.690943, test:0.203914 | lr:0.000000\n",
            "Epoch[6692/10000] | loss train:1.579707, test:1.746977 | lr:0.000000\n",
            "Epoch[6693/10000] | loss train:0.971990, test:0.898643 | lr:0.000000\n",
            "Epoch[6694/10000] | loss train:1.781420, test:0.183914 | lr:0.000000\n",
            "Epoch[6695/10000] | loss train:1.502397, test:0.892849 | lr:0.000000\n",
            "Epoch[6696/10000] | loss train:0.953331, test:0.204615 | lr:0.000000\n",
            "Epoch[6697/10000] | loss train:1.356500, test:0.504256 | lr:0.000000\n",
            "Epoch[6698/10000] | loss train:1.289100, test:0.146010 | lr:0.000000\n",
            "Epoch[6699/10000] | loss train:1.415935, test:0.509408 | lr:0.000000\n",
            "Epoch[6700/10000] | loss train:1.317400, test:1.262433 | lr:0.000000\n",
            "Epoch[6701/10000] | loss train:1.743736, test:0.338533 | lr:0.000000\n",
            "Epoch[6702/10000] | loss train:1.965046, test:0.371838 | lr:0.000000\n",
            "Epoch[6703/10000] | loss train:1.049507, test:0.812477 | lr:0.000000\n",
            "Epoch[6704/10000] | loss train:0.837691, test:0.258951 | lr:0.000000\n",
            "Epoch[6705/10000] | loss train:0.864231, test:0.631485 | lr:0.000000\n",
            "Epoch[6706/10000] | loss train:1.585886, test:0.869262 | lr:0.000000\n",
            "Epoch[6707/10000] | loss train:1.680165, test:0.789783 | lr:0.000000\n",
            "Epoch[6708/10000] | loss train:2.958946, test:0.319662 | lr:0.000000\n",
            "Epoch[6709/10000] | loss train:1.256813, test:1.146006 | lr:0.000000\n",
            "Epoch[6710/10000] | loss train:3.216229, test:1.125897 | lr:0.000000\n",
            "Epoch[6711/10000] | loss train:1.618286, test:0.405721 | lr:0.000000\n",
            "Epoch[6712/10000] | loss train:1.228931, test:0.752762 | lr:0.000000\n",
            "Epoch[6713/10000] | loss train:0.861873, test:1.158632 | lr:0.000000\n",
            "Epoch[6714/10000] | loss train:1.040275, test:0.340935 | lr:0.000000\n",
            "Epoch[6715/10000] | loss train:0.947230, test:0.264554 | lr:0.000000\n",
            "Epoch[6716/10000] | loss train:1.211005, test:0.569582 | lr:0.000000\n",
            "Epoch[6717/10000] | loss train:1.824290, test:0.561667 | lr:0.000000\n",
            "Epoch[6718/10000] | loss train:2.646204, test:0.714661 | lr:0.000000\n",
            "Epoch[6719/10000] | loss train:1.040751, test:0.062076 | lr:0.000000\n",
            "Epoch[6720/10000] | loss train:0.840305, test:0.522139 | lr:0.000000\n",
            "Epoch[6721/10000] | loss train:1.293412, test:0.507192 | lr:0.000000\n",
            "Epoch[6722/10000] | loss train:0.990807, test:0.484872 | lr:0.000000\n",
            "Epoch[6723/10000] | loss train:1.257529, test:0.370316 | lr:0.000000\n",
            "Epoch[6724/10000] | loss train:2.436085, test:0.512475 | lr:0.000000\n",
            "Epoch[6725/10000] | loss train:1.071252, test:0.263350 | lr:0.000000\n",
            "Epoch[6726/10000] | loss train:1.118500, test:0.360574 | lr:0.000000\n",
            "Epoch[6727/10000] | loss train:1.047430, test:0.795282 | lr:0.000000\n",
            "Epoch[6728/10000] | loss train:1.313110, test:0.108144 | lr:0.000000\n",
            "Epoch[6729/10000] | loss train:0.927531, test:0.217717 | lr:0.000000\n",
            "Epoch[6730/10000] | loss train:1.693396, test:0.638003 | lr:0.000000\n",
            "Epoch[6731/10000] | loss train:1.898884, test:0.197054 | lr:0.000000\n",
            "Epoch[6732/10000] | loss train:1.850703, test:1.380771 | lr:0.000000\n",
            "Epoch[6733/10000] | loss train:1.093008, test:0.963362 | lr:0.000000\n",
            "Epoch[6734/10000] | loss train:1.052963, test:0.397759 | lr:0.000000\n",
            "Epoch[6735/10000] | loss train:0.880593, test:1.478417 | lr:0.000000\n",
            "Epoch[6736/10000] | loss train:1.737202, test:0.051960 | lr:0.000000\n",
            "Epoch[6737/10000] | loss train:1.042041, test:0.552407 | lr:0.000000\n",
            "Epoch[6738/10000] | loss train:0.964036, test:0.334899 | lr:0.000000\n",
            "Epoch[6739/10000] | loss train:1.648711, test:0.320269 | lr:0.000000\n",
            "Epoch[6740/10000] | loss train:1.099785, test:1.859028 | lr:0.000000\n",
            "Epoch[6741/10000] | loss train:0.985012, test:0.312135 | lr:0.000000\n",
            "Epoch[6742/10000] | loss train:1.097247, test:1.042386 | lr:0.000000\n",
            "Epoch[6743/10000] | loss train:1.202729, test:0.564261 | lr:0.000000\n",
            "Epoch[6744/10000] | loss train:1.867231, test:0.538693 | lr:0.000000\n",
            "Epoch[6745/10000] | loss train:0.685888, test:0.287039 | lr:0.000000\n",
            "Epoch[6746/10000] | loss train:0.786565, test:0.690237 | lr:0.000000\n",
            "Epoch[6747/10000] | loss train:1.037042, test:0.766619 | lr:0.000000\n",
            "Epoch[6748/10000] | loss train:0.952107, test:0.266045 | lr:0.000000\n",
            "Epoch[6749/10000] | loss train:0.843876, test:0.211197 | lr:0.000000\n",
            "Epoch[6750/10000] | loss train:1.427529, test:0.332291 | lr:0.000000\n",
            "Epoch[6751/10000] | loss train:1.156501, test:0.234070 | lr:0.000000\n",
            "Epoch[6752/10000] | loss train:1.264363, test:0.280376 | lr:0.000000\n",
            "Epoch[6753/10000] | loss train:1.851214, test:0.667330 | lr:0.000000\n",
            "Epoch[6754/10000] | loss train:1.799017, test:0.261108 | lr:0.000000\n",
            "Epoch[6755/10000] | loss train:1.152089, test:0.744732 | lr:0.000000\n",
            "Epoch[6756/10000] | loss train:0.609894, test:0.511475 | lr:0.000000\n",
            "Epoch[6757/10000] | loss train:1.544496, test:0.376419 | lr:0.000000\n",
            "Epoch[6758/10000] | loss train:1.194907, test:0.823769 | lr:0.000000\n",
            "Epoch[6759/10000] | loss train:1.012909, test:0.686465 | lr:0.000000\n",
            "Epoch[6760/10000] | loss train:1.503517, test:0.375247 | lr:0.000000\n",
            "Epoch[6761/10000] | loss train:0.651510, test:0.324567 | lr:0.000000\n",
            "Epoch[6762/10000] | loss train:1.554029, test:0.464376 | lr:0.000000\n",
            "Epoch[6763/10000] | loss train:0.955800, test:0.319015 | lr:0.000000\n",
            "Epoch[6764/10000] | loss train:0.904767, test:0.454276 | lr:0.000000\n",
            "Epoch[6765/10000] | loss train:1.231853, test:0.759306 | lr:0.000000\n",
            "Epoch[6766/10000] | loss train:1.151747, test:0.294954 | lr:0.000000\n",
            "Epoch[6767/10000] | loss train:1.012106, test:1.807934 | lr:0.000000\n",
            "Epoch[6768/10000] | loss train:1.020798, test:0.259001 | lr:0.000000\n",
            "Epoch[6769/10000] | loss train:1.119783, test:0.749206 | lr:0.000000\n",
            "Epoch[6770/10000] | loss train:1.331169, test:0.346012 | lr:0.000000\n",
            "Epoch[6771/10000] | loss train:2.181591, test:0.472788 | lr:0.000000\n",
            "Epoch[6772/10000] | loss train:1.569286, test:1.818311 | lr:0.000000\n",
            "Epoch[6773/10000] | loss train:1.347296, test:1.098502 | lr:0.000000\n",
            "Epoch[6774/10000] | loss train:2.671837, test:0.434266 | lr:0.000000\n",
            "Epoch[6775/10000] | loss train:1.767368, test:1.293721 | lr:0.000000\n",
            "Epoch[6776/10000] | loss train:1.145443, test:0.430248 | lr:0.000000\n",
            "Epoch[6777/10000] | loss train:0.974991, test:0.433655 | lr:0.000000\n",
            "Epoch[6778/10000] | loss train:1.501677, test:0.251773 | lr:0.000000\n",
            "Epoch[6779/10000] | loss train:1.040930, test:0.256958 | lr:0.000000\n",
            "Epoch[6780/10000] | loss train:1.731804, test:0.326148 | lr:0.000000\n",
            "Epoch[6781/10000] | loss train:0.829430, test:0.437457 | lr:0.000000\n",
            "Epoch[6782/10000] | loss train:0.759130, test:0.855876 | lr:0.000000\n",
            "Epoch[6783/10000] | loss train:1.380824, test:0.568948 | lr:0.000000\n",
            "Epoch[6784/10000] | loss train:1.199860, test:1.033666 | lr:0.000000\n",
            "Epoch[6785/10000] | loss train:1.309659, test:0.277457 | lr:0.000000\n",
            "Epoch[6786/10000] | loss train:1.446307, test:1.081037 | lr:0.000000\n",
            "Epoch[6787/10000] | loss train:0.645162, test:0.597812 | lr:0.000000\n",
            "Epoch[6788/10000] | loss train:1.050736, test:0.576135 | lr:0.000000\n",
            "Epoch[6789/10000] | loss train:1.087000, test:2.014621 | lr:0.000000\n",
            "Epoch[6790/10000] | loss train:0.906848, test:0.176488 | lr:0.000000\n",
            "Epoch[6791/10000] | loss train:0.975614, test:0.695907 | lr:0.000000\n",
            "Epoch[6792/10000] | loss train:1.728479, test:0.229618 | lr:0.000000\n",
            "Epoch[6793/10000] | loss train:1.119294, test:0.265698 | lr:0.000000\n",
            "Epoch[6794/10000] | loss train:0.983693, test:0.347579 | lr:0.000000\n",
            "Epoch[6795/10000] | loss train:0.904539, test:0.077862 | lr:0.000000\n",
            "Epoch[6796/10000] | loss train:0.857499, test:0.862684 | lr:0.000000\n",
            "Epoch[6797/10000] | loss train:0.871016, test:2.432347 | lr:0.000000\n",
            "Epoch[6798/10000] | loss train:1.071791, test:0.763478 | lr:0.000000\n",
            "Epoch[6799/10000] | loss train:1.217129, test:0.365361 | lr:0.000000\n",
            "Epoch[6800/10000] | loss train:1.318835, test:1.017352 | lr:0.000000\n",
            "Epoch[6801/10000] | loss train:1.980120, test:1.244365 | lr:0.000000\n",
            "Epoch[6802/10000] | loss train:2.018059, test:0.418006 | lr:0.000000\n",
            "Epoch[6803/10000] | loss train:1.238651, test:0.624513 | lr:0.000000\n",
            "Epoch[6804/10000] | loss train:1.252610, test:0.929471 | lr:0.000000\n",
            "Epoch[6805/10000] | loss train:1.554900, test:0.285128 | lr:0.000000\n",
            "Epoch[6806/10000] | loss train:1.355835, test:0.885640 | lr:0.000000\n",
            "Epoch[6807/10000] | loss train:0.879241, test:0.299601 | lr:0.000000\n",
            "Epoch[6808/10000] | loss train:0.900583, test:0.327277 | lr:0.000000\n",
            "Epoch[6809/10000] | loss train:1.853542, test:1.141777 | lr:0.000000\n",
            "Epoch[6810/10000] | loss train:1.726543, test:0.100523 | lr:0.000000\n",
            "Epoch[6811/10000] | loss train:1.565772, test:1.170385 | lr:0.000000\n",
            "Epoch[6812/10000] | loss train:0.853914, test:0.807290 | lr:0.000000\n",
            "Epoch[6813/10000] | loss train:1.199707, test:0.513379 | lr:0.000000\n",
            "Epoch[6814/10000] | loss train:1.681492, test:0.282460 | lr:0.000000\n",
            "Epoch[6815/10000] | loss train:1.734483, test:1.113568 | lr:0.000000\n",
            "Epoch[6816/10000] | loss train:0.754169, test:1.019879 | lr:0.000000\n",
            "Epoch[6817/10000] | loss train:1.292964, test:0.551644 | lr:0.000000\n",
            "Epoch[6818/10000] | loss train:1.307367, test:0.206617 | lr:0.000000\n",
            "Epoch[6819/10000] | loss train:1.413629, test:0.734244 | lr:0.000000\n",
            "Epoch[6820/10000] | loss train:1.619531, test:1.230297 | lr:0.000000\n",
            "Epoch[6821/10000] | loss train:0.834659, test:0.531213 | lr:0.000000\n",
            "Epoch[6822/10000] | loss train:1.240646, test:0.929394 | lr:0.000000\n",
            "Epoch[6823/10000] | loss train:1.506381, test:0.314876 | lr:0.000000\n",
            "Epoch[6824/10000] | loss train:2.293526, test:1.641433 | lr:0.000000\n",
            "Epoch[6825/10000] | loss train:0.863942, test:0.302201 | lr:0.000000\n",
            "Epoch[6826/10000] | loss train:0.806760, test:1.070736 | lr:0.000000\n",
            "Epoch[6827/10000] | loss train:1.131858, test:0.244319 | lr:0.000000\n",
            "Epoch[6828/10000] | loss train:1.394921, test:0.210517 | lr:0.000000\n",
            "Epoch[6829/10000] | loss train:1.036243, test:0.426867 | lr:0.000000\n",
            "Epoch[6830/10000] | loss train:1.793413, test:0.254858 | lr:0.000000\n",
            "Epoch[6831/10000] | loss train:1.685625, test:0.630150 | lr:0.000000\n",
            "Epoch[6832/10000] | loss train:0.890291, test:0.701333 | lr:0.000000\n",
            "Epoch[6833/10000] | loss train:1.551597, test:0.754737 | lr:0.000000\n",
            "Epoch[6834/10000] | loss train:0.953907, test:0.499233 | lr:0.000000\n",
            "Epoch[6835/10000] | loss train:0.631343, test:1.174191 | lr:0.000000\n",
            "Epoch[6836/10000] | loss train:1.403128, test:1.047188 | lr:0.000000\n",
            "Epoch[6837/10000] | loss train:1.555905, test:1.508980 | lr:0.000000\n",
            "Epoch[6838/10000] | loss train:1.427890, test:0.429388 | lr:0.000000\n",
            "Epoch[6839/10000] | loss train:2.474518, test:0.380366 | lr:0.000000\n",
            "Epoch[6840/10000] | loss train:0.923954, test:0.617850 | lr:0.000000\n",
            "Epoch[6841/10000] | loss train:1.243905, test:0.195216 | lr:0.000000\n",
            "Epoch[6842/10000] | loss train:1.973488, test:0.050770 | lr:0.000000\n",
            "Epoch[6843/10000] | loss train:0.940960, test:0.998354 | lr:0.000000\n",
            "Epoch[6844/10000] | loss train:0.909911, test:1.083303 | lr:0.000000\n",
            "Epoch[6845/10000] | loss train:1.295137, test:0.308795 | lr:0.000000\n",
            "Epoch[6846/10000] | loss train:1.487849, test:0.329896 | lr:0.000000\n",
            "Epoch[6847/10000] | loss train:0.768401, test:1.310702 | lr:0.000000\n",
            "Epoch[6848/10000] | loss train:1.089652, test:0.481173 | lr:0.000000\n",
            "Epoch[6849/10000] | loss train:1.519611, test:0.290790 | lr:0.000000\n",
            "Epoch[6850/10000] | loss train:1.389348, test:0.348878 | lr:0.000000\n",
            "Epoch[6851/10000] | loss train:0.881197, test:0.435083 | lr:0.000000\n",
            "Epoch[6852/10000] | loss train:1.985710, test:0.593309 | lr:0.000000\n",
            "Epoch[6853/10000] | loss train:1.134781, test:0.796704 | lr:0.000000\n",
            "Epoch[6854/10000] | loss train:1.988442, test:0.693024 | lr:0.000000\n",
            "Epoch[6855/10000] | loss train:1.737601, test:0.442180 | lr:0.000000\n",
            "Epoch[6856/10000] | loss train:2.191431, test:0.212122 | lr:0.000000\n",
            "Epoch[6857/10000] | loss train:0.745301, test:0.556549 | lr:0.000000\n",
            "Epoch[6858/10000] | loss train:0.998661, test:1.124474 | lr:0.000000\n",
            "Epoch[6859/10000] | loss train:0.999329, test:0.289646 | lr:0.000000\n",
            "Epoch[6860/10000] | loss train:0.882407, test:0.047958 | lr:0.000000\n",
            "Epoch[6861/10000] | loss train:1.385134, test:0.263343 | lr:0.000000\n",
            "Epoch[6862/10000] | loss train:0.668358, test:0.309398 | lr:0.000000\n",
            "Epoch[6863/10000] | loss train:2.063375, test:1.009112 | lr:0.000000\n",
            "Epoch[6864/10000] | loss train:0.793763, test:0.512877 | lr:0.000000\n",
            "Epoch[6865/10000] | loss train:1.107401, test:0.335501 | lr:0.000000\n",
            "Epoch[6866/10000] | loss train:1.372915, test:0.187246 | lr:0.000000\n",
            "Epoch[6867/10000] | loss train:3.285037, test:1.381198 | lr:0.000000\n",
            "Epoch[6868/10000] | loss train:1.101987, test:0.534327 | lr:0.000000\n",
            "Epoch[6869/10000] | loss train:0.918627, test:0.402111 | lr:0.000000\n",
            "Epoch[6870/10000] | loss train:1.070326, test:2.488700 | lr:0.000000\n",
            "Epoch[6871/10000] | loss train:1.451023, test:0.329477 | lr:0.000000\n",
            "Epoch[6872/10000] | loss train:1.209691, test:0.842943 | lr:0.000000\n",
            "Epoch[6873/10000] | loss train:1.221782, test:0.450093 | lr:0.000000\n",
            "Epoch[6874/10000] | loss train:0.976690, test:0.271101 | lr:0.000000\n",
            "Epoch[6875/10000] | loss train:1.376341, test:1.374837 | lr:0.000000\n",
            "Epoch[6876/10000] | loss train:1.368091, test:0.376013 | lr:0.000000\n",
            "Epoch[6877/10000] | loss train:1.736975, test:0.672471 | lr:0.000000\n",
            "Epoch[6878/10000] | loss train:0.768288, test:0.143446 | lr:0.000000\n",
            "Epoch[6879/10000] | loss train:0.855285, test:1.766821 | lr:0.000000\n",
            "Epoch[6880/10000] | loss train:0.942553, test:0.321905 | lr:0.000000\n",
            "Epoch[6881/10000] | loss train:1.626511, test:0.534467 | lr:0.000000\n",
            "Epoch[6882/10000] | loss train:1.445551, test:0.174882 | lr:0.000000\n",
            "Epoch[6883/10000] | loss train:1.213297, test:0.274587 | lr:0.000000\n",
            "Epoch[6884/10000] | loss train:1.770478, test:0.208568 | lr:0.000000\n",
            "Epoch[6885/10000] | loss train:0.907789, test:0.174056 | lr:0.000000\n",
            "Epoch[6886/10000] | loss train:1.344884, test:0.842852 | lr:0.000000\n",
            "Epoch[6887/10000] | loss train:0.846131, test:0.622959 | lr:0.000000\n",
            "Epoch[6888/10000] | loss train:1.103020, test:0.174709 | lr:0.000000\n",
            "Epoch[6889/10000] | loss train:1.565616, test:0.321683 | lr:0.000000\n",
            "Epoch[6890/10000] | loss train:1.172243, test:0.222383 | lr:0.000000\n",
            "Epoch[6891/10000] | loss train:1.493263, test:0.592146 | lr:0.000000\n",
            "Epoch[6892/10000] | loss train:0.738637, test:0.780876 | lr:0.000000\n",
            "Epoch[6893/10000] | loss train:1.375559, test:0.109183 | lr:0.000000\n",
            "Epoch[6894/10000] | loss train:1.412272, test:0.873584 | lr:0.000000\n",
            "Epoch[6895/10000] | loss train:1.730369, test:0.335447 | lr:0.000000\n",
            "Epoch[6896/10000] | loss train:1.625245, test:1.940014 | lr:0.000000\n",
            "Epoch[6897/10000] | loss train:1.338805, test:0.900584 | lr:0.000000\n",
            "Epoch[6898/10000] | loss train:1.333707, test:0.636587 | lr:0.000000\n",
            "Epoch[6899/10000] | loss train:1.250662, test:0.618455 | lr:0.000000\n",
            "Epoch[6900/10000] | loss train:1.769807, test:0.620610 | lr:0.000000\n",
            "Epoch[6901/10000] | loss train:1.362020, test:1.468479 | lr:0.000000\n",
            "Epoch[6902/10000] | loss train:1.506632, test:0.253948 | lr:0.000000\n",
            "Epoch[6903/10000] | loss train:1.020077, test:0.353667 | lr:0.000000\n",
            "Epoch[6904/10000] | loss train:0.925386, test:1.002020 | lr:0.000000\n",
            "Epoch[6905/10000] | loss train:1.040129, test:2.488002 | lr:0.000000\n",
            "Epoch[6906/10000] | loss train:0.658700, test:0.404519 | lr:0.000000\n",
            "Epoch[6907/10000] | loss train:1.216294, test:1.047425 | lr:0.000000\n",
            "Epoch[6908/10000] | loss train:1.125501, test:0.890110 | lr:0.000000\n",
            "Epoch[6909/10000] | loss train:1.091765, test:0.741469 | lr:0.000000\n",
            "Epoch[6910/10000] | loss train:1.080315, test:1.443398 | lr:0.000000\n",
            "Epoch[6911/10000] | loss train:1.843048, test:0.614458 | lr:0.000000\n",
            "Epoch[6912/10000] | loss train:1.037979, test:0.050833 | lr:0.000000\n",
            "Epoch[6913/10000] | loss train:0.828589, test:0.282338 | lr:0.000000\n",
            "Epoch[6914/10000] | loss train:1.168380, test:0.706440 | lr:0.000000\n",
            "Epoch[6915/10000] | loss train:1.454921, test:0.419748 | lr:0.000000\n",
            "Epoch[6916/10000] | loss train:1.826693, test:0.179155 | lr:0.000000\n",
            "Epoch[6917/10000] | loss train:1.330483, test:0.229971 | lr:0.000000\n",
            "Epoch[6918/10000] | loss train:0.650301, test:0.492149 | lr:0.000000\n",
            "Epoch[6919/10000] | loss train:1.318787, test:0.589320 | lr:0.000000\n",
            "Epoch[6920/10000] | loss train:2.035637, test:0.244900 | lr:0.000000\n",
            "Epoch[6921/10000] | loss train:1.040919, test:1.514641 | lr:0.000000\n",
            "Epoch[6922/10000] | loss train:0.669850, test:0.250203 | lr:0.000000\n",
            "Epoch[6923/10000] | loss train:0.792972, test:0.622811 | lr:0.000000\n",
            "Epoch[6924/10000] | loss train:1.452019, test:0.469838 | lr:0.000000\n",
            "Epoch[6925/10000] | loss train:0.996984, test:0.273744 | lr:0.000000\n",
            "Epoch[6926/10000] | loss train:1.507739, test:0.320368 | lr:0.000000\n",
            "Epoch[6927/10000] | loss train:0.975131, test:0.098324 | lr:0.000000\n",
            "Epoch[6928/10000] | loss train:1.620930, test:0.121487 | lr:0.000000\n",
            "Epoch[6929/10000] | loss train:1.101831, test:1.224570 | lr:0.000000\n",
            "Epoch[6930/10000] | loss train:0.821151, test:0.202726 | lr:0.000000\n",
            "Epoch[6931/10000] | loss train:0.734985, test:0.210635 | lr:0.000000\n",
            "Epoch[6932/10000] | loss train:2.051351, test:0.352127 | lr:0.000000\n",
            "Epoch[6933/10000] | loss train:1.438985, test:0.068160 | lr:0.000000\n",
            "Epoch[6934/10000] | loss train:1.974255, test:0.580552 | lr:0.000000\n",
            "Epoch[6935/10000] | loss train:2.660670, test:0.126462 | lr:0.000000\n",
            "Epoch[6936/10000] | loss train:2.189231, test:0.871054 | lr:0.000000\n",
            "Epoch[6937/10000] | loss train:1.894050, test:0.713401 | lr:0.000000\n",
            "Epoch[6938/10000] | loss train:1.157626, test:0.694750 | lr:0.000000\n",
            "Epoch[6939/10000] | loss train:1.814458, test:1.786154 | lr:0.000000\n",
            "Epoch[6940/10000] | loss train:1.475137, test:0.939950 | lr:0.000000\n",
            "Epoch[6941/10000] | loss train:1.659409, test:1.070547 | lr:0.000000\n",
            "Epoch[6942/10000] | loss train:1.606195, test:1.432425 | lr:0.000000\n",
            "Epoch[6943/10000] | loss train:1.181370, test:0.211288 | lr:0.000000\n",
            "Epoch[6944/10000] | loss train:0.766177, test:1.518834 | lr:0.000000\n",
            "Epoch[6945/10000] | loss train:1.100087, test:0.210785 | lr:0.000000\n",
            "Epoch[6946/10000] | loss train:0.954615, test:0.168805 | lr:0.000000\n",
            "Epoch[6947/10000] | loss train:0.788997, test:0.320305 | lr:0.000000\n",
            "Epoch[6948/10000] | loss train:1.195624, test:0.256319 | lr:0.000000\n",
            "Epoch[6949/10000] | loss train:0.866437, test:0.484989 | lr:0.000000\n",
            "Epoch[6950/10000] | loss train:1.044683, test:0.534713 | lr:0.000000\n",
            "Epoch[6951/10000] | loss train:2.046887, test:0.197476 | lr:0.000000\n",
            "Epoch[6952/10000] | loss train:1.335788, test:0.122988 | lr:0.000000\n",
            "Epoch[6953/10000] | loss train:1.000794, test:0.729422 | lr:0.000000\n",
            "Epoch[6954/10000] | loss train:1.322607, test:0.147177 | lr:0.000000\n",
            "Epoch[6955/10000] | loss train:1.268333, test:0.537870 | lr:0.000000\n",
            "Epoch[6956/10000] | loss train:1.047507, test:0.768668 | lr:0.000000\n",
            "Epoch[6957/10000] | loss train:1.006294, test:0.261416 | lr:0.000000\n",
            "Epoch[6958/10000] | loss train:0.747974, test:0.146927 | lr:0.000000\n",
            "Epoch[6959/10000] | loss train:2.362060, test:0.665665 | lr:0.000000\n",
            "Epoch[6960/10000] | loss train:0.952578, test:0.590416 | lr:0.000000\n",
            "Epoch[6961/10000] | loss train:0.735215, test:0.080191 | lr:0.000000\n",
            "Epoch[6962/10000] | loss train:1.949840, test:0.190991 | lr:0.000000\n",
            "Epoch[6963/10000] | loss train:1.088351, test:1.923398 | lr:0.000000\n",
            "Epoch[6964/10000] | loss train:1.534167, test:0.387569 | lr:0.000000\n",
            "Epoch[6965/10000] | loss train:1.507838, test:0.346964 | lr:0.000000\n",
            "Epoch[6966/10000] | loss train:1.748615, test:1.167950 | lr:0.000000\n",
            "Epoch[6967/10000] | loss train:0.924876, test:0.401996 | lr:0.000000\n",
            "Epoch[6968/10000] | loss train:0.980816, test:0.341416 | lr:0.000000\n",
            "Epoch[6969/10000] | loss train:1.490087, test:1.214100 | lr:0.000000\n",
            "Epoch[6970/10000] | loss train:1.163399, test:0.409864 | lr:0.000000\n",
            "Epoch[6971/10000] | loss train:1.552820, test:0.321032 | lr:0.000000\n",
            "Epoch[6972/10000] | loss train:1.278520, test:1.283605 | lr:0.000000\n",
            "Epoch[6973/10000] | loss train:1.654143, test:0.302864 | lr:0.000000\n",
            "Epoch[6974/10000] | loss train:1.330785, test:0.231822 | lr:0.000000\n",
            "Epoch[6975/10000] | loss train:1.421522, test:0.337543 | lr:0.000000\n",
            "Epoch[6976/10000] | loss train:1.178852, test:0.390789 | lr:0.000000\n",
            "Epoch[6977/10000] | loss train:1.326988, test:0.274305 | lr:0.000000\n",
            "Epoch[6978/10000] | loss train:1.060524, test:0.416078 | lr:0.000000\n",
            "Epoch[6979/10000] | loss train:0.957299, test:0.239105 | lr:0.000000\n",
            "Epoch[6980/10000] | loss train:1.200141, test:0.226533 | lr:0.000000\n",
            "Epoch[6981/10000] | loss train:1.542827, test:1.262491 | lr:0.000000\n",
            "Epoch[6982/10000] | loss train:0.916564, test:0.973492 | lr:0.000000\n",
            "Epoch[6983/10000] | loss train:1.447869, test:0.793100 | lr:0.000000\n",
            "Epoch[6984/10000] | loss train:0.782903, test:0.763867 | lr:0.000000\n",
            "Epoch[6985/10000] | loss train:0.979974, test:1.801050 | lr:0.000000\n",
            "Epoch[6986/10000] | loss train:1.324900, test:0.584829 | lr:0.000000\n",
            "Epoch[6987/10000] | loss train:1.301069, test:0.417963 | lr:0.000000\n",
            "Epoch[6988/10000] | loss train:1.467843, test:0.285794 | lr:0.000000\n",
            "Epoch[6989/10000] | loss train:1.491187, test:0.383691 | lr:0.000000\n",
            "Epoch[6990/10000] | loss train:1.512999, test:0.197726 | lr:0.000000\n",
            "Epoch[6991/10000] | loss train:1.403041, test:0.585754 | lr:0.000000\n",
            "Epoch[6992/10000] | loss train:0.710804, test:1.082943 | lr:0.000000\n",
            "Epoch[6993/10000] | loss train:1.238211, test:1.047880 | lr:0.000000\n",
            "Epoch[6994/10000] | loss train:0.917291, test:0.564694 | lr:0.000000\n",
            "Epoch[6995/10000] | loss train:2.512905, test:0.234280 | lr:0.000000\n",
            "Epoch[6996/10000] | loss train:1.416642, test:0.861831 | lr:0.000000\n",
            "Epoch[6997/10000] | loss train:0.865915, test:0.288132 | lr:0.000000\n",
            "Epoch[6998/10000] | loss train:0.759293, test:0.713554 | lr:0.000000\n",
            "Epoch[6999/10000] | loss train:1.904536, test:1.594235 | lr:0.000000\n",
            "Epoch[7000/10000] | loss train:0.876736, test:1.866932 | lr:0.000000\n",
            "Epoch[7001/10000] | loss train:0.883730, test:0.680442 | lr:0.000000\n",
            "Epoch[7002/10000] | loss train:1.858258, test:0.390106 | lr:0.000000\n",
            "Epoch[7003/10000] | loss train:1.787318, test:0.385177 | lr:0.000000\n",
            "Epoch[7004/10000] | loss train:1.373371, test:0.280334 | lr:0.000000\n",
            "Epoch[7005/10000] | loss train:3.301737, test:0.307231 | lr:0.000000\n",
            "Epoch[7006/10000] | loss train:0.882247, test:1.428122 | lr:0.000000\n",
            "Epoch[7007/10000] | loss train:1.180130, test:0.562858 | lr:0.000000\n",
            "Epoch[7008/10000] | loss train:0.597584, test:0.204339 | lr:0.000000\n",
            "Epoch[7009/10000] | loss train:1.034653, test:1.217846 | lr:0.000000\n",
            "Epoch[7010/10000] | loss train:0.762280, test:0.515909 | lr:0.000000\n",
            "Epoch[7011/10000] | loss train:1.155529, test:1.282637 | lr:0.000000\n",
            "Epoch[7012/10000] | loss train:1.005825, test:0.456503 | lr:0.000000\n",
            "Epoch[7013/10000] | loss train:0.761246, test:0.786686 | lr:0.000000\n",
            "Epoch[7014/10000] | loss train:1.891874, test:1.421975 | lr:0.000000\n",
            "Epoch[7015/10000] | loss train:1.256944, test:0.602411 | lr:0.000000\n",
            "Epoch[7016/10000] | loss train:1.412503, test:0.386022 | lr:0.000000\n",
            "Epoch[7017/10000] | loss train:0.743568, test:0.213019 | lr:0.000000\n",
            "Epoch[7018/10000] | loss train:1.397752, test:0.800794 | lr:0.000000\n",
            "Epoch[7019/10000] | loss train:0.920967, test:0.486144 | lr:0.000000\n",
            "Epoch[7020/10000] | loss train:1.950800, test:0.325844 | lr:0.000000\n",
            "Epoch[7021/10000] | loss train:1.237137, test:0.738658 | lr:0.000000\n",
            "Epoch[7022/10000] | loss train:1.756879, test:1.033970 | lr:0.000000\n",
            "Epoch[7023/10000] | loss train:1.428274, test:0.747072 | lr:0.000000\n",
            "Epoch[7024/10000] | loss train:1.148071, test:0.386923 | lr:0.000000\n",
            "Epoch[7025/10000] | loss train:0.993260, test:0.380027 | lr:0.000000\n",
            "Epoch[7026/10000] | loss train:0.670072, test:0.644905 | lr:0.000000\n",
            "Epoch[7027/10000] | loss train:1.521528, test:1.242710 | lr:0.000000\n",
            "Epoch[7028/10000] | loss train:1.216551, test:0.605932 | lr:0.000000\n",
            "Epoch[7029/10000] | loss train:2.556129, test:0.419206 | lr:0.000000\n",
            "Epoch[7030/10000] | loss train:1.029648, test:0.825130 | lr:0.000000\n",
            "Epoch[7031/10000] | loss train:1.906253, test:0.075718 | lr:0.000000\n",
            "Epoch[7032/10000] | loss train:1.175818, test:0.783119 | lr:0.000000\n",
            "Epoch[7033/10000] | loss train:1.199271, test:0.370622 | lr:0.000000\n",
            "Epoch[7034/10000] | loss train:0.774279, test:0.527309 | lr:0.000000\n",
            "Epoch[7035/10000] | loss train:0.954237, test:1.316667 | lr:0.000000\n",
            "Epoch[7036/10000] | loss train:1.156638, test:0.263774 | lr:0.000000\n",
            "Epoch[7037/10000] | loss train:1.321003, test:0.492097 | lr:0.000000\n",
            "Epoch[7038/10000] | loss train:1.446756, test:0.226064 | lr:0.000000\n",
            "Epoch[7039/10000] | loss train:1.225699, test:0.292048 | lr:0.000000\n",
            "Epoch[7040/10000] | loss train:2.365032, test:0.363050 | lr:0.000000\n",
            "Epoch[7041/10000] | loss train:0.745801, test:0.489682 | lr:0.000000\n",
            "Epoch[7042/10000] | loss train:2.032584, test:0.533640 | lr:0.000000\n",
            "Epoch[7043/10000] | loss train:1.188829, test:1.577481 | lr:0.000000\n",
            "Epoch[7044/10000] | loss train:1.389644, test:0.316455 | lr:0.000000\n",
            "Epoch[7045/10000] | loss train:1.188160, test:0.620725 | lr:0.000000\n",
            "Epoch[7046/10000] | loss train:0.897296, test:0.437165 | lr:0.000000\n",
            "Epoch[7047/10000] | loss train:0.774868, test:0.356128 | lr:0.000000\n",
            "Epoch[7048/10000] | loss train:1.193795, test:1.745699 | lr:0.000000\n",
            "Epoch[7049/10000] | loss train:1.075291, test:1.499662 | lr:0.000000\n",
            "Epoch[7050/10000] | loss train:1.508799, test:0.331220 | lr:0.000000\n",
            "Epoch[7051/10000] | loss train:1.005352, test:1.402193 | lr:0.000000\n",
            "Epoch[7052/10000] | loss train:1.064043, test:0.518728 | lr:0.000000\n",
            "Epoch[7053/10000] | loss train:1.068274, test:0.828564 | lr:0.000000\n",
            "Epoch[7054/10000] | loss train:1.181084, test:0.218177 | lr:0.000000\n",
            "Epoch[7055/10000] | loss train:0.687483, test:0.283575 | lr:0.000000\n",
            "Epoch[7056/10000] | loss train:1.211807, test:0.374539 | lr:0.000000\n",
            "Epoch[7057/10000] | loss train:1.759778, test:1.103369 | lr:0.000000\n",
            "Epoch[7058/10000] | loss train:1.625050, test:1.909821 | lr:0.000000\n",
            "Epoch[7059/10000] | loss train:0.826797, test:0.576348 | lr:0.000000\n",
            "Epoch[7060/10000] | loss train:1.774953, test:0.660878 | lr:0.000000\n",
            "Epoch[7061/10000] | loss train:1.226350, test:0.239300 | lr:0.000000\n",
            "Epoch[7062/10000] | loss train:2.805676, test:0.287156 | lr:0.000000\n",
            "Epoch[7063/10000] | loss train:0.865836, test:0.282084 | lr:0.000000\n",
            "Epoch[7064/10000] | loss train:1.164529, test:1.142599 | lr:0.000000\n",
            "Epoch[7065/10000] | loss train:0.900922, test:0.312894 | lr:0.000000\n",
            "Epoch[7066/10000] | loss train:0.758205, test:0.250537 | lr:0.000000\n",
            "Epoch[7067/10000] | loss train:1.314296, test:0.691888 | lr:0.000000\n",
            "Epoch[7068/10000] | loss train:0.840984, test:0.243541 | lr:0.000000\n",
            "Epoch[7069/10000] | loss train:2.001282, test:0.050902 | lr:0.000000\n",
            "Epoch[7070/10000] | loss train:0.802564, test:0.825160 | lr:0.000000\n",
            "Epoch[7071/10000] | loss train:1.048305, test:0.815409 | lr:0.000000\n",
            "Epoch[7072/10000] | loss train:1.357072, test:1.369898 | lr:0.000000\n",
            "Epoch[7073/10000] | loss train:1.542671, test:1.006292 | lr:0.000000\n",
            "Epoch[7074/10000] | loss train:2.011954, test:1.472081 | lr:0.000000\n",
            "Epoch[7075/10000] | loss train:1.010450, test:0.604225 | lr:0.000000\n",
            "Epoch[7076/10000] | loss train:1.190214, test:0.306673 | lr:0.000000\n",
            "Epoch[7077/10000] | loss train:1.935381, test:0.316204 | lr:0.000000\n",
            "Epoch[7078/10000] | loss train:0.638762, test:1.522329 | lr:0.000000\n",
            "Epoch[7079/10000] | loss train:0.950347, test:0.333830 | lr:0.000000\n",
            "Epoch[7080/10000] | loss train:0.981411, test:1.713717 | lr:0.000000\n",
            "Epoch[7081/10000] | loss train:1.308831, test:1.193032 | lr:0.000000\n",
            "Epoch[7082/10000] | loss train:0.865518, test:0.854827 | lr:0.000000\n",
            "Epoch[7083/10000] | loss train:1.069230, test:0.397903 | lr:0.000000\n",
            "Epoch[7084/10000] | loss train:1.188598, test:0.624058 | lr:0.000000\n",
            "Epoch[7085/10000] | loss train:1.673294, test:1.643488 | lr:0.000000\n",
            "Epoch[7086/10000] | loss train:0.950619, test:0.770853 | lr:0.000000\n",
            "Epoch[7087/10000] | loss train:1.696758, test:1.671962 | lr:0.000000\n",
            "Epoch[7088/10000] | loss train:1.022198, test:0.147889 | lr:0.000000\n",
            "Epoch[7089/10000] | loss train:1.122890, test:1.144944 | lr:0.000000\n",
            "Epoch[7090/10000] | loss train:1.211612, test:0.487096 | lr:0.000000\n",
            "Epoch[7091/10000] | loss train:1.173470, test:1.300370 | lr:0.000000\n",
            "Epoch[7092/10000] | loss train:1.416020, test:0.421564 | lr:0.000000\n",
            "Epoch[7093/10000] | loss train:0.696564, test:0.052183 | lr:0.000000\n",
            "Epoch[7094/10000] | loss train:0.965373, test:0.747503 | lr:0.000000\n",
            "Epoch[7095/10000] | loss train:0.922140, test:0.490316 | lr:0.000000\n",
            "Epoch[7096/10000] | loss train:0.999666, test:0.263468 | lr:0.000000\n",
            "Epoch[7097/10000] | loss train:1.096554, test:0.848407 | lr:0.000000\n",
            "Epoch[7098/10000] | loss train:1.030956, test:1.194672 | lr:0.000000\n",
            "Epoch[7099/10000] | loss train:1.429215, test:0.360109 | lr:0.000000\n",
            "Epoch[7100/10000] | loss train:0.985560, test:0.624227 | lr:0.000000\n",
            "Epoch[7101/10000] | loss train:1.643048, test:0.234682 | lr:0.000000\n",
            "Epoch[7102/10000] | loss train:0.870540, test:0.383184 | lr:0.000000\n",
            "Epoch[7103/10000] | loss train:2.264807, test:1.562621 | lr:0.000000\n",
            "Epoch[7104/10000] | loss train:0.901996, test:0.498896 | lr:0.000000\n",
            "Epoch[7105/10000] | loss train:1.087597, test:0.976728 | lr:0.000000\n",
            "Epoch[7106/10000] | loss train:1.688169, test:0.915631 | lr:0.000000\n",
            "Epoch[7107/10000] | loss train:1.775480, test:0.577588 | lr:0.000000\n",
            "Epoch[7108/10000] | loss train:0.691482, test:0.524732 | lr:0.000000\n",
            "Epoch[7109/10000] | loss train:1.162200, test:0.676076 | lr:0.000000\n",
            "Epoch[7110/10000] | loss train:1.231877, test:0.703908 | lr:0.000000\n",
            "Epoch[7111/10000] | loss train:1.577458, test:0.173162 | lr:0.000000\n",
            "Epoch[7112/10000] | loss train:0.762367, test:2.108136 | lr:0.000000\n",
            "Epoch[7113/10000] | loss train:0.885533, test:1.410091 | lr:0.000000\n",
            "Epoch[7114/10000] | loss train:1.163874, test:0.616578 | lr:0.000000\n",
            "Epoch[7115/10000] | loss train:1.286473, test:0.512130 | lr:0.000000\n",
            "Epoch[7116/10000] | loss train:1.789734, test:1.350433 | lr:0.000000\n",
            "Epoch[7117/10000] | loss train:1.783872, test:0.652951 | lr:0.000000\n",
            "Epoch[7118/10000] | loss train:1.685981, test:0.331411 | lr:0.000000\n",
            "Epoch[7119/10000] | loss train:0.820953, test:0.281401 | lr:0.000000\n",
            "Epoch[7120/10000] | loss train:1.613725, test:0.977913 | lr:0.000000\n",
            "Epoch[7121/10000] | loss train:1.528560, test:0.269918 | lr:0.000000\n",
            "Epoch[7122/10000] | loss train:0.947314, test:1.086739 | lr:0.000000\n",
            "Epoch[7123/10000] | loss train:1.041956, test:0.385804 | lr:0.000000\n",
            "Epoch[7124/10000] | loss train:0.770504, test:0.919560 | lr:0.000000\n",
            "Epoch[7125/10000] | loss train:0.722971, test:0.139609 | lr:0.000000\n",
            "Epoch[7126/10000] | loss train:1.482900, test:0.656520 | lr:0.000000\n",
            "Epoch[7127/10000] | loss train:1.489121, test:1.897394 | lr:0.000000\n",
            "Epoch[7128/10000] | loss train:0.964652, test:0.240811 | lr:0.000000\n",
            "Epoch[7129/10000] | loss train:0.836192, test:0.118260 | lr:0.000000\n",
            "Epoch[7130/10000] | loss train:1.089493, test:0.170378 | lr:0.000000\n",
            "Epoch[7131/10000] | loss train:0.631348, test:0.422379 | lr:0.000000\n",
            "Epoch[7132/10000] | loss train:1.572666, test:0.367722 | lr:0.000000\n",
            "Epoch[7133/10000] | loss train:1.395552, test:1.894670 | lr:0.000000\n",
            "Epoch[7134/10000] | loss train:1.291331, test:1.455477 | lr:0.000000\n",
            "Epoch[7135/10000] | loss train:1.735286, test:1.749532 | lr:0.000000\n",
            "Epoch[7136/10000] | loss train:1.519201, test:0.361196 | lr:0.000000\n",
            "Epoch[7137/10000] | loss train:0.989733, test:1.661139 | lr:0.000000\n",
            "Epoch[7138/10000] | loss train:1.914266, test:0.663853 | lr:0.000000\n",
            "Epoch[7139/10000] | loss train:1.025433, test:1.114025 | lr:0.000000\n",
            "Epoch[7140/10000] | loss train:1.747654, test:0.537251 | lr:0.000000\n",
            "Epoch[7141/10000] | loss train:1.846496, test:0.564003 | lr:0.000000\n",
            "Epoch[7142/10000] | loss train:1.864784, test:0.274720 | lr:0.000000\n",
            "Epoch[7143/10000] | loss train:0.986083, test:0.716482 | lr:0.000000\n",
            "Epoch[7144/10000] | loss train:1.533435, test:0.534480 | lr:0.000000\n",
            "Epoch[7145/10000] | loss train:1.882188, test:0.904679 | lr:0.000000\n",
            "Epoch[7146/10000] | loss train:1.603700, test:0.169683 | lr:0.000000\n",
            "Epoch[7147/10000] | loss train:0.746059, test:1.920767 | lr:0.000000\n",
            "Epoch[7148/10000] | loss train:1.452115, test:1.910358 | lr:0.000000\n",
            "Epoch[7149/10000] | loss train:1.339153, test:0.102726 | lr:0.000000\n",
            "Epoch[7150/10000] | loss train:1.126960, test:1.047839 | lr:0.000000\n",
            "Epoch[7151/10000] | loss train:1.428967, test:0.769647 | lr:0.000000\n",
            "Epoch[7152/10000] | loss train:1.339130, test:0.323851 | lr:0.000000\n",
            "Epoch[7153/10000] | loss train:1.221068, test:0.350949 | lr:0.000000\n",
            "Epoch[7154/10000] | loss train:1.204085, test:0.248942 | lr:0.000000\n",
            "Epoch[7155/10000] | loss train:0.912854, test:0.226507 | lr:0.000000\n",
            "Epoch[7156/10000] | loss train:0.949308, test:0.572147 | lr:0.000000\n",
            "Epoch[7157/10000] | loss train:1.322311, test:0.279701 | lr:0.000000\n",
            "Epoch[7158/10000] | loss train:1.312987, test:0.776583 | lr:0.000000\n",
            "Epoch[7159/10000] | loss train:1.144418, test:1.205038 | lr:0.000000\n",
            "Epoch[7160/10000] | loss train:1.239620, test:0.742092 | lr:0.000000\n",
            "Epoch[7161/10000] | loss train:1.260197, test:1.059237 | lr:0.000000\n",
            "Epoch[7162/10000] | loss train:1.044534, test:0.965640 | lr:0.000000\n",
            "Epoch[7163/10000] | loss train:1.330059, test:0.361867 | lr:0.000000\n",
            "Epoch[7164/10000] | loss train:0.910094, test:0.636457 | lr:0.000000\n",
            "Epoch[7165/10000] | loss train:1.980762, test:0.489585 | lr:0.000000\n",
            "Epoch[7166/10000] | loss train:1.710725, test:1.149658 | lr:0.000000\n",
            "Epoch[7167/10000] | loss train:1.311349, test:0.212302 | lr:0.000000\n",
            "Epoch[7168/10000] | loss train:1.365625, test:0.326459 | lr:0.000000\n",
            "Epoch[7169/10000] | loss train:1.053210, test:0.133790 | lr:0.000000\n",
            "Epoch[7170/10000] | loss train:0.889481, test:1.125524 | lr:0.000000\n",
            "Epoch[7171/10000] | loss train:0.877799, test:0.852426 | lr:0.000000\n",
            "Epoch[7172/10000] | loss train:1.508630, test:0.209433 | lr:0.000000\n",
            "Epoch[7173/10000] | loss train:0.933722, test:0.336031 | lr:0.000000\n",
            "Epoch[7174/10000] | loss train:1.052129, test:0.280512 | lr:0.000000\n",
            "Epoch[7175/10000] | loss train:0.737006, test:0.215458 | lr:0.000000\n",
            "Epoch[7176/10000] | loss train:0.779254, test:0.427828 | lr:0.000000\n",
            "Epoch[7177/10000] | loss train:0.873095, test:0.127027 | lr:0.000000\n",
            "Epoch[7178/10000] | loss train:0.974456, test:0.731339 | lr:0.000000\n",
            "Epoch[7179/10000] | loss train:1.737533, test:0.850283 | lr:0.000000\n",
            "Epoch[7180/10000] | loss train:0.910105, test:0.235908 | lr:0.000000\n",
            "Epoch[7181/10000] | loss train:2.595714, test:0.304653 | lr:0.000000\n",
            "Epoch[7182/10000] | loss train:0.813895, test:0.216417 | lr:0.000000\n",
            "Epoch[7183/10000] | loss train:0.927752, test:0.634872 | lr:0.000000\n",
            "Epoch[7184/10000] | loss train:1.525597, test:0.721988 | lr:0.000000\n",
            "Epoch[7185/10000] | loss train:0.822727, test:1.179819 | lr:0.000000\n",
            "Epoch[7186/10000] | loss train:1.110487, test:0.331893 | lr:0.000000\n",
            "Epoch[7187/10000] | loss train:2.763636, test:1.465984 | lr:0.000000\n",
            "Epoch[7188/10000] | loss train:1.224388, test:0.296459 | lr:0.000000\n",
            "Epoch[7189/10000] | loss train:1.427402, test:1.458253 | lr:0.000000\n",
            "Epoch[7190/10000] | loss train:1.307734, test:0.051623 | lr:0.000000\n",
            "Epoch[7191/10000] | loss train:0.799781, test:0.162048 | lr:0.000000\n",
            "Epoch[7192/10000] | loss train:1.607161, test:0.790365 | lr:0.000000\n",
            "Epoch[7193/10000] | loss train:1.224726, test:0.694911 | lr:0.000000\n",
            "Epoch[7194/10000] | loss train:1.208965, test:0.499517 | lr:0.000000\n",
            "Epoch[7195/10000] | loss train:0.844397, test:0.380879 | lr:0.000000\n",
            "Epoch[7196/10000] | loss train:1.485688, test:0.204608 | lr:0.000000\n",
            "Epoch[7197/10000] | loss train:1.238679, test:0.356003 | lr:0.000000\n",
            "Epoch[7198/10000] | loss train:0.835008, test:0.446348 | lr:0.000000\n",
            "Epoch[7199/10000] | loss train:1.758430, test:0.286052 | lr:0.000000\n",
            "Epoch[7200/10000] | loss train:1.909727, test:1.454584 | lr:0.000000\n",
            "Epoch[7201/10000] | loss train:0.669786, test:0.705737 | lr:0.000000\n",
            "Epoch[7202/10000] | loss train:1.138684, test:0.787356 | lr:0.000000\n",
            "Epoch[7203/10000] | loss train:1.528946, test:0.267648 | lr:0.000000\n",
            "Epoch[7204/10000] | loss train:0.709706, test:0.376119 | lr:0.000000\n",
            "Epoch[7205/10000] | loss train:1.567228, test:0.593087 | lr:0.000000\n",
            "Epoch[7206/10000] | loss train:2.623949, test:0.455137 | lr:0.000000\n",
            "Epoch[7207/10000] | loss train:1.906610, test:0.341228 | lr:0.000000\n",
            "Epoch[7208/10000] | loss train:1.268749, test:1.006720 | lr:0.000000\n",
            "Epoch[7209/10000] | loss train:0.964979, test:0.634577 | lr:0.000000\n",
            "Epoch[7210/10000] | loss train:0.698696, test:0.975652 | lr:0.000000\n",
            "Epoch[7211/10000] | loss train:0.781233, test:0.149171 | lr:0.000000\n",
            "Epoch[7212/10000] | loss train:1.303586, test:0.865972 | lr:0.000000\n",
            "Epoch[7213/10000] | loss train:1.430536, test:0.266676 | lr:0.000000\n",
            "Epoch[7214/10000] | loss train:0.965842, test:1.285850 | lr:0.000000\n",
            "Epoch[7215/10000] | loss train:1.043359, test:0.707388 | lr:0.000000\n",
            "Epoch[7216/10000] | loss train:1.330492, test:1.654032 | lr:0.000000\n",
            "Epoch[7217/10000] | loss train:2.100421, test:0.202809 | lr:0.000000\n",
            "Epoch[7218/10000] | loss train:2.222761, test:0.295612 | lr:0.000000\n",
            "Epoch[7219/10000] | loss train:1.289034, test:0.318467 | lr:0.000000\n",
            "Epoch[7220/10000] | loss train:1.924291, test:0.759841 | lr:0.000000\n",
            "Epoch[7221/10000] | loss train:1.382713, test:1.898847 | lr:0.000000\n",
            "Epoch[7222/10000] | loss train:1.263412, test:0.710084 | lr:0.000000\n",
            "Epoch[7223/10000] | loss train:0.738096, test:0.271152 | lr:0.000000\n",
            "Epoch[7224/10000] | loss train:1.830957, test:0.285854 | lr:0.000000\n",
            "Epoch[7225/10000] | loss train:1.709998, test:0.268470 | lr:0.000000\n",
            "Epoch[7226/10000] | loss train:0.859205, test:0.449366 | lr:0.000000\n",
            "Epoch[7227/10000] | loss train:2.389311, test:0.696789 | lr:0.000000\n",
            "Epoch[7228/10000] | loss train:1.526070, test:2.108788 | lr:0.000000\n",
            "Epoch[7229/10000] | loss train:1.261226, test:0.500753 | lr:0.000000\n",
            "Epoch[7230/10000] | loss train:0.899633, test:0.415316 | lr:0.000000\n",
            "Epoch[7231/10000] | loss train:1.637542, test:2.661201 | lr:0.000000\n",
            "Epoch[7232/10000] | loss train:1.305778, test:0.237528 | lr:0.000000\n",
            "Epoch[7233/10000] | loss train:1.047598, test:1.116409 | lr:0.000000\n",
            "Epoch[7234/10000] | loss train:1.007322, test:0.265747 | lr:0.000000\n",
            "Epoch[7235/10000] | loss train:1.376629, test:1.260073 | lr:0.000000\n",
            "Epoch[7236/10000] | loss train:1.523191, test:0.701467 | lr:0.000000\n",
            "Epoch[7237/10000] | loss train:0.960614, test:1.183943 | lr:0.000000\n",
            "Epoch[7238/10000] | loss train:1.726216, test:0.359649 | lr:0.000000\n",
            "Epoch[7239/10000] | loss train:2.266880, test:1.155862 | lr:0.000000\n",
            "Epoch[7240/10000] | loss train:1.402850, test:0.199679 | lr:0.000000\n",
            "Epoch[7241/10000] | loss train:1.005461, test:0.554707 | lr:0.000000\n",
            "Epoch[7242/10000] | loss train:1.271272, test:0.892779 | lr:0.000000\n",
            "Epoch[7243/10000] | loss train:0.813482, test:0.575598 | lr:0.000000\n",
            "Epoch[7244/10000] | loss train:1.358293, test:0.797945 | lr:0.000000\n",
            "Epoch[7245/10000] | loss train:0.983835, test:1.227550 | lr:0.000000\n",
            "Epoch[7246/10000] | loss train:1.458244, test:0.489462 | lr:0.000000\n",
            "Epoch[7247/10000] | loss train:1.415636, test:0.682868 | lr:0.000000\n",
            "Epoch[7248/10000] | loss train:1.714768, test:0.060723 | lr:0.000000\n",
            "Epoch[7249/10000] | loss train:1.785963, test:0.854980 | lr:0.000000\n",
            "Epoch[7250/10000] | loss train:0.722323, test:0.559810 | lr:0.000000\n",
            "Epoch[7251/10000] | loss train:0.841815, test:0.341625 | lr:0.000000\n",
            "Epoch[7252/10000] | loss train:1.480376, test:0.732596 | lr:0.000000\n",
            "Epoch[7253/10000] | loss train:0.812348, test:0.204904 | lr:0.000000\n",
            "Epoch[7254/10000] | loss train:1.142887, test:0.138141 | lr:0.000000\n",
            "Epoch[7255/10000] | loss train:0.823397, test:0.364874 | lr:0.000000\n",
            "Epoch[7256/10000] | loss train:2.922406, test:0.523841 | lr:0.000000\n",
            "Epoch[7257/10000] | loss train:1.236240, test:0.722879 | lr:0.000000\n",
            "Epoch[7258/10000] | loss train:1.679663, test:0.589561 | lr:0.000000\n",
            "Epoch[7259/10000] | loss train:1.045310, test:0.498738 | lr:0.000000\n",
            "Epoch[7260/10000] | loss train:0.648938, test:1.667334 | lr:0.000000\n",
            "Epoch[7261/10000] | loss train:0.743170, test:2.255296 | lr:0.000000\n",
            "Epoch[7262/10000] | loss train:0.872236, test:0.859693 | lr:0.000000\n",
            "Epoch[7263/10000] | loss train:1.148598, test:0.196885 | lr:0.000000\n",
            "Epoch[7264/10000] | loss train:1.049934, test:1.153530 | lr:0.000000\n",
            "Epoch[7265/10000] | loss train:0.862094, test:1.768749 | lr:0.000000\n",
            "Epoch[7266/10000] | loss train:1.097743, test:0.440428 | lr:0.000000\n",
            "Epoch[7267/10000] | loss train:1.025988, test:0.204473 | lr:0.000000\n",
            "Epoch[7268/10000] | loss train:0.973886, test:0.526573 | lr:0.000000\n",
            "Epoch[7269/10000] | loss train:2.398334, test:0.571059 | lr:0.000000\n",
            "Epoch[7270/10000] | loss train:0.843320, test:0.186987 | lr:0.000000\n",
            "Epoch[7271/10000] | loss train:1.153217, test:0.455360 | lr:0.000000\n",
            "Epoch[7272/10000] | loss train:1.005957, test:1.093887 | lr:0.000000\n",
            "Epoch[7273/10000] | loss train:0.899320, test:0.320504 | lr:0.000000\n",
            "Epoch[7274/10000] | loss train:1.644336, test:1.276861 | lr:0.000000\n",
            "Epoch[7275/10000] | loss train:0.661435, test:0.352781 | lr:0.000000\n",
            "Epoch[7276/10000] | loss train:1.110090, test:0.378879 | lr:0.000000\n",
            "Epoch[7277/10000] | loss train:1.381060, test:0.104064 | lr:0.000000\n",
            "Epoch[7278/10000] | loss train:1.363844, test:0.537836 | lr:0.000000\n",
            "Epoch[7279/10000] | loss train:1.425584, test:0.192054 | lr:0.000000\n",
            "Epoch[7280/10000] | loss train:1.346307, test:0.679782 | lr:0.000000\n",
            "Epoch[7281/10000] | loss train:2.103924, test:1.197659 | lr:0.000000\n",
            "Epoch[7282/10000] | loss train:1.553164, test:0.666030 | lr:0.000000\n",
            "Epoch[7283/10000] | loss train:0.905257, test:1.012799 | lr:0.000000\n",
            "Epoch[7284/10000] | loss train:1.739626, test:1.406554 | lr:0.000000\n",
            "Epoch[7285/10000] | loss train:2.091706, test:1.191790 | lr:0.000000\n",
            "Epoch[7286/10000] | loss train:1.110185, test:0.977002 | lr:0.000000\n",
            "Epoch[7287/10000] | loss train:1.411562, test:0.636333 | lr:0.000000\n",
            "Epoch[7288/10000] | loss train:1.008296, test:0.254050 | lr:0.000000\n",
            "Epoch[7289/10000] | loss train:1.291494, test:0.348583 | lr:0.000000\n",
            "Epoch[7290/10000] | loss train:0.864421, test:0.334121 | lr:0.000000\n",
            "Epoch[7291/10000] | loss train:1.192978, test:1.352639 | lr:0.000000\n",
            "Epoch[7292/10000] | loss train:1.271941, test:1.306829 | lr:0.000000\n",
            "Epoch[7293/10000] | loss train:2.176429, test:0.116982 | lr:0.000000\n",
            "Epoch[7294/10000] | loss train:1.563590, test:1.086838 | lr:0.000000\n",
            "Epoch[7295/10000] | loss train:1.153032, test:0.153232 | lr:0.000000\n",
            "Epoch[7296/10000] | loss train:1.153344, test:1.327154 | lr:0.000000\n",
            "Epoch[7297/10000] | loss train:1.282431, test:0.712835 | lr:0.000000\n",
            "Epoch[7298/10000] | loss train:1.072539, test:0.588821 | lr:0.000000\n",
            "Epoch[7299/10000] | loss train:1.620766, test:0.250230 | lr:0.000000\n",
            "Epoch[7300/10000] | loss train:1.122098, test:0.288535 | lr:0.000000\n",
            "Epoch[7301/10000] | loss train:1.641716, test:0.106628 | lr:0.000000\n",
            "Epoch[7302/10000] | loss train:0.832859, test:0.728572 | lr:0.000000\n",
            "Epoch[7303/10000] | loss train:0.977425, test:0.190682 | lr:0.000000\n",
            "Epoch[7304/10000] | loss train:1.363773, test:0.666628 | lr:0.000000\n",
            "Epoch[7305/10000] | loss train:1.007157, test:1.118049 | lr:0.000000\n",
            "Epoch[7306/10000] | loss train:0.708887, test:0.188000 | lr:0.000000\n",
            "Epoch[7307/10000] | loss train:1.427241, test:0.315094 | lr:0.000000\n",
            "Epoch[7308/10000] | loss train:0.630354, test:0.398442 | lr:0.000000\n",
            "Epoch[7309/10000] | loss train:1.142183, test:0.313165 | lr:0.000000\n",
            "Epoch[7310/10000] | loss train:1.779952, test:0.243567 | lr:0.000000\n",
            "Epoch[7311/10000] | loss train:0.988198, test:0.329340 | lr:0.000000\n",
            "Epoch[7312/10000] | loss train:1.134700, test:1.385623 | lr:0.000000\n",
            "Epoch[7313/10000] | loss train:0.942838, test:0.528188 | lr:0.000000\n",
            "Epoch[7314/10000] | loss train:1.314692, test:0.675684 | lr:0.000000\n",
            "Epoch[7315/10000] | loss train:1.044005, test:0.223322 | lr:0.000000\n",
            "Epoch[7316/10000] | loss train:2.701966, test:0.943820 | lr:0.000000\n",
            "Epoch[7317/10000] | loss train:1.173216, test:0.679335 | lr:0.000000\n",
            "Epoch[7318/10000] | loss train:1.120731, test:0.684907 | lr:0.000000\n",
            "Epoch[7319/10000] | loss train:1.295018, test:1.261226 | lr:0.000000\n",
            "Epoch[7320/10000] | loss train:1.105054, test:2.157391 | lr:0.000000\n",
            "Epoch[7321/10000] | loss train:1.912160, test:0.600713 | lr:0.000000\n",
            "Epoch[7322/10000] | loss train:0.869895, test:0.427681 | lr:0.000000\n",
            "Epoch[7323/10000] | loss train:1.034557, test:0.239634 | lr:0.000000\n",
            "Epoch[7324/10000] | loss train:0.971008, test:0.560924 | lr:0.000000\n",
            "Epoch[7325/10000] | loss train:1.947725, test:0.311583 | lr:0.000000\n",
            "Epoch[7326/10000] | loss train:1.262040, test:0.903584 | lr:0.000000\n",
            "Epoch[7327/10000] | loss train:1.096792, test:0.783612 | lr:0.000000\n",
            "Epoch[7328/10000] | loss train:0.846620, test:0.068579 | lr:0.000000\n",
            "Epoch[7329/10000] | loss train:0.974508, test:0.709647 | lr:0.000000\n",
            "Epoch[7330/10000] | loss train:1.296300, test:0.097894 | lr:0.000000\n",
            "Epoch[7331/10000] | loss train:0.832451, test:0.310991 | lr:0.000000\n",
            "Epoch[7332/10000] | loss train:1.130385, test:0.393635 | lr:0.000000\n",
            "Epoch[7333/10000] | loss train:1.380842, test:1.273218 | lr:0.000000\n",
            "Epoch[7334/10000] | loss train:1.928457, test:0.236448 | lr:0.000000\n",
            "Epoch[7335/10000] | loss train:0.931411, test:2.010240 | lr:0.000000\n",
            "Epoch[7336/10000] | loss train:0.972491, test:0.053947 | lr:0.000000\n",
            "Epoch[7337/10000] | loss train:1.167915, test:0.058889 | lr:0.000000\n",
            "Epoch[7338/10000] | loss train:1.887760, test:1.114016 | lr:0.000000\n",
            "Epoch[7339/10000] | loss train:1.378589, test:0.496493 | lr:0.000000\n",
            "Epoch[7340/10000] | loss train:1.343602, test:0.926050 | lr:0.000000\n",
            "Epoch[7341/10000] | loss train:1.063459, test:1.687004 | lr:0.000000\n",
            "Epoch[7342/10000] | loss train:1.078573, test:1.060412 | lr:0.000000\n",
            "Epoch[7343/10000] | loss train:1.080497, test:0.268314 | lr:0.000000\n",
            "Epoch[7344/10000] | loss train:1.329292, test:0.180198 | lr:0.000000\n",
            "Epoch[7345/10000] | loss train:0.608232, test:1.040970 | lr:0.000000\n",
            "Epoch[7346/10000] | loss train:1.452630, test:0.386596 | lr:0.000000\n",
            "Epoch[7347/10000] | loss train:1.310065, test:1.156453 | lr:0.000000\n",
            "Epoch[7348/10000] | loss train:0.710218, test:0.887604 | lr:0.000000\n",
            "Epoch[7349/10000] | loss train:2.042119, test:0.338530 | lr:0.000000\n",
            "Epoch[7350/10000] | loss train:1.230661, test:0.299317 | lr:0.000000\n",
            "Epoch[7351/10000] | loss train:0.944261, test:0.402207 | lr:0.000000\n",
            "Epoch[7352/10000] | loss train:1.443374, test:0.141027 | lr:0.000000\n",
            "Epoch[7353/10000] | loss train:1.828664, test:0.667778 | lr:0.000000\n",
            "Epoch[7354/10000] | loss train:2.065131, test:0.755641 | lr:0.000000\n",
            "Epoch[7355/10000] | loss train:1.644696, test:0.521252 | lr:0.000000\n",
            "Epoch[7356/10000] | loss train:0.777753, test:2.238707 | lr:0.000000\n",
            "Epoch[7357/10000] | loss train:0.913221, test:0.801222 | lr:0.000000\n",
            "Epoch[7358/10000] | loss train:1.191242, test:0.637009 | lr:0.000000\n",
            "Epoch[7359/10000] | loss train:0.997272, test:1.518309 | lr:0.000000\n",
            "Epoch[7360/10000] | loss train:0.723102, test:2.135237 | lr:0.000000\n",
            "Epoch[7361/10000] | loss train:0.938616, test:0.349856 | lr:0.000000\n",
            "Epoch[7362/10000] | loss train:2.298525, test:1.194513 | lr:0.000000\n",
            "Epoch[7363/10000] | loss train:1.564007, test:0.634190 | lr:0.000000\n",
            "Epoch[7364/10000] | loss train:1.112000, test:1.090911 | lr:0.000000\n",
            "Epoch[7365/10000] | loss train:1.161346, test:0.357617 | lr:0.000000\n",
            "Epoch[7366/10000] | loss train:1.852705, test:0.296772 | lr:0.000000\n",
            "Epoch[7367/10000] | loss train:0.759429, test:0.787907 | lr:0.000000\n",
            "Epoch[7368/10000] | loss train:1.647839, test:0.249165 | lr:0.000000\n",
            "Epoch[7369/10000] | loss train:1.253411, test:0.513347 | lr:0.000000\n",
            "Epoch[7370/10000] | loss train:1.161552, test:0.473158 | lr:0.000000\n",
            "Epoch[7371/10000] | loss train:1.174037, test:0.322205 | lr:0.000000\n",
            "Epoch[7372/10000] | loss train:1.415455, test:1.025715 | lr:0.000000\n",
            "Epoch[7373/10000] | loss train:1.544510, test:0.253506 | lr:0.000000\n",
            "Epoch[7374/10000] | loss train:2.131322, test:0.240766 | lr:0.000000\n",
            "Epoch[7375/10000] | loss train:0.952095, test:0.582767 | lr:0.000000\n",
            "Epoch[7376/10000] | loss train:0.873428, test:1.245192 | lr:0.000000\n",
            "Epoch[7377/10000] | loss train:1.746693, test:1.333565 | lr:0.000000\n",
            "Epoch[7378/10000] | loss train:1.453436, test:0.330134 | lr:0.000000\n",
            "Epoch[7379/10000] | loss train:0.865757, test:0.210865 | lr:0.000000\n",
            "Epoch[7380/10000] | loss train:1.378232, test:0.424747 | lr:0.000000\n",
            "Epoch[7381/10000] | loss train:0.825625, test:0.352743 | lr:0.000000\n",
            "Epoch[7382/10000] | loss train:2.368356, test:0.420528 | lr:0.000000\n",
            "Epoch[7383/10000] | loss train:1.702805, test:1.368556 | lr:0.000000\n",
            "Epoch[7384/10000] | loss train:1.225609, test:1.574423 | lr:0.000000\n",
            "Epoch[7385/10000] | loss train:1.039128, test:0.321369 | lr:0.000000\n",
            "Epoch[7386/10000] | loss train:1.068955, test:1.340331 | lr:0.000000\n",
            "Epoch[7387/10000] | loss train:1.664956, test:0.181197 | lr:0.000000\n",
            "Epoch[7388/10000] | loss train:1.036324, test:0.884569 | lr:0.000000\n",
            "Epoch[7389/10000] | loss train:1.531969, test:0.300584 | lr:0.000000\n",
            "Epoch[7390/10000] | loss train:1.002114, test:0.317657 | lr:0.000000\n",
            "Epoch[7391/10000] | loss train:1.726419, test:0.494587 | lr:0.000000\n",
            "Epoch[7392/10000] | loss train:1.461927, test:1.233762 | lr:0.000000\n",
            "Epoch[7393/10000] | loss train:0.845130, test:0.259065 | lr:0.000000\n",
            "Epoch[7394/10000] | loss train:2.052489, test:0.966575 | lr:0.000000\n",
            "Epoch[7395/10000] | loss train:1.322097, test:0.653713 | lr:0.000000\n",
            "Epoch[7396/10000] | loss train:2.071497, test:1.499116 | lr:0.000000\n",
            "Epoch[7397/10000] | loss train:1.792220, test:0.484766 | lr:0.000000\n",
            "Epoch[7398/10000] | loss train:0.782849, test:1.232102 | lr:0.000000\n",
            "Epoch[7399/10000] | loss train:1.880382, test:0.222897 | lr:0.000000\n",
            "Epoch[7400/10000] | loss train:0.787332, test:0.832762 | lr:0.000000\n",
            "Epoch[7401/10000] | loss train:1.351671, test:0.328257 | lr:0.000000\n",
            "Epoch[7402/10000] | loss train:1.271453, test:0.448089 | lr:0.000000\n",
            "Epoch[7403/10000] | loss train:1.043210, test:0.594310 | lr:0.000000\n",
            "Epoch[7404/10000] | loss train:1.705079, test:0.870242 | lr:0.000000\n",
            "Epoch[7405/10000] | loss train:1.627720, test:0.508939 | lr:0.000000\n",
            "Epoch[7406/10000] | loss train:0.917608, test:0.223270 | lr:0.000000\n",
            "Epoch[7407/10000] | loss train:1.507962, test:0.873948 | lr:0.000000\n",
            "Epoch[7408/10000] | loss train:1.343062, test:1.782544 | lr:0.000000\n",
            "Epoch[7409/10000] | loss train:1.467319, test:0.463412 | lr:0.000000\n",
            "Epoch[7410/10000] | loss train:1.559547, test:1.122699 | lr:0.000000\n",
            "Epoch[7411/10000] | loss train:2.087421, test:1.215486 | lr:0.000000\n",
            "Epoch[7412/10000] | loss train:0.926131, test:1.212226 | lr:0.000000\n",
            "Epoch[7413/10000] | loss train:2.015690, test:0.237582 | lr:0.000000\n",
            "Epoch[7414/10000] | loss train:1.020672, test:0.092843 | lr:0.000000\n",
            "Epoch[7415/10000] | loss train:1.009390, test:0.546851 | lr:0.000000\n",
            "Epoch[7416/10000] | loss train:1.163237, test:0.256332 | lr:0.000000\n",
            "Epoch[7417/10000] | loss train:1.067375, test:1.338650 | lr:0.000000\n",
            "Epoch[7418/10000] | loss train:0.936818, test:0.489029 | lr:0.000000\n",
            "Epoch[7419/10000] | loss train:0.900525, test:0.136381 | lr:0.000000\n",
            "Epoch[7420/10000] | loss train:1.902600, test:0.332970 | lr:0.000000\n",
            "Epoch[7421/10000] | loss train:2.051934, test:0.616098 | lr:0.000000\n",
            "Epoch[7422/10000] | loss train:1.373673, test:0.315135 | lr:0.000000\n",
            "Epoch[7423/10000] | loss train:0.926842, test:1.585142 | lr:0.000000\n",
            "Epoch[7424/10000] | loss train:1.029339, test:1.361382 | lr:0.000000\n",
            "Epoch[7425/10000] | loss train:0.756476, test:1.766329 | lr:0.000000\n",
            "Epoch[7426/10000] | loss train:0.724952, test:1.091416 | lr:0.000000\n",
            "Epoch[7427/10000] | loss train:0.781279, test:1.051407 | lr:0.000000\n",
            "Epoch[7428/10000] | loss train:1.172280, test:0.245016 | lr:0.000000\n",
            "Epoch[7429/10000] | loss train:1.488265, test:0.337209 | lr:0.000000\n",
            "Epoch[7430/10000] | loss train:0.846804, test:0.304836 | lr:0.000000\n",
            "Epoch[7431/10000] | loss train:1.042043, test:0.648024 | lr:0.000000\n",
            "Epoch[7432/10000] | loss train:1.214651, test:0.200905 | lr:0.000000\n",
            "Epoch[7433/10000] | loss train:1.126295, test:1.663229 | lr:0.000000\n",
            "Epoch[7434/10000] | loss train:1.394721, test:0.371076 | lr:0.000000\n",
            "Epoch[7435/10000] | loss train:0.752248, test:0.774833 | lr:0.000000\n",
            "Epoch[7436/10000] | loss train:1.634747, test:0.671731 | lr:0.000000\n",
            "Epoch[7437/10000] | loss train:1.227401, test:0.215183 | lr:0.000000\n",
            "Epoch[7438/10000] | loss train:0.919056, test:0.473625 | lr:0.000000\n",
            "Epoch[7439/10000] | loss train:0.968490, test:0.225497 | lr:0.000000\n",
            "Epoch[7440/10000] | loss train:0.986083, test:1.973372 | lr:0.000000\n",
            "Epoch[7441/10000] | loss train:1.049571, test:0.312426 | lr:0.000000\n",
            "Epoch[7442/10000] | loss train:1.124320, test:1.013680 | lr:0.000000\n",
            "Epoch[7443/10000] | loss train:0.831667, test:0.478090 | lr:0.000000\n",
            "Epoch[7444/10000] | loss train:0.914385, test:0.506562 | lr:0.000000\n",
            "Epoch[7445/10000] | loss train:1.378891, test:0.335547 | lr:0.000000\n",
            "Epoch[7446/10000] | loss train:1.104916, test:0.536078 | lr:0.000000\n",
            "Epoch[7447/10000] | loss train:1.485901, test:1.087573 | lr:0.000000\n",
            "Epoch[7448/10000] | loss train:1.375000, test:1.730033 | lr:0.000000\n",
            "Epoch[7449/10000] | loss train:0.853191, test:0.204987 | lr:0.000000\n",
            "Epoch[7450/10000] | loss train:1.273804, test:0.523749 | lr:0.000000\n",
            "Epoch[7451/10000] | loss train:1.011419, test:1.416663 | lr:0.000000\n",
            "Epoch[7452/10000] | loss train:1.187221, test:0.639763 | lr:0.000000\n",
            "Epoch[7453/10000] | loss train:1.092924, test:0.536031 | lr:0.000000\n",
            "Epoch[7454/10000] | loss train:1.205416, test:0.276567 | lr:0.000000\n",
            "Epoch[7455/10000] | loss train:0.906371, test:0.358202 | lr:0.000000\n",
            "Epoch[7456/10000] | loss train:1.409984, test:0.350536 | lr:0.000000\n",
            "Epoch[7457/10000] | loss train:0.799660, test:0.535637 | lr:0.000000\n",
            "Epoch[7458/10000] | loss train:0.996845, test:0.585034 | lr:0.000000\n",
            "Epoch[7459/10000] | loss train:0.982078, test:0.608504 | lr:0.000000\n",
            "Epoch[7460/10000] | loss train:1.192515, test:0.673867 | lr:0.000000\n",
            "Epoch[7461/10000] | loss train:1.346780, test:0.954131 | lr:0.000000\n",
            "Epoch[7462/10000] | loss train:0.956637, test:0.649196 | lr:0.000000\n",
            "Epoch[7463/10000] | loss train:1.873434, test:1.173629 | lr:0.000000\n",
            "Epoch[7464/10000] | loss train:1.280969, test:0.386357 | lr:0.000000\n",
            "Epoch[7465/10000] | loss train:2.012876, test:0.279468 | lr:0.000000\n",
            "Epoch[7466/10000] | loss train:1.083143, test:0.547528 | lr:0.000000\n",
            "Epoch[7467/10000] | loss train:1.810915, test:0.434846 | lr:0.000000\n",
            "Epoch[7468/10000] | loss train:1.114050, test:0.500506 | lr:0.000000\n",
            "Epoch[7469/10000] | loss train:1.598019, test:0.145695 | lr:0.000000\n",
            "Epoch[7470/10000] | loss train:1.830203, test:0.527763 | lr:0.000000\n",
            "Epoch[7471/10000] | loss train:2.551161, test:0.476857 | lr:0.000000\n",
            "Epoch[7472/10000] | loss train:1.426542, test:1.882615 | lr:0.000000\n",
            "Epoch[7473/10000] | loss train:1.179554, test:0.402402 | lr:0.000000\n",
            "Epoch[7474/10000] | loss train:0.663116, test:0.596332 | lr:0.000000\n",
            "Epoch[7475/10000] | loss train:0.952327, test:0.323678 | lr:0.000000\n",
            "Epoch[7476/10000] | loss train:2.621758, test:0.637119 | lr:0.000000\n",
            "Epoch[7477/10000] | loss train:1.070218, test:0.199910 | lr:0.000000\n",
            "Epoch[7478/10000] | loss train:1.071654, test:1.307024 | lr:0.000000\n",
            "Epoch[7479/10000] | loss train:1.630228, test:0.587756 | lr:0.000000\n",
            "Epoch[7480/10000] | loss train:1.224384, test:0.546215 | lr:0.000000\n",
            "Epoch[7481/10000] | loss train:0.884567, test:0.321642 | lr:0.000000\n",
            "Epoch[7482/10000] | loss train:0.757946, test:0.388138 | lr:0.000000\n",
            "Epoch[7483/10000] | loss train:0.988240, test:0.788641 | lr:0.000000\n",
            "Epoch[7484/10000] | loss train:1.200439, test:0.456981 | lr:0.000000\n",
            "Epoch[7485/10000] | loss train:0.976617, test:2.023299 | lr:0.000000\n",
            "Epoch[7486/10000] | loss train:1.049085, test:0.515735 | lr:0.000000\n",
            "Epoch[7487/10000] | loss train:0.863573, test:0.785397 | lr:0.000000\n",
            "Epoch[7488/10000] | loss train:1.170212, test:0.495854 | lr:0.000000\n",
            "Epoch[7489/10000] | loss train:1.051068, test:0.954459 | lr:0.000000\n",
            "Epoch[7490/10000] | loss train:1.115951, test:0.687407 | lr:0.000000\n",
            "Epoch[7491/10000] | loss train:1.006456, test:0.195466 | lr:0.000000\n",
            "Epoch[7492/10000] | loss train:1.077083, test:0.549801 | lr:0.000000\n",
            "Epoch[7493/10000] | loss train:0.655357, test:0.137312 | lr:0.000000\n",
            "Epoch[7494/10000] | loss train:1.980134, test:0.636576 | lr:0.000000\n",
            "Epoch[7495/10000] | loss train:1.124940, test:0.420008 | lr:0.000000\n",
            "Epoch[7496/10000] | loss train:1.702867, test:1.296404 | lr:0.000000\n",
            "Epoch[7497/10000] | loss train:1.168031, test:0.379044 | lr:0.000000\n",
            "Epoch[7498/10000] | loss train:1.320898, test:0.302235 | lr:0.000000\n",
            "Epoch[7499/10000] | loss train:1.291402, test:1.103368 | lr:0.000000\n",
            "Epoch[7500/10000] | loss train:1.303770, test:0.313672 | lr:0.000000\n",
            "Epoch[7501/10000] | loss train:2.486319, test:0.177977 | lr:0.000000\n",
            "Epoch[7502/10000] | loss train:1.185640, test:0.209709 | lr:0.000000\n",
            "Epoch[7503/10000] | loss train:2.039198, test:0.462501 | lr:0.000000\n",
            "Epoch[7504/10000] | loss train:0.830091, test:0.591310 | lr:0.000000\n",
            "Epoch[7505/10000] | loss train:1.072366, test:1.093245 | lr:0.000000\n",
            "Epoch[7506/10000] | loss train:0.838150, test:0.213969 | lr:0.000000\n",
            "Epoch[7507/10000] | loss train:1.502523, test:0.293722 | lr:0.000000\n",
            "Epoch[7508/10000] | loss train:1.178116, test:1.232008 | lr:0.000000\n",
            "Epoch[7509/10000] | loss train:1.124316, test:1.939220 | lr:0.000000\n",
            "Epoch[7510/10000] | loss train:1.727615, test:1.199216 | lr:0.000000\n",
            "Epoch[7511/10000] | loss train:0.871309, test:0.244640 | lr:0.000000\n",
            "Epoch[7512/10000] | loss train:1.111860, test:2.136451 | lr:0.000000\n",
            "Epoch[7513/10000] | loss train:1.484719, test:0.236464 | lr:0.000000\n",
            "Epoch[7514/10000] | loss train:1.442482, test:0.520368 | lr:0.000000\n",
            "Epoch[7515/10000] | loss train:0.895222, test:0.196439 | lr:0.000000\n",
            "Epoch[7516/10000] | loss train:0.932222, test:0.289736 | lr:0.000000\n",
            "Epoch[7517/10000] | loss train:1.549324, test:0.831456 | lr:0.000000\n",
            "Epoch[7518/10000] | loss train:0.767444, test:0.047848 | lr:0.000000\n",
            "Epoch[7519/10000] | loss train:1.348241, test:0.339011 | lr:0.000000\n",
            "Epoch[7520/10000] | loss train:1.747333, test:1.043047 | lr:0.000000\n",
            "Epoch[7521/10000] | loss train:2.367002, test:0.143024 | lr:0.000000\n",
            "Epoch[7522/10000] | loss train:1.562726, test:0.239555 | lr:0.000000\n",
            "Epoch[7523/10000] | loss train:1.485706, test:0.647803 | lr:0.000000\n",
            "Epoch[7524/10000] | loss train:0.749755, test:0.384035 | lr:0.000000\n",
            "Epoch[7525/10000] | loss train:2.545701, test:0.336166 | lr:0.000000\n",
            "Epoch[7526/10000] | loss train:1.264646, test:0.124399 | lr:0.000000\n",
            "Epoch[7527/10000] | loss train:2.065225, test:1.163278 | lr:0.000000\n",
            "Epoch[7528/10000] | loss train:1.550701, test:0.330929 | lr:0.000000\n",
            "Epoch[7529/10000] | loss train:2.426054, test:1.588345 | lr:0.000000\n",
            "Epoch[7530/10000] | loss train:1.253054, test:0.529844 | lr:0.000000\n",
            "Epoch[7531/10000] | loss train:1.137690, test:0.238335 | lr:0.000000\n",
            "Epoch[7532/10000] | loss train:1.089731, test:0.258288 | lr:0.000000\n",
            "Epoch[7533/10000] | loss train:0.808718, test:0.110764 | lr:0.000000\n",
            "Epoch[7534/10000] | loss train:1.128928, test:0.325040 | lr:0.000000\n",
            "Epoch[7535/10000] | loss train:1.069167, test:0.753855 | lr:0.000000\n",
            "Epoch[7536/10000] | loss train:1.013342, test:1.101187 | lr:0.000000\n",
            "Epoch[7537/10000] | loss train:1.276145, test:0.786360 | lr:0.000000\n",
            "Epoch[7538/10000] | loss train:1.034691, test:1.329710 | lr:0.000000\n",
            "Epoch[7539/10000] | loss train:1.313594, test:0.223259 | lr:0.000000\n",
            "Epoch[7540/10000] | loss train:1.085344, test:0.662774 | lr:0.000000\n",
            "Epoch[7541/10000] | loss train:0.856630, test:0.401802 | lr:0.000000\n",
            "Epoch[7542/10000] | loss train:1.211675, test:0.053369 | lr:0.000000\n",
            "Epoch[7543/10000] | loss train:1.953889, test:0.564382 | lr:0.000000\n",
            "Epoch[7544/10000] | loss train:1.832482, test:0.604651 | lr:0.000000\n",
            "Epoch[7545/10000] | loss train:1.176400, test:1.232399 | lr:0.000000\n",
            "Epoch[7546/10000] | loss train:1.345106, test:0.698724 | lr:0.000000\n",
            "Epoch[7547/10000] | loss train:1.226959, test:0.255821 | lr:0.000000\n",
            "Epoch[7548/10000] | loss train:2.024573, test:0.773877 | lr:0.000000\n",
            "Epoch[7549/10000] | loss train:1.625144, test:0.205575 | lr:0.000000\n",
            "Epoch[7550/10000] | loss train:1.303642, test:0.837699 | lr:0.000000\n",
            "Epoch[7551/10000] | loss train:1.455227, test:1.288606 | lr:0.000000\n",
            "Epoch[7552/10000] | loss train:1.172117, test:0.185830 | lr:0.000000\n",
            "Epoch[7553/10000] | loss train:1.280050, test:1.161225 | lr:0.000000\n",
            "Epoch[7554/10000] | loss train:0.994260, test:0.310238 | lr:0.000000\n",
            "Epoch[7555/10000] | loss train:1.281801, test:0.347830 | lr:0.000000\n",
            "Epoch[7556/10000] | loss train:1.043048, test:1.455802 | lr:0.000000\n",
            "Epoch[7557/10000] | loss train:2.041337, test:1.840898 | lr:0.000000\n",
            "Epoch[7558/10000] | loss train:1.309193, test:0.693651 | lr:0.000000\n",
            "Epoch[7559/10000] | loss train:1.153589, test:0.135691 | lr:0.000000\n",
            "Epoch[7560/10000] | loss train:0.944291, test:1.054007 | lr:0.000000\n",
            "Epoch[7561/10000] | loss train:1.034018, test:1.066657 | lr:0.000000\n",
            "Epoch[7562/10000] | loss train:1.308488, test:0.205689 | lr:0.000000\n",
            "Epoch[7563/10000] | loss train:1.438811, test:0.324777 | lr:0.000000\n",
            "Epoch[7564/10000] | loss train:1.412395, test:0.195901 | lr:0.000000\n",
            "Epoch[7565/10000] | loss train:1.642912, test:1.040831 | lr:0.000000\n",
            "Epoch[7566/10000] | loss train:2.272532, test:0.644420 | lr:0.000000\n",
            "Epoch[7567/10000] | loss train:1.450016, test:0.571387 | lr:0.000000\n",
            "Epoch[7568/10000] | loss train:1.328527, test:0.355600 | lr:0.000000\n",
            "Epoch[7569/10000] | loss train:1.922489, test:0.406013 | lr:0.000000\n",
            "Epoch[7570/10000] | loss train:1.793185, test:0.820104 | lr:0.000000\n",
            "Epoch[7571/10000] | loss train:0.776346, test:0.532668 | lr:0.000000\n",
            "Epoch[7572/10000] | loss train:1.058673, test:1.001654 | lr:0.000000\n",
            "Epoch[7573/10000] | loss train:1.021225, test:0.494154 | lr:0.000000\n",
            "Epoch[7574/10000] | loss train:1.459567, test:0.667127 | lr:0.000000\n",
            "Epoch[7575/10000] | loss train:0.800920, test:0.214488 | lr:0.000000\n",
            "Epoch[7576/10000] | loss train:1.128617, test:0.050663 | lr:0.000000\n",
            "Epoch[7577/10000] | loss train:1.179065, test:0.275230 | lr:0.000000\n",
            "Epoch[7578/10000] | loss train:1.833240, test:0.577768 | lr:0.000000\n",
            "Epoch[7579/10000] | loss train:0.738925, test:0.544754 | lr:0.000000\n",
            "Epoch[7580/10000] | loss train:1.084829, test:0.318832 | lr:0.000000\n",
            "Epoch[7581/10000] | loss train:1.297130, test:0.426997 | lr:0.000000\n",
            "Epoch[7582/10000] | loss train:1.509170, test:0.237112 | lr:0.000000\n",
            "Epoch[7583/10000] | loss train:1.528905, test:0.414464 | lr:0.000000\n",
            "Epoch[7584/10000] | loss train:1.801472, test:1.424071 | lr:0.000000\n",
            "Epoch[7585/10000] | loss train:0.647402, test:0.782192 | lr:0.000000\n",
            "Epoch[7586/10000] | loss train:0.725527, test:0.561772 | lr:0.000000\n",
            "Epoch[7587/10000] | loss train:1.832110, test:0.173679 | lr:0.000000\n",
            "Epoch[7588/10000] | loss train:1.014902, test:0.242030 | lr:0.000000\n",
            "Epoch[7589/10000] | loss train:1.288076, test:1.227954 | lr:0.000000\n",
            "Epoch[7590/10000] | loss train:2.837512, test:1.841838 | lr:0.000000\n",
            "Epoch[7591/10000] | loss train:1.462155, test:0.479405 | lr:0.000000\n",
            "Epoch[7592/10000] | loss train:1.222303, test:0.101155 | lr:0.000000\n",
            "Epoch[7593/10000] | loss train:1.075898, test:1.179452 | lr:0.000000\n",
            "Epoch[7594/10000] | loss train:1.275096, test:0.457566 | lr:0.000000\n",
            "Epoch[7595/10000] | loss train:2.444078, test:2.031612 | lr:0.000000\n",
            "Epoch[7596/10000] | loss train:1.575648, test:0.802892 | lr:0.000000\n",
            "Epoch[7597/10000] | loss train:1.106512, test:0.233432 | lr:0.000000\n",
            "Epoch[7598/10000] | loss train:0.794017, test:0.655304 | lr:0.000000\n",
            "Epoch[7599/10000] | loss train:1.577445, test:0.804086 | lr:0.000000\n",
            "Epoch[7600/10000] | loss train:1.102267, test:1.683584 | lr:0.000000\n",
            "Epoch[7601/10000] | loss train:1.373908, test:0.678173 | lr:0.000000\n",
            "Epoch[7602/10000] | loss train:2.377923, test:1.075252 | lr:0.000000\n",
            "Epoch[7603/10000] | loss train:1.059581, test:1.285113 | lr:0.000000\n",
            "Epoch[7604/10000] | loss train:0.797216, test:1.708428 | lr:0.000000\n",
            "Epoch[7605/10000] | loss train:1.390517, test:1.509500 | lr:0.000000\n",
            "Epoch[7606/10000] | loss train:1.656916, test:0.396565 | lr:0.000000\n",
            "Epoch[7607/10000] | loss train:1.101291, test:0.643180 | lr:0.000000\n",
            "Epoch[7608/10000] | loss train:1.375443, test:0.706375 | lr:0.000000\n",
            "Epoch[7609/10000] | loss train:1.724958, test:0.533038 | lr:0.000000\n",
            "Epoch[7610/10000] | loss train:0.771849, test:0.444064 | lr:0.000000\n",
            "Epoch[7611/10000] | loss train:1.210583, test:0.149665 | lr:0.000000\n",
            "Epoch[7612/10000] | loss train:1.379477, test:0.052414 | lr:0.000000\n",
            "Epoch[7613/10000] | loss train:1.319362, test:1.036240 | lr:0.000000\n",
            "Epoch[7614/10000] | loss train:1.879343, test:0.262602 | lr:0.000000\n",
            "Epoch[7615/10000] | loss train:1.392732, test:0.252861 | lr:0.000000\n",
            "Epoch[7616/10000] | loss train:1.222417, test:0.302630 | lr:0.000000\n",
            "Epoch[7617/10000] | loss train:1.072523, test:0.409014 | lr:0.000000\n",
            "Epoch[7618/10000] | loss train:0.997182, test:0.569228 | lr:0.000000\n",
            "Epoch[7619/10000] | loss train:1.575431, test:0.710083 | lr:0.000000\n",
            "Epoch[7620/10000] | loss train:1.955439, test:0.324230 | lr:0.000000\n",
            "Epoch[7621/10000] | loss train:1.177471, test:0.211522 | lr:0.000000\n",
            "Epoch[7622/10000] | loss train:1.641252, test:1.829564 | lr:0.000000\n",
            "Epoch[7623/10000] | loss train:1.559509, test:1.301763 | lr:0.000000\n",
            "Epoch[7624/10000] | loss train:1.070142, test:1.261211 | lr:0.000000\n",
            "Epoch[7625/10000] | loss train:1.912716, test:0.550112 | lr:0.000000\n",
            "Epoch[7626/10000] | loss train:1.926270, test:1.357370 | lr:0.000000\n",
            "Epoch[7627/10000] | loss train:1.266833, test:0.413097 | lr:0.000000\n",
            "Epoch[7628/10000] | loss train:0.840986, test:0.231632 | lr:0.000000\n",
            "Epoch[7629/10000] | loss train:1.151334, test:1.699785 | lr:0.000000\n",
            "Epoch[7630/10000] | loss train:0.857973, test:0.867390 | lr:0.000000\n",
            "Epoch[7631/10000] | loss train:1.611504, test:1.226080 | lr:0.000000\n",
            "Epoch[7632/10000] | loss train:1.213584, test:0.549789 | lr:0.000000\n",
            "Epoch[7633/10000] | loss train:1.240566, test:0.763658 | lr:0.000000\n",
            "Epoch[7634/10000] | loss train:0.874319, test:0.163283 | lr:0.000000\n",
            "Epoch[7635/10000] | loss train:0.809432, test:0.378547 | lr:0.000000\n",
            "Epoch[7636/10000] | loss train:1.396724, test:1.356617 | lr:0.000000\n",
            "Epoch[7637/10000] | loss train:1.318320, test:0.201083 | lr:0.000000\n",
            "Epoch[7638/10000] | loss train:0.656765, test:0.575941 | lr:0.000000\n",
            "Epoch[7639/10000] | loss train:1.351048, test:0.258826 | lr:0.000000\n",
            "Epoch[7640/10000] | loss train:1.046488, test:0.560124 | lr:0.000000\n",
            "Epoch[7641/10000] | loss train:0.995002, test:0.573576 | lr:0.000000\n",
            "Epoch[7642/10000] | loss train:0.894095, test:0.494153 | lr:0.000000\n",
            "Epoch[7643/10000] | loss train:0.761556, test:1.725058 | lr:0.000000\n",
            "Epoch[7644/10000] | loss train:1.028384, test:0.284599 | lr:0.000000\n",
            "Epoch[7645/10000] | loss train:1.453207, test:0.573199 | lr:0.000000\n",
            "Epoch[7646/10000] | loss train:1.603216, test:0.254794 | lr:0.000000\n",
            "Epoch[7647/10000] | loss train:1.295194, test:1.119555 | lr:0.000000\n",
            "Epoch[7648/10000] | loss train:0.951815, test:0.257693 | lr:0.000000\n",
            "Epoch[7649/10000] | loss train:0.898026, test:0.278994 | lr:0.000000\n",
            "Epoch[7650/10000] | loss train:2.991742, test:1.385135 | lr:0.000000\n",
            "Epoch[7651/10000] | loss train:1.694212, test:0.124739 | lr:0.000000\n",
            "Epoch[7652/10000] | loss train:2.300607, test:0.210835 | lr:0.000000\n",
            "Epoch[7653/10000] | loss train:1.935194, test:2.357198 | lr:0.000000\n",
            "Epoch[7654/10000] | loss train:1.706027, test:0.455121 | lr:0.000000\n",
            "Epoch[7655/10000] | loss train:1.655235, test:0.775537 | lr:0.000000\n",
            "Epoch[7656/10000] | loss train:0.633810, test:0.116102 | lr:0.000000\n",
            "Epoch[7657/10000] | loss train:0.881856, test:0.780902 | lr:0.000000\n",
            "Epoch[7658/10000] | loss train:0.850463, test:0.250121 | lr:0.000000\n",
            "Epoch[7659/10000] | loss train:0.862937, test:0.478693 | lr:0.000000\n",
            "Epoch[7660/10000] | loss train:1.457705, test:0.461614 | lr:0.000000\n",
            "Epoch[7661/10000] | loss train:1.034627, test:0.200035 | lr:0.000000\n",
            "Epoch[7662/10000] | loss train:1.415138, test:0.502022 | lr:0.000000\n",
            "Epoch[7663/10000] | loss train:1.049887, test:0.094918 | lr:0.000000\n",
            "Epoch[7664/10000] | loss train:1.186915, test:0.957971 | lr:0.000000\n",
            "Epoch[7665/10000] | loss train:1.508527, test:0.368202 | lr:0.000000\n",
            "Epoch[7666/10000] | loss train:1.625592, test:0.448327 | lr:0.000000\n",
            "Epoch[7667/10000] | loss train:1.152976, test:0.064525 | lr:0.000000\n",
            "Epoch[7668/10000] | loss train:1.760826, test:0.714692 | lr:0.000000\n",
            "Epoch[7669/10000] | loss train:1.296152, test:0.131609 | lr:0.000000\n",
            "Epoch[7670/10000] | loss train:1.587526, test:1.304332 | lr:0.000000\n",
            "Epoch[7671/10000] | loss train:1.804094, test:0.318097 | lr:0.000000\n",
            "Epoch[7672/10000] | loss train:2.352635, test:0.371416 | lr:0.000000\n",
            "Epoch[7673/10000] | loss train:1.539731, test:0.277589 | lr:0.000000\n",
            "Epoch[7674/10000] | loss train:0.800667, test:0.350618 | lr:0.000000\n",
            "Epoch[7675/10000] | loss train:0.817211, test:0.301953 | lr:0.000000\n",
            "Epoch[7676/10000] | loss train:1.372455, test:0.605998 | lr:0.000000\n",
            "Epoch[7677/10000] | loss train:0.872267, test:0.976190 | lr:0.000000\n",
            "Epoch[7678/10000] | loss train:1.460899, test:0.523436 | lr:0.000000\n",
            "Epoch[7679/10000] | loss train:0.967621, test:0.601389 | lr:0.000000\n",
            "Epoch[7680/10000] | loss train:1.777294, test:0.225908 | lr:0.000000\n",
            "Epoch[7681/10000] | loss train:1.470059, test:1.219243 | lr:0.000000\n",
            "Epoch[7682/10000] | loss train:0.913857, test:0.246205 | lr:0.000000\n",
            "Epoch[7683/10000] | loss train:0.931221, test:1.637310 | lr:0.000000\n",
            "Epoch[7684/10000] | loss train:1.198394, test:0.620415 | lr:0.000000\n",
            "Epoch[7685/10000] | loss train:1.077719, test:0.569672 | lr:0.000000\n",
            "Epoch[7686/10000] | loss train:1.526222, test:0.206545 | lr:0.000000\n",
            "Epoch[7687/10000] | loss train:0.806394, test:1.077626 | lr:0.000000\n",
            "Epoch[7688/10000] | loss train:1.362772, test:0.567011 | lr:0.000000\n",
            "Epoch[7689/10000] | loss train:1.512577, test:1.315894 | lr:0.000000\n",
            "Epoch[7690/10000] | loss train:1.142126, test:0.892985 | lr:0.000000\n",
            "Epoch[7691/10000] | loss train:0.951066, test:0.863201 | lr:0.000000\n",
            "Epoch[7692/10000] | loss train:0.817081, test:0.511897 | lr:0.000000\n",
            "Epoch[7693/10000] | loss train:1.422063, test:0.719795 | lr:0.000000\n",
            "Epoch[7694/10000] | loss train:1.075597, test:0.094218 | lr:0.000000\n",
            "Epoch[7695/10000] | loss train:1.634867, test:0.305183 | lr:0.000000\n",
            "Epoch[7696/10000] | loss train:0.832856, test:1.647250 | lr:0.000000\n",
            "Epoch[7697/10000] | loss train:0.974222, test:1.364759 | lr:0.000000\n",
            "Epoch[7698/10000] | loss train:0.928676, test:0.857864 | lr:0.000000\n",
            "Epoch[7699/10000] | loss train:0.833925, test:0.234784 | lr:0.000000\n",
            "Epoch[7700/10000] | loss train:0.961847, test:1.396098 | lr:0.000000\n",
            "Epoch[7701/10000] | loss train:1.151445, test:1.195717 | lr:0.000000\n",
            "Epoch[7702/10000] | loss train:1.988844, test:0.464517 | lr:0.000000\n",
            "Epoch[7703/10000] | loss train:1.166470, test:1.274608 | lr:0.000000\n",
            "Epoch[7704/10000] | loss train:1.180748, test:0.613266 | lr:0.000000\n",
            "Epoch[7705/10000] | loss train:1.015266, test:0.327506 | lr:0.000000\n",
            "Epoch[7706/10000] | loss train:1.682843, test:1.272622 | lr:0.000000\n",
            "Epoch[7707/10000] | loss train:1.196345, test:1.550069 | lr:0.000000\n",
            "Epoch[7708/10000] | loss train:1.847249, test:0.173321 | lr:0.000000\n",
            "Epoch[7709/10000] | loss train:0.805034, test:0.113777 | lr:0.000000\n",
            "Epoch[7710/10000] | loss train:0.867408, test:1.277520 | lr:0.000000\n",
            "Epoch[7711/10000] | loss train:0.879022, test:0.277522 | lr:0.000000\n",
            "Epoch[7712/10000] | loss train:1.008667, test:1.009531 | lr:0.000000\n",
            "Epoch[7713/10000] | loss train:1.050398, test:1.488719 | lr:0.000000\n",
            "Epoch[7714/10000] | loss train:0.992971, test:0.716088 | lr:0.000000\n",
            "Epoch[7715/10000] | loss train:0.852495, test:0.592190 | lr:0.000000\n",
            "Epoch[7716/10000] | loss train:2.404443, test:1.174736 | lr:0.000000\n",
            "Epoch[7717/10000] | loss train:1.126709, test:0.624625 | lr:0.000000\n",
            "Epoch[7718/10000] | loss train:0.878561, test:0.639122 | lr:0.000000\n",
            "Epoch[7719/10000] | loss train:1.072172, test:0.175270 | lr:0.000000\n",
            "Epoch[7720/10000] | loss train:1.502610, test:0.082570 | lr:0.000000\n",
            "Epoch[7721/10000] | loss train:0.977880, test:1.355905 | lr:0.000000\n",
            "Epoch[7722/10000] | loss train:1.019274, test:0.719415 | lr:0.000000\n",
            "Epoch[7723/10000] | loss train:1.548839, test:0.490492 | lr:0.000000\n",
            "Epoch[7724/10000] | loss train:0.755179, test:0.366046 | lr:0.000000\n",
            "Epoch[7725/10000] | loss train:1.487381, test:1.023277 | lr:0.000000\n",
            "Epoch[7726/10000] | loss train:1.258104, test:1.261218 | lr:0.000000\n",
            "Epoch[7727/10000] | loss train:1.539900, test:0.404327 | lr:0.000000\n",
            "Epoch[7728/10000] | loss train:1.309341, test:0.349673 | lr:0.000000\n",
            "Epoch[7729/10000] | loss train:0.978070, test:0.602426 | lr:0.000000\n",
            "Epoch[7730/10000] | loss train:1.651040, test:0.197256 | lr:0.000000\n",
            "Epoch[7731/10000] | loss train:0.833586, test:1.474769 | lr:0.000000\n",
            "Epoch[7732/10000] | loss train:2.203482, test:0.758647 | lr:0.000000\n",
            "Epoch[7733/10000] | loss train:1.034421, test:0.846562 | lr:0.000000\n",
            "Epoch[7734/10000] | loss train:1.181208, test:0.733307 | lr:0.000000\n",
            "Epoch[7735/10000] | loss train:2.130432, test:0.138239 | lr:0.000000\n",
            "Epoch[7736/10000] | loss train:2.103820, test:0.188838 | lr:0.000000\n",
            "Epoch[7737/10000] | loss train:0.948266, test:0.635087 | lr:0.000000\n",
            "Epoch[7738/10000] | loss train:2.243544, test:0.422156 | lr:0.000000\n",
            "Epoch[7739/10000] | loss train:1.409914, test:0.101734 | lr:0.000000\n",
            "Epoch[7740/10000] | loss train:2.760451, test:0.618943 | lr:0.000000\n",
            "Epoch[7741/10000] | loss train:0.919670, test:0.596973 | lr:0.000000\n",
            "Epoch[7742/10000] | loss train:1.346521, test:0.667333 | lr:0.000000\n",
            "Epoch[7743/10000] | loss train:1.387015, test:0.309892 | lr:0.000000\n",
            "Epoch[7744/10000] | loss train:1.827777, test:0.217111 | lr:0.000000\n",
            "Epoch[7745/10000] | loss train:1.503463, test:2.122904 | lr:0.000000\n",
            "Epoch[7746/10000] | loss train:0.653805, test:0.321681 | lr:0.000000\n",
            "Epoch[7747/10000] | loss train:1.224271, test:0.584106 | lr:0.000000\n",
            "Epoch[7748/10000] | loss train:0.886913, test:0.082351 | lr:0.000000\n",
            "Epoch[7749/10000] | loss train:1.545231, test:0.265899 | lr:0.000000\n",
            "Epoch[7750/10000] | loss train:1.507584, test:0.496074 | lr:0.000000\n",
            "Epoch[7751/10000] | loss train:0.781561, test:1.666996 | lr:0.000000\n",
            "Epoch[7752/10000] | loss train:1.130512, test:1.179452 | lr:0.000000\n",
            "Epoch[7753/10000] | loss train:1.428004, test:0.348014 | lr:0.000000\n",
            "Epoch[7754/10000] | loss train:0.717849, test:0.240372 | lr:0.000000\n",
            "Epoch[7755/10000] | loss train:1.397884, test:0.692213 | lr:0.000000\n",
            "Epoch[7756/10000] | loss train:1.254116, test:1.034878 | lr:0.000000\n",
            "Epoch[7757/10000] | loss train:1.941920, test:0.668800 | lr:0.000000\n",
            "Epoch[7758/10000] | loss train:1.724584, test:0.807027 | lr:0.000000\n",
            "Epoch[7759/10000] | loss train:0.919691, test:0.441246 | lr:0.000000\n",
            "Epoch[7760/10000] | loss train:1.834490, test:0.633416 | lr:0.000000\n",
            "Epoch[7761/10000] | loss train:1.245892, test:0.296994 | lr:0.000000\n",
            "Epoch[7762/10000] | loss train:1.282195, test:0.934336 | lr:0.000000\n",
            "Epoch[7763/10000] | loss train:1.368639, test:1.264891 | lr:0.000000\n",
            "Epoch[7764/10000] | loss train:1.042946, test:1.775939 | lr:0.000000\n",
            "Epoch[7765/10000] | loss train:0.955219, test:0.697978 | lr:0.000000\n",
            "Epoch[7766/10000] | loss train:1.826037, test:0.182488 | lr:0.000000\n",
            "Epoch[7767/10000] | loss train:0.629663, test:0.994349 | lr:0.000000\n",
            "Epoch[7768/10000] | loss train:0.624656, test:0.392116 | lr:0.000000\n",
            "Epoch[7769/10000] | loss train:0.706943, test:0.205068 | lr:0.000000\n",
            "Epoch[7770/10000] | loss train:1.008390, test:1.643434 | lr:0.000000\n",
            "Epoch[7771/10000] | loss train:2.362549, test:0.251976 | lr:0.000000\n",
            "Epoch[7772/10000] | loss train:1.132937, test:0.200311 | lr:0.000000\n",
            "Epoch[7773/10000] | loss train:1.900189, test:0.873339 | lr:0.000000\n",
            "Epoch[7774/10000] | loss train:2.200305, test:0.296790 | lr:0.000000\n",
            "Epoch[7775/10000] | loss train:1.167826, test:0.571480 | lr:0.000000\n",
            "Epoch[7776/10000] | loss train:1.745085, test:0.528498 | lr:0.000000\n",
            "Epoch[7777/10000] | loss train:1.186820, test:1.080396 | lr:0.000000\n",
            "Epoch[7778/10000] | loss train:0.839000, test:0.236077 | lr:0.000000\n",
            "Epoch[7779/10000] | loss train:0.809604, test:1.124788 | lr:0.000000\n",
            "Epoch[7780/10000] | loss train:1.918585, test:0.555058 | lr:0.000000\n",
            "Epoch[7781/10000] | loss train:1.123087, test:0.331493 | lr:0.000000\n",
            "Epoch[7782/10000] | loss train:1.385116, test:0.237402 | lr:0.000000\n",
            "Epoch[7783/10000] | loss train:1.008198, test:1.608909 | lr:0.000000\n",
            "Epoch[7784/10000] | loss train:1.460624, test:0.531898 | lr:0.000000\n",
            "Epoch[7785/10000] | loss train:0.815266, test:0.965382 | lr:0.000000\n",
            "Epoch[7786/10000] | loss train:2.187279, test:0.468822 | lr:0.000000\n",
            "Epoch[7787/10000] | loss train:0.882704, test:0.523492 | lr:0.000000\n",
            "Epoch[7788/10000] | loss train:1.467238, test:0.333268 | lr:0.000000\n",
            "Epoch[7789/10000] | loss train:1.950632, test:0.153861 | lr:0.000000\n",
            "Epoch[7790/10000] | loss train:0.970511, test:2.199916 | lr:0.000000\n",
            "Epoch[7791/10000] | loss train:1.628144, test:0.799148 | lr:0.000000\n",
            "Epoch[7792/10000] | loss train:0.991018, test:0.509371 | lr:0.000000\n",
            "Epoch[7793/10000] | loss train:0.953073, test:0.815412 | lr:0.000000\n",
            "Epoch[7794/10000] | loss train:1.171104, test:2.128838 | lr:0.000000\n",
            "Epoch[7795/10000] | loss train:0.740310, test:0.490057 | lr:0.000000\n",
            "Epoch[7796/10000] | loss train:1.857799, test:1.902774 | lr:0.000000\n",
            "Epoch[7797/10000] | loss train:1.516182, test:0.127351 | lr:0.000000\n",
            "Epoch[7798/10000] | loss train:1.903830, test:0.598549 | lr:0.000000\n",
            "Epoch[7799/10000] | loss train:1.167877, test:0.675387 | lr:0.000000\n",
            "Epoch[7800/10000] | loss train:2.459145, test:0.555977 | lr:0.000000\n",
            "Epoch[7801/10000] | loss train:1.220759, test:0.926541 | lr:0.000000\n",
            "Epoch[7802/10000] | loss train:1.026413, test:0.688274 | lr:0.000000\n",
            "Epoch[7803/10000] | loss train:1.061688, test:0.566813 | lr:0.000000\n",
            "Epoch[7804/10000] | loss train:1.037305, test:0.146603 | lr:0.000000\n",
            "Epoch[7805/10000] | loss train:0.910450, test:1.119257 | lr:0.000000\n",
            "Epoch[7806/10000] | loss train:0.881704, test:0.512573 | lr:0.000000\n",
            "Epoch[7807/10000] | loss train:1.023625, test:0.678249 | lr:0.000000\n",
            "Epoch[7808/10000] | loss train:1.005427, test:0.462128 | lr:0.000000\n",
            "Epoch[7809/10000] | loss train:1.531105, test:0.333738 | lr:0.000000\n",
            "Epoch[7810/10000] | loss train:1.452449, test:0.738248 | lr:0.000000\n",
            "Epoch[7811/10000] | loss train:1.362309, test:0.412712 | lr:0.000000\n",
            "Epoch[7812/10000] | loss train:1.431803, test:0.248167 | lr:0.000000\n",
            "Epoch[7813/10000] | loss train:1.807227, test:0.649170 | lr:0.000000\n",
            "Epoch[7814/10000] | loss train:1.208226, test:0.313232 | lr:0.000000\n",
            "Epoch[7815/10000] | loss train:1.155894, test:1.249186 | lr:0.000000\n",
            "Epoch[7816/10000] | loss train:1.071043, test:0.160490 | lr:0.000000\n",
            "Epoch[7817/10000] | loss train:0.791343, test:0.791889 | lr:0.000000\n",
            "Epoch[7818/10000] | loss train:1.181808, test:0.246753 | lr:0.000000\n",
            "Epoch[7819/10000] | loss train:1.346222, test:1.246616 | lr:0.000000\n",
            "Epoch[7820/10000] | loss train:1.031072, test:1.469874 | lr:0.000000\n",
            "Epoch[7821/10000] | loss train:1.591205, test:0.541074 | lr:0.000000\n",
            "Epoch[7822/10000] | loss train:0.997711, test:0.360465 | lr:0.000000\n",
            "Epoch[7823/10000] | loss train:1.059273, test:0.559021 | lr:0.000000\n",
            "Epoch[7824/10000] | loss train:1.711329, test:0.178282 | lr:0.000000\n",
            "Epoch[7825/10000] | loss train:1.397923, test:0.261560 | lr:0.000000\n",
            "Epoch[7826/10000] | loss train:1.934180, test:1.241279 | lr:0.000000\n",
            "Epoch[7827/10000] | loss train:2.689544, test:0.545468 | lr:0.000000\n",
            "Epoch[7828/10000] | loss train:0.727531, test:0.963348 | lr:0.000000\n",
            "Epoch[7829/10000] | loss train:1.966422, test:0.130094 | lr:0.000000\n",
            "Epoch[7830/10000] | loss train:0.854654, test:0.892849 | lr:0.000000\n",
            "Epoch[7831/10000] | loss train:0.903507, test:0.725265 | lr:0.000000\n",
            "Epoch[7832/10000] | loss train:1.171333, test:0.783466 | lr:0.000000\n",
            "Epoch[7833/10000] | loss train:2.017807, test:0.289487 | lr:0.000000\n",
            "Epoch[7834/10000] | loss train:1.286600, test:0.319386 | lr:0.000000\n",
            "Epoch[7835/10000] | loss train:1.430915, test:0.099150 | lr:0.000000\n",
            "Epoch[7836/10000] | loss train:1.275726, test:1.933520 | lr:0.000000\n",
            "Epoch[7837/10000] | loss train:0.793765, test:0.259452 | lr:0.000000\n",
            "Epoch[7838/10000] | loss train:1.099038, test:0.234552 | lr:0.000000\n",
            "Epoch[7839/10000] | loss train:1.452986, test:0.198746 | lr:0.000000\n",
            "Epoch[7840/10000] | loss train:1.102051, test:0.219661 | lr:0.000000\n",
            "Epoch[7841/10000] | loss train:1.298885, test:0.378919 | lr:0.000000\n",
            "Epoch[7842/10000] | loss train:0.975577, test:2.123513 | lr:0.000000\n",
            "Epoch[7843/10000] | loss train:0.850076, test:0.327044 | lr:0.000000\n",
            "Epoch[7844/10000] | loss train:0.845396, test:2.041127 | lr:0.000000\n",
            "Epoch[7845/10000] | loss train:1.153110, test:0.886010 | lr:0.000000\n",
            "Epoch[7846/10000] | loss train:1.126196, test:1.156570 | lr:0.000000\n",
            "Epoch[7847/10000] | loss train:0.812096, test:1.042503 | lr:0.000000\n",
            "Epoch[7848/10000] | loss train:1.882868, test:0.524132 | lr:0.000000\n",
            "Epoch[7849/10000] | loss train:1.698100, test:0.567579 | lr:0.000000\n",
            "Epoch[7850/10000] | loss train:1.152918, test:0.273505 | lr:0.000000\n",
            "Epoch[7851/10000] | loss train:0.877758, test:0.753810 | lr:0.000000\n",
            "Epoch[7852/10000] | loss train:1.284665, test:1.144581 | lr:0.000000\n",
            "Epoch[7853/10000] | loss train:1.870456, test:2.202993 | lr:0.000000\n",
            "Epoch[7854/10000] | loss train:0.944683, test:0.738493 | lr:0.000000\n",
            "Epoch[7855/10000] | loss train:1.478384, test:1.381436 | lr:0.000000\n",
            "Epoch[7856/10000] | loss train:0.991061, test:1.373801 | lr:0.000000\n",
            "Epoch[7857/10000] | loss train:0.818104, test:0.467521 | lr:0.000000\n",
            "Epoch[7858/10000] | loss train:1.413391, test:0.481057 | lr:0.000000\n",
            "Epoch[7859/10000] | loss train:2.157915, test:0.256211 | lr:0.000000\n",
            "Epoch[7860/10000] | loss train:1.075730, test:0.533050 | lr:0.000000\n",
            "Epoch[7861/10000] | loss train:1.012301, test:0.115795 | lr:0.000000\n",
            "Epoch[7862/10000] | loss train:1.321736, test:0.156509 | lr:0.000000\n",
            "Epoch[7863/10000] | loss train:1.136702, test:0.279110 | lr:0.000000\n",
            "Epoch[7864/10000] | loss train:1.428617, test:1.210481 | lr:0.000000\n",
            "Epoch[7865/10000] | loss train:0.624379, test:0.705134 | lr:0.000000\n",
            "Epoch[7866/10000] | loss train:1.023851, test:0.620993 | lr:0.000000\n",
            "Epoch[7867/10000] | loss train:1.248284, test:1.017285 | lr:0.000000\n",
            "Epoch[7868/10000] | loss train:1.506795, test:0.565392 | lr:0.000000\n",
            "Epoch[7869/10000] | loss train:0.929496, test:1.075945 | lr:0.000000\n",
            "Epoch[7870/10000] | loss train:0.899795, test:0.697338 | lr:0.000000\n",
            "Epoch[7871/10000] | loss train:1.298422, test:0.286864 | lr:0.000000\n",
            "Epoch[7872/10000] | loss train:0.763233, test:0.088831 | lr:0.000000\n",
            "Epoch[7873/10000] | loss train:1.073755, test:0.187210 | lr:0.000000\n",
            "Epoch[7874/10000] | loss train:0.721170, test:0.495282 | lr:0.000000\n",
            "Epoch[7875/10000] | loss train:1.496890, test:0.164410 | lr:0.000000\n",
            "Epoch[7876/10000] | loss train:1.498655, test:0.865525 | lr:0.000000\n",
            "Epoch[7877/10000] | loss train:1.646974, test:0.640372 | lr:0.000000\n",
            "Epoch[7878/10000] | loss train:0.984273, test:0.388582 | lr:0.000000\n",
            "Epoch[7879/10000] | loss train:1.287545, test:0.286900 | lr:0.000000\n",
            "Epoch[7880/10000] | loss train:1.097789, test:1.087255 | lr:0.000000\n",
            "Epoch[7881/10000] | loss train:0.570310, test:0.381747 | lr:0.000000\n",
            "Epoch[7882/10000] | loss train:0.615037, test:0.559966 | lr:0.000000\n",
            "Epoch[7883/10000] | loss train:1.812253, test:1.970534 | lr:0.000000\n",
            "Epoch[7884/10000] | loss train:1.429253, test:0.182055 | lr:0.000000\n",
            "Epoch[7885/10000] | loss train:1.871213, test:0.321031 | lr:0.000000\n",
            "Epoch[7886/10000] | loss train:0.864593, test:1.231314 | lr:0.000000\n",
            "Epoch[7887/10000] | loss train:0.789643, test:0.117651 | lr:0.000000\n",
            "Epoch[7888/10000] | loss train:0.763694, test:1.037972 | lr:0.000000\n",
            "Epoch[7889/10000] | loss train:1.912854, test:1.272316 | lr:0.000000\n",
            "Epoch[7890/10000] | loss train:0.784720, test:0.549550 | lr:0.000000\n",
            "Epoch[7891/10000] | loss train:2.572900, test:0.548316 | lr:0.000000\n",
            "Epoch[7892/10000] | loss train:1.059602, test:0.908852 | lr:0.000000\n",
            "Epoch[7893/10000] | loss train:0.746201, test:0.743968 | lr:0.000000\n",
            "Epoch[7894/10000] | loss train:1.562635, test:0.447402 | lr:0.000000\n",
            "Epoch[7895/10000] | loss train:2.143348, test:0.146463 | lr:0.000000\n",
            "Epoch[7896/10000] | loss train:1.699537, test:0.302942 | lr:0.000000\n",
            "Epoch[7897/10000] | loss train:1.297170, test:0.184986 | lr:0.000000\n",
            "Epoch[7898/10000] | loss train:0.769668, test:0.265533 | lr:0.000000\n",
            "Epoch[7899/10000] | loss train:0.658861, test:1.347758 | lr:0.000000\n",
            "Epoch[7900/10000] | loss train:0.951590, test:0.067801 | lr:0.000000\n",
            "Epoch[7901/10000] | loss train:1.336565, test:0.762990 | lr:0.000000\n",
            "Epoch[7902/10000] | loss train:0.899081, test:0.769594 | lr:0.000000\n",
            "Epoch[7903/10000] | loss train:1.114159, test:0.116947 | lr:0.000000\n",
            "Epoch[7904/10000] | loss train:1.307474, test:1.852714 | lr:0.000000\n",
            "Epoch[7905/10000] | loss train:2.025104, test:0.215023 | lr:0.000000\n",
            "Epoch[7906/10000] | loss train:1.621285, test:0.293692 | lr:0.000000\n",
            "Epoch[7907/10000] | loss train:0.809886, test:0.372603 | lr:0.000000\n",
            "Epoch[7908/10000] | loss train:0.727578, test:0.469775 | lr:0.000000\n",
            "Epoch[7909/10000] | loss train:1.332580, test:0.265491 | lr:0.000000\n",
            "Epoch[7910/10000] | loss train:1.614499, test:0.358636 | lr:0.000000\n",
            "Epoch[7911/10000] | loss train:1.390612, test:0.440336 | lr:0.000000\n",
            "Epoch[7912/10000] | loss train:2.086807, test:1.177124 | lr:0.000000\n",
            "Epoch[7913/10000] | loss train:1.151586, test:0.059192 | lr:0.000000\n",
            "Epoch[7914/10000] | loss train:1.060580, test:0.427976 | lr:0.000000\n",
            "Epoch[7915/10000] | loss train:0.977419, test:0.532999 | lr:0.000000\n",
            "Epoch[7916/10000] | loss train:1.192872, test:0.212189 | lr:0.000000\n",
            "Epoch[7917/10000] | loss train:0.690772, test:0.204304 | lr:0.000000\n",
            "Epoch[7918/10000] | loss train:1.579729, test:1.017800 | lr:0.000000\n",
            "Epoch[7919/10000] | loss train:1.050082, test:0.139996 | lr:0.000000\n",
            "Epoch[7920/10000] | loss train:0.879112, test:0.985434 | lr:0.000000\n",
            "Epoch[7921/10000] | loss train:0.869049, test:0.519593 | lr:0.000000\n",
            "Epoch[7922/10000] | loss train:1.251952, test:0.599482 | lr:0.000000\n",
            "Epoch[7923/10000] | loss train:1.049651, test:0.620963 | lr:0.000000\n",
            "Epoch[7924/10000] | loss train:1.987898, test:0.956175 | lr:0.000000\n",
            "Epoch[7925/10000] | loss train:1.588682, test:0.285531 | lr:0.000000\n",
            "Epoch[7926/10000] | loss train:1.504181, test:0.473517 | lr:0.000000\n",
            "Epoch[7927/10000] | loss train:0.780147, test:0.201025 | lr:0.000000\n",
            "Epoch[7928/10000] | loss train:0.966238, test:0.350443 | lr:0.000000\n",
            "Epoch[7929/10000] | loss train:1.235251, test:0.521648 | lr:0.000000\n",
            "Epoch[7930/10000] | loss train:0.792792, test:1.687155 | lr:0.000000\n",
            "Epoch[7931/10000] | loss train:0.808017, test:0.100319 | lr:0.000000\n",
            "Epoch[7932/10000] | loss train:0.951194, test:1.223270 | lr:0.000000\n",
            "Epoch[7933/10000] | loss train:1.126839, test:0.345974 | lr:0.000000\n",
            "Epoch[7934/10000] | loss train:1.489272, test:0.284276 | lr:0.000000\n",
            "Epoch[7935/10000] | loss train:1.434673, test:0.288229 | lr:0.000000\n",
            "Epoch[7936/10000] | loss train:1.434662, test:0.332327 | lr:0.000000\n",
            "Epoch[7937/10000] | loss train:0.719406, test:0.923757 | lr:0.000000\n",
            "Epoch[7938/10000] | loss train:0.968517, test:0.180316 | lr:0.000000\n",
            "Epoch[7939/10000] | loss train:1.888000, test:0.201604 | lr:0.000000\n",
            "Epoch[7940/10000] | loss train:1.306961, test:0.131735 | lr:0.000000\n",
            "Epoch[7941/10000] | loss train:2.099796, test:1.622515 | lr:0.000000\n",
            "Epoch[7942/10000] | loss train:1.763800, test:0.473052 | lr:0.000000\n",
            "Epoch[7943/10000] | loss train:1.906976, test:0.452163 | lr:0.000000\n",
            "Epoch[7944/10000] | loss train:1.141920, test:1.305201 | lr:0.000000\n",
            "Epoch[7945/10000] | loss train:0.819762, test:2.268590 | lr:0.000000\n",
            "Epoch[7946/10000] | loss train:1.004021, test:1.395831 | lr:0.000000\n",
            "Epoch[7947/10000] | loss train:0.782456, test:0.156149 | lr:0.000000\n",
            "Epoch[7948/10000] | loss train:1.051478, test:0.553710 | lr:0.000000\n",
            "Epoch[7949/10000] | loss train:1.180736, test:0.685053 | lr:0.000000\n",
            "Epoch[7950/10000] | loss train:1.025880, test:0.616714 | lr:0.000000\n",
            "Epoch[7951/10000] | loss train:1.093673, test:0.094185 | lr:0.000000\n",
            "Epoch[7952/10000] | loss train:1.258525, test:1.012165 | lr:0.000000\n",
            "Epoch[7953/10000] | loss train:1.891328, test:1.173161 | lr:0.000000\n",
            "Epoch[7954/10000] | loss train:1.343073, test:0.518042 | lr:0.000000\n",
            "Epoch[7955/10000] | loss train:1.895472, test:1.858549 | lr:0.000000\n",
            "Epoch[7956/10000] | loss train:1.899218, test:0.533084 | lr:0.000000\n",
            "Epoch[7957/10000] | loss train:1.533036, test:1.781295 | lr:0.000000\n",
            "Epoch[7958/10000] | loss train:1.551496, test:1.252458 | lr:0.000000\n",
            "Epoch[7959/10000] | loss train:1.514519, test:0.779551 | lr:0.000000\n",
            "Epoch[7960/10000] | loss train:1.251255, test:0.660095 | lr:0.000000\n",
            "Epoch[7961/10000] | loss train:0.768382, test:0.385387 | lr:0.000000\n",
            "Epoch[7962/10000] | loss train:0.990763, test:0.083384 | lr:0.000000\n",
            "Epoch[7963/10000] | loss train:1.084867, test:0.220866 | lr:0.000000\n",
            "Epoch[7964/10000] | loss train:1.516328, test:0.407279 | lr:0.000000\n",
            "Epoch[7965/10000] | loss train:1.227899, test:0.842355 | lr:0.000000\n",
            "Epoch[7966/10000] | loss train:0.848829, test:0.453471 | lr:0.000000\n",
            "Epoch[7967/10000] | loss train:1.626091, test:0.310752 | lr:0.000000\n",
            "Epoch[7968/10000] | loss train:0.918007, test:0.931695 | lr:0.000000\n",
            "Epoch[7969/10000] | loss train:1.487959, test:0.523338 | lr:0.000000\n",
            "Epoch[7970/10000] | loss train:0.759484, test:1.223029 | lr:0.000000\n",
            "Epoch[7971/10000] | loss train:1.058101, test:1.033582 | lr:0.000000\n",
            "Epoch[7972/10000] | loss train:2.305656, test:0.115284 | lr:0.000000\n",
            "Epoch[7973/10000] | loss train:0.919046, test:1.305463 | lr:0.000000\n",
            "Epoch[7974/10000] | loss train:0.729162, test:1.249784 | lr:0.000000\n",
            "Epoch[7975/10000] | loss train:0.944602, test:1.031853 | lr:0.000000\n",
            "Epoch[7976/10000] | loss train:1.457707, test:0.272808 | lr:0.000000\n",
            "Epoch[7977/10000] | loss train:2.147894, test:0.387192 | lr:0.000000\n",
            "Epoch[7978/10000] | loss train:1.019826, test:0.377969 | lr:0.000000\n",
            "Epoch[7979/10000] | loss train:1.590133, test:0.051696 | lr:0.000000\n",
            "Epoch[7980/10000] | loss train:0.946191, test:0.361649 | lr:0.000000\n",
            "Epoch[7981/10000] | loss train:1.949449, test:0.374839 | lr:0.000000\n",
            "Epoch[7982/10000] | loss train:1.362475, test:0.443658 | lr:0.000000\n",
            "Epoch[7983/10000] | loss train:1.244955, test:0.410383 | lr:0.000000\n",
            "Epoch[7984/10000] | loss train:1.680752, test:0.187250 | lr:0.000000\n",
            "Epoch[7985/10000] | loss train:1.098364, test:1.076495 | lr:0.000000\n",
            "Epoch[7986/10000] | loss train:1.076099, test:0.124939 | lr:0.000000\n",
            "Epoch[7987/10000] | loss train:1.207329, test:0.552964 | lr:0.000000\n",
            "Epoch[7988/10000] | loss train:0.732706, test:0.626033 | lr:0.000000\n",
            "Epoch[7989/10000] | loss train:2.231897, test:1.712313 | lr:0.000000\n",
            "Epoch[7990/10000] | loss train:1.186924, test:0.575785 | lr:0.000000\n",
            "Epoch[7991/10000] | loss train:1.082545, test:0.906417 | lr:0.000000\n",
            "Epoch[7992/10000] | loss train:1.526868, test:0.333003 | lr:0.000000\n",
            "Epoch[7993/10000] | loss train:0.995264, test:0.221384 | lr:0.000000\n",
            "Epoch[7994/10000] | loss train:1.021499, test:1.777303 | lr:0.000000\n",
            "Epoch[7995/10000] | loss train:1.242792, test:1.170825 | lr:0.000000\n",
            "Epoch[7996/10000] | loss train:0.978967, test:1.165881 | lr:0.000000\n",
            "Epoch[7997/10000] | loss train:1.286507, test:0.186399 | lr:0.000000\n",
            "Epoch[7998/10000] | loss train:0.686412, test:1.050872 | lr:0.000000\n",
            "Epoch[7999/10000] | loss train:0.895307, test:0.682803 | lr:0.000000\n",
            "Epoch[8000/10000] | loss train:0.915178, test:0.708590 | lr:0.000000\n",
            "Epoch[8001/10000] | loss train:1.364379, test:0.397435 | lr:0.000000\n",
            "Epoch[8002/10000] | loss train:1.137278, test:1.445290 | lr:0.000000\n",
            "Epoch[8003/10000] | loss train:1.036254, test:0.577420 | lr:0.000000\n",
            "Epoch[8004/10000] | loss train:1.751733, test:0.565856 | lr:0.000000\n",
            "Epoch[8005/10000] | loss train:1.486067, test:0.507588 | lr:0.000000\n",
            "Epoch[8006/10000] | loss train:0.786894, test:1.452901 | lr:0.000000\n",
            "Epoch[8007/10000] | loss train:1.335970, test:0.048887 | lr:0.000000\n",
            "Epoch[8008/10000] | loss train:1.185290, test:0.351758 | lr:0.000000\n",
            "Epoch[8009/10000] | loss train:1.572344, test:0.588223 | lr:0.000000\n",
            "Epoch[8010/10000] | loss train:0.923005, test:0.748476 | lr:0.000000\n",
            "Epoch[8011/10000] | loss train:1.377775, test:1.521594 | lr:0.000000\n",
            "Epoch[8012/10000] | loss train:1.570234, test:1.364910 | lr:0.000000\n",
            "Epoch[8013/10000] | loss train:1.298685, test:0.281108 | lr:0.000000\n",
            "Epoch[8014/10000] | loss train:1.212499, test:0.507987 | lr:0.000000\n",
            "Epoch[8015/10000] | loss train:1.061537, test:0.224933 | lr:0.000000\n",
            "Epoch[8016/10000] | loss train:1.043666, test:0.698295 | lr:0.000000\n",
            "Epoch[8017/10000] | loss train:1.198884, test:0.381810 | lr:0.000000\n",
            "Epoch[8018/10000] | loss train:0.852188, test:1.308282 | lr:0.000000\n",
            "Epoch[8019/10000] | loss train:1.235096, test:0.141036 | lr:0.000000\n",
            "Epoch[8020/10000] | loss train:0.628742, test:0.175759 | lr:0.000000\n",
            "Epoch[8021/10000] | loss train:0.784330, test:0.065746 | lr:0.000000\n",
            "Epoch[8022/10000] | loss train:0.866001, test:0.056415 | lr:0.000000\n",
            "Epoch[8023/10000] | loss train:2.325828, test:0.254607 | lr:0.000000\n",
            "Epoch[8024/10000] | loss train:1.169735, test:1.164795 | lr:0.000000\n",
            "Epoch[8025/10000] | loss train:1.136997, test:0.951522 | lr:0.000000\n",
            "Epoch[8026/10000] | loss train:0.709407, test:0.618525 | lr:0.000000\n",
            "Epoch[8027/10000] | loss train:1.091585, test:0.920311 | lr:0.000000\n",
            "Epoch[8028/10000] | loss train:1.318126, test:1.306754 | lr:0.000000\n",
            "Epoch[8029/10000] | loss train:0.731877, test:0.489886 | lr:0.000000\n",
            "Epoch[8030/10000] | loss train:0.890039, test:0.131407 | lr:0.000000\n",
            "Epoch[8031/10000] | loss train:1.764966, test:0.250675 | lr:0.000000\n",
            "Epoch[8032/10000] | loss train:0.845620, test:0.210010 | lr:0.000000\n",
            "Epoch[8033/10000] | loss train:1.718806, test:0.227023 | lr:0.000000\n",
            "Epoch[8034/10000] | loss train:0.939841, test:0.391545 | lr:0.000000\n",
            "Epoch[8035/10000] | loss train:0.815574, test:0.448763 | lr:0.000000\n",
            "Epoch[8036/10000] | loss train:0.857777, test:0.373668 | lr:0.000000\n",
            "Epoch[8037/10000] | loss train:0.721077, test:1.110071 | lr:0.000000\n",
            "Epoch[8038/10000] | loss train:1.166741, test:1.396043 | lr:0.000000\n",
            "Epoch[8039/10000] | loss train:1.622236, test:0.769806 | lr:0.000000\n",
            "Epoch[8040/10000] | loss train:1.498872, test:0.154309 | lr:0.000000\n",
            "Epoch[8041/10000] | loss train:1.065978, test:0.879996 | lr:0.000000\n",
            "Epoch[8042/10000] | loss train:1.051213, test:0.473815 | lr:0.000000\n",
            "Epoch[8043/10000] | loss train:0.834462, test:0.588710 | lr:0.000000\n",
            "Epoch[8044/10000] | loss train:1.222566, test:0.322700 | lr:0.000000\n",
            "Epoch[8045/10000] | loss train:1.155816, test:0.298128 | lr:0.000000\n",
            "Epoch[8046/10000] | loss train:1.741213, test:0.820237 | lr:0.000000\n",
            "Epoch[8047/10000] | loss train:0.975469, test:0.338670 | lr:0.000000\n",
            "Epoch[8048/10000] | loss train:1.126379, test:0.941990 | lr:0.000000\n",
            "Epoch[8049/10000] | loss train:0.971782, test:0.834427 | lr:0.000000\n",
            "Epoch[8050/10000] | loss train:0.633170, test:0.435746 | lr:0.000000\n",
            "Epoch[8051/10000] | loss train:1.720612, test:0.190815 | lr:0.000000\n",
            "Epoch[8052/10000] | loss train:2.317717, test:1.103044 | lr:0.000000\n",
            "Epoch[8053/10000] | loss train:1.161957, test:1.885955 | lr:0.000000\n",
            "Epoch[8054/10000] | loss train:1.491634, test:0.253614 | lr:0.000000\n",
            "Epoch[8055/10000] | loss train:0.648186, test:0.736203 | lr:0.000000\n",
            "Epoch[8056/10000] | loss train:0.767902, test:0.932532 | lr:0.000000\n",
            "Epoch[8057/10000] | loss train:2.222796, test:0.204935 | lr:0.000000\n",
            "Epoch[8058/10000] | loss train:1.518547, test:0.335177 | lr:0.000000\n",
            "Epoch[8059/10000] | loss train:1.812204, test:0.938246 | lr:0.000000\n",
            "Epoch[8060/10000] | loss train:1.105354, test:0.180965 | lr:0.000000\n",
            "Epoch[8061/10000] | loss train:1.185254, test:0.537372 | lr:0.000000\n",
            "Epoch[8062/10000] | loss train:1.193401, test:1.450329 | lr:0.000000\n",
            "Epoch[8063/10000] | loss train:1.190348, test:0.369536 | lr:0.000000\n",
            "Epoch[8064/10000] | loss train:1.637935, test:0.491478 | lr:0.000000\n",
            "Epoch[8065/10000] | loss train:1.129146, test:0.380115 | lr:0.000000\n",
            "Epoch[8066/10000] | loss train:2.408435, test:0.263725 | lr:0.000000\n",
            "Epoch[8067/10000] | loss train:2.236914, test:0.506307 | lr:0.000000\n",
            "Epoch[8068/10000] | loss train:1.496561, test:0.130524 | lr:0.000000\n",
            "Epoch[8069/10000] | loss train:1.044643, test:0.685435 | lr:0.000000\n",
            "Epoch[8070/10000] | loss train:1.706695, test:0.633048 | lr:0.000000\n",
            "Epoch[8071/10000] | loss train:1.328302, test:0.245740 | lr:0.000000\n",
            "Epoch[8072/10000] | loss train:1.488035, test:0.533911 | lr:0.000000\n",
            "Epoch[8073/10000] | loss train:1.785188, test:0.319206 | lr:0.000000\n",
            "Epoch[8074/10000] | loss train:1.512903, test:0.187837 | lr:0.000000\n",
            "Epoch[8075/10000] | loss train:1.644827, test:0.928068 | lr:0.000000\n",
            "Epoch[8076/10000] | loss train:2.029954, test:1.214071 | lr:0.000000\n",
            "Epoch[8077/10000] | loss train:1.699998, test:0.573701 | lr:0.000000\n",
            "Epoch[8078/10000] | loss train:1.584791, test:0.343981 | lr:0.000000\n",
            "Epoch[8079/10000] | loss train:0.663163, test:0.728345 | lr:0.000000\n",
            "Epoch[8080/10000] | loss train:1.666731, test:0.213853 | lr:0.000000\n",
            "Epoch[8081/10000] | loss train:0.760993, test:0.321846 | lr:0.000000\n",
            "Epoch[8082/10000] | loss train:1.972441, test:0.230576 | lr:0.000000\n",
            "Epoch[8083/10000] | loss train:0.998105, test:1.040029 | lr:0.000000\n",
            "Epoch[8084/10000] | loss train:1.510784, test:1.418979 | lr:0.000000\n",
            "Epoch[8085/10000] | loss train:1.611012, test:0.634536 | lr:0.000000\n",
            "Epoch[8086/10000] | loss train:0.678795, test:0.600527 | lr:0.000000\n",
            "Epoch[8087/10000] | loss train:1.349719, test:1.732782 | lr:0.000000\n",
            "Epoch[8088/10000] | loss train:1.363973, test:0.537891 | lr:0.000000\n",
            "Epoch[8089/10000] | loss train:1.265728, test:0.305950 | lr:0.000000\n",
            "Epoch[8090/10000] | loss train:1.153268, test:0.484909 | lr:0.000000\n",
            "Epoch[8091/10000] | loss train:1.372464, test:0.324403 | lr:0.000000\n",
            "Epoch[8092/10000] | loss train:1.101035, test:0.470602 | lr:0.000000\n",
            "Epoch[8093/10000] | loss train:1.225142, test:0.470095 | lr:0.000000\n",
            "Epoch[8094/10000] | loss train:2.613094, test:1.449226 | lr:0.000000\n",
            "Epoch[8095/10000] | loss train:0.682271, test:2.067271 | lr:0.000000\n",
            "Epoch[8096/10000] | loss train:0.699772, test:1.253891 | lr:0.000000\n",
            "Epoch[8097/10000] | loss train:1.266258, test:1.163252 | lr:0.000000\n",
            "Epoch[8098/10000] | loss train:1.349539, test:0.120349 | lr:0.000000\n",
            "Epoch[8099/10000] | loss train:1.555635, test:0.358991 | lr:0.000000\n",
            "Epoch[8100/10000] | loss train:1.295883, test:0.377533 | lr:0.000000\n",
            "Epoch[8101/10000] | loss train:1.095214, test:1.350566 | lr:0.000000\n",
            "Epoch[8102/10000] | loss train:1.633425, test:0.656543 | lr:0.000000\n",
            "Epoch[8103/10000] | loss train:0.824702, test:0.543212 | lr:0.000000\n",
            "Epoch[8104/10000] | loss train:1.640483, test:1.393951 | lr:0.000000\n",
            "Epoch[8105/10000] | loss train:0.867942, test:0.483564 | lr:0.000000\n",
            "Epoch[8106/10000] | loss train:1.504042, test:0.524672 | lr:0.000000\n",
            "Epoch[8107/10000] | loss train:2.524990, test:0.224432 | lr:0.000000\n",
            "Epoch[8108/10000] | loss train:1.094464, test:1.456033 | lr:0.000000\n",
            "Epoch[8109/10000] | loss train:1.192363, test:0.873254 | lr:0.000000\n",
            "Epoch[8110/10000] | loss train:1.152740, test:0.377775 | lr:0.000000\n",
            "Epoch[8111/10000] | loss train:1.903404, test:0.624010 | lr:0.000000\n",
            "Epoch[8112/10000] | loss train:0.708036, test:0.401064 | lr:0.000000\n",
            "Epoch[8113/10000] | loss train:0.596022, test:0.413528 | lr:0.000000\n",
            "Epoch[8114/10000] | loss train:1.213828, test:1.383097 | lr:0.000000\n",
            "Epoch[8115/10000] | loss train:1.629848, test:1.052921 | lr:0.000000\n",
            "Epoch[8116/10000] | loss train:2.510797, test:1.457016 | lr:0.000000\n",
            "Epoch[8117/10000] | loss train:0.990330, test:0.367649 | lr:0.000000\n",
            "Epoch[8118/10000] | loss train:2.077727, test:0.168739 | lr:0.000000\n",
            "Epoch[8119/10000] | loss train:0.695796, test:0.647551 | lr:0.000000\n",
            "Epoch[8120/10000] | loss train:1.138584, test:0.104779 | lr:0.000000\n",
            "Epoch[8121/10000] | loss train:1.007641, test:0.619409 | lr:0.000000\n",
            "Epoch[8122/10000] | loss train:0.728360, test:0.630034 | lr:0.000000\n",
            "Epoch[8123/10000] | loss train:0.963963, test:0.255274 | lr:0.000000\n",
            "Epoch[8124/10000] | loss train:1.394650, test:0.911414 | lr:0.000000\n",
            "Epoch[8125/10000] | loss train:1.633520, test:0.301085 | lr:0.000000\n",
            "Epoch[8126/10000] | loss train:1.154329, test:0.206789 | lr:0.000000\n",
            "Epoch[8127/10000] | loss train:2.034551, test:0.889355 | lr:0.000000\n",
            "Epoch[8128/10000] | loss train:1.334080, test:0.720528 | lr:0.000000\n",
            "Epoch[8129/10000] | loss train:2.872015, test:0.224784 | lr:0.000000\n",
            "Epoch[8130/10000] | loss train:0.783024, test:0.670158 | lr:0.000000\n",
            "Epoch[8131/10000] | loss train:1.366435, test:0.494132 | lr:0.000000\n",
            "Epoch[8132/10000] | loss train:0.694772, test:0.184364 | lr:0.000000\n",
            "Epoch[8133/10000] | loss train:1.874069, test:0.324664 | lr:0.000000\n",
            "Epoch[8134/10000] | loss train:1.197098, test:0.828799 | lr:0.000000\n",
            "Epoch[8135/10000] | loss train:1.164369, test:0.358173 | lr:0.000000\n",
            "Epoch[8136/10000] | loss train:2.562000, test:0.673532 | lr:0.000000\n",
            "Epoch[8137/10000] | loss train:1.611554, test:0.262757 | lr:0.000000\n",
            "Epoch[8138/10000] | loss train:0.832847, test:0.282971 | lr:0.000000\n",
            "Epoch[8139/10000] | loss train:1.162350, test:0.425173 | lr:0.000000\n",
            "Epoch[8140/10000] | loss train:1.445869, test:1.147118 | lr:0.000000\n",
            "Epoch[8141/10000] | loss train:1.207883, test:0.511552 | lr:0.000000\n",
            "Epoch[8142/10000] | loss train:2.207771, test:1.224610 | lr:0.000000\n",
            "Epoch[8143/10000] | loss train:0.700696, test:1.107547 | lr:0.000000\n",
            "Epoch[8144/10000] | loss train:0.895832, test:0.323144 | lr:0.000000\n",
            "Epoch[8145/10000] | loss train:1.393276, test:0.374865 | lr:0.000000\n",
            "Epoch[8146/10000] | loss train:1.412502, test:0.529969 | lr:0.000000\n",
            "Epoch[8147/10000] | loss train:2.637015, test:1.284225 | lr:0.000000\n",
            "Epoch[8148/10000] | loss train:1.904327, test:2.311944 | lr:0.000000\n",
            "Epoch[8149/10000] | loss train:2.879884, test:1.488231 | lr:0.000000\n",
            "Epoch[8150/10000] | loss train:1.244376, test:1.237321 | lr:0.000000\n",
            "Epoch[8151/10000] | loss train:1.353520, test:1.110970 | lr:0.000000\n",
            "Epoch[8152/10000] | loss train:1.464425, test:0.459940 | lr:0.000000\n",
            "Epoch[8153/10000] | loss train:0.930013, test:0.225983 | lr:0.000000\n",
            "Epoch[8154/10000] | loss train:1.008091, test:1.112996 | lr:0.000000\n",
            "Epoch[8155/10000] | loss train:1.673230, test:1.335976 | lr:0.000000\n",
            "Epoch[8156/10000] | loss train:2.172464, test:0.251205 | lr:0.000000\n",
            "Epoch[8157/10000] | loss train:1.065211, test:1.294510 | lr:0.000000\n",
            "Epoch[8158/10000] | loss train:1.114349, test:1.340586 | lr:0.000000\n",
            "Epoch[8159/10000] | loss train:0.942207, test:0.873642 | lr:0.000000\n",
            "Epoch[8160/10000] | loss train:0.771730, test:0.544180 | lr:0.000000\n",
            "Epoch[8161/10000] | loss train:1.921140, test:0.479212 | lr:0.000000\n",
            "Epoch[8162/10000] | loss train:1.787947, test:0.599215 | lr:0.000000\n",
            "Epoch[8163/10000] | loss train:0.824813, test:0.464695 | lr:0.000000\n",
            "Epoch[8164/10000] | loss train:2.388484, test:0.620864 | lr:0.000000\n",
            "Epoch[8165/10000] | loss train:1.514179, test:0.723812 | lr:0.000000\n",
            "Epoch[8166/10000] | loss train:1.226494, test:0.051298 | lr:0.000000\n",
            "Epoch[8167/10000] | loss train:1.420295, test:1.156712 | lr:0.000000\n",
            "Epoch[8168/10000] | loss train:1.665095, test:1.187960 | lr:0.000000\n",
            "Epoch[8169/10000] | loss train:1.764587, test:0.528081 | lr:0.000000\n",
            "Epoch[8170/10000] | loss train:1.311265, test:0.147885 | lr:0.000000\n",
            "Epoch[8171/10000] | loss train:0.814912, test:0.777614 | lr:0.000000\n",
            "Epoch[8172/10000] | loss train:1.165154, test:0.430256 | lr:0.000000\n",
            "Epoch[8173/10000] | loss train:1.426107, test:0.302776 | lr:0.000000\n",
            "Epoch[8174/10000] | loss train:1.067710, test:0.949198 | lr:0.000000\n",
            "Epoch[8175/10000] | loss train:1.951831, test:0.726261 | lr:0.000000\n",
            "Epoch[8176/10000] | loss train:0.999059, test:1.415278 | lr:0.000000\n",
            "Epoch[8177/10000] | loss train:0.918317, test:0.342897 | lr:0.000000\n",
            "Epoch[8178/10000] | loss train:1.888786, test:0.147346 | lr:0.000000\n",
            "Epoch[8179/10000] | loss train:1.586606, test:0.185207 | lr:0.000000\n",
            "Epoch[8180/10000] | loss train:1.613513, test:0.319964 | lr:0.000000\n",
            "Epoch[8181/10000] | loss train:1.608328, test:0.548410 | lr:0.000000\n",
            "Epoch[8182/10000] | loss train:0.813225, test:1.144868 | lr:0.000000\n",
            "Epoch[8183/10000] | loss train:2.082305, test:0.326062 | lr:0.000000\n",
            "Epoch[8184/10000] | loss train:1.457902, test:0.851812 | lr:0.000000\n",
            "Epoch[8185/10000] | loss train:1.475759, test:0.305666 | lr:0.000000\n",
            "Epoch[8186/10000] | loss train:1.012666, test:1.440947 | lr:0.000000\n",
            "Epoch[8187/10000] | loss train:0.804809, test:0.325545 | lr:0.000000\n",
            "Epoch[8188/10000] | loss train:0.861186, test:0.123269 | lr:0.000000\n",
            "Epoch[8189/10000] | loss train:0.823457, test:0.352210 | lr:0.000000\n",
            "Epoch[8190/10000] | loss train:1.292083, test:0.344443 | lr:0.000000\n",
            "Epoch[8191/10000] | loss train:0.763945, test:0.206211 | lr:0.000000\n",
            "Epoch[8192/10000] | loss train:1.142410, test:0.428758 | lr:0.000000\n",
            "Epoch[8193/10000] | loss train:1.082604, test:1.432437 | lr:0.000000\n",
            "Epoch[8194/10000] | loss train:1.463849, test:1.082476 | lr:0.000000\n",
            "Epoch[8195/10000] | loss train:0.740118, test:0.160819 | lr:0.000000\n",
            "Epoch[8196/10000] | loss train:1.232201, test:0.588084 | lr:0.000000\n",
            "Epoch[8197/10000] | loss train:1.346099, test:1.053225 | lr:0.000000\n",
            "Epoch[8198/10000] | loss train:1.910504, test:0.636740 | lr:0.000000\n",
            "Epoch[8199/10000] | loss train:0.862352, test:0.382426 | lr:0.000000\n",
            "Epoch[8200/10000] | loss train:0.960619, test:0.936294 | lr:0.000000\n",
            "Epoch[8201/10000] | loss train:1.205285, test:0.111559 | lr:0.000000\n",
            "Epoch[8202/10000] | loss train:1.367454, test:0.221061 | lr:0.000000\n",
            "Epoch[8203/10000] | loss train:1.548675, test:1.194650 | lr:0.000000\n",
            "Epoch[8204/10000] | loss train:1.757133, test:1.358953 | lr:0.000000\n",
            "Epoch[8205/10000] | loss train:1.127914, test:0.304829 | lr:0.000000\n",
            "Epoch[8206/10000] | loss train:2.160480, test:0.606162 | lr:0.000000\n",
            "Epoch[8207/10000] | loss train:1.473690, test:0.136356 | lr:0.000000\n",
            "Epoch[8208/10000] | loss train:1.857180, test:0.514529 | lr:0.000000\n",
            "Epoch[8209/10000] | loss train:0.867101, test:0.548246 | lr:0.000000\n",
            "Epoch[8210/10000] | loss train:0.725992, test:0.754433 | lr:0.000000\n",
            "Epoch[8211/10000] | loss train:1.121850, test:0.884137 | lr:0.000000\n",
            "Epoch[8212/10000] | loss train:2.021801, test:1.427948 | lr:0.000000\n",
            "Epoch[8213/10000] | loss train:1.052552, test:0.228644 | lr:0.000000\n",
            "Epoch[8214/10000] | loss train:1.568827, test:0.328939 | lr:0.000000\n",
            "Epoch[8215/10000] | loss train:0.956344, test:1.442108 | lr:0.000000\n",
            "Epoch[8216/10000] | loss train:1.302798, test:0.625116 | lr:0.000000\n",
            "Epoch[8217/10000] | loss train:1.429141, test:0.218051 | lr:0.000000\n",
            "Epoch[8218/10000] | loss train:2.248157, test:0.098939 | lr:0.000000\n",
            "Epoch[8219/10000] | loss train:0.880819, test:1.826017 | lr:0.000000\n",
            "Epoch[8220/10000] | loss train:0.695963, test:0.723904 | lr:0.000000\n",
            "Epoch[8221/10000] | loss train:1.066279, test:0.881789 | lr:0.000000\n",
            "Epoch[8222/10000] | loss train:0.784299, test:1.826784 | lr:0.000000\n",
            "Epoch[8223/10000] | loss train:1.459641, test:0.677256 | lr:0.000000\n",
            "Epoch[8224/10000] | loss train:1.956775, test:0.643700 | lr:0.000000\n",
            "Epoch[8225/10000] | loss train:2.652196, test:0.561761 | lr:0.000000\n",
            "Epoch[8226/10000] | loss train:0.947404, test:0.389505 | lr:0.000000\n",
            "Epoch[8227/10000] | loss train:0.814590, test:0.520297 | lr:0.000000\n",
            "Epoch[8228/10000] | loss train:1.122611, test:0.423074 | lr:0.000000\n",
            "Epoch[8229/10000] | loss train:0.802677, test:1.368700 | lr:0.000000\n",
            "Epoch[8230/10000] | loss train:1.877316, test:0.363020 | lr:0.000000\n",
            "Epoch[8231/10000] | loss train:0.924961, test:0.331352 | lr:0.000000\n",
            "Epoch[8232/10000] | loss train:0.950539, test:1.741211 | lr:0.000000\n",
            "Epoch[8233/10000] | loss train:0.810740, test:0.389979 | lr:0.000000\n",
            "Epoch[8234/10000] | loss train:1.558609, test:0.296954 | lr:0.000000\n",
            "Epoch[8235/10000] | loss train:0.951195, test:0.049897 | lr:0.000000\n",
            "Epoch[8236/10000] | loss train:1.345029, test:0.275087 | lr:0.000000\n",
            "Epoch[8237/10000] | loss train:1.219240, test:0.596829 | lr:0.000000\n",
            "Epoch[8238/10000] | loss train:2.398349, test:0.836990 | lr:0.000000\n",
            "Epoch[8239/10000] | loss train:1.959890, test:0.602970 | lr:0.000000\n",
            "Epoch[8240/10000] | loss train:1.341451, test:0.615598 | lr:0.000000\n",
            "Epoch[8241/10000] | loss train:0.686780, test:1.374726 | lr:0.000000\n",
            "Epoch[8242/10000] | loss train:1.648453, test:0.450862 | lr:0.000000\n",
            "Epoch[8243/10000] | loss train:1.989662, test:0.146929 | lr:0.000000\n",
            "Epoch[8244/10000] | loss train:1.222763, test:0.918703 | lr:0.000000\n",
            "Epoch[8245/10000] | loss train:1.559190, test:0.208176 | lr:0.000000\n",
            "Epoch[8246/10000] | loss train:0.981415, test:0.536239 | lr:0.000000\n",
            "Epoch[8247/10000] | loss train:0.958270, test:0.112521 | lr:0.000000\n",
            "Epoch[8248/10000] | loss train:2.502215, test:0.573161 | lr:0.000000\n",
            "Epoch[8249/10000] | loss train:2.222869, test:2.153947 | lr:0.000000\n",
            "Epoch[8250/10000] | loss train:1.068828, test:1.354813 | lr:0.000000\n",
            "Epoch[8251/10000] | loss train:1.663107, test:0.298359 | lr:0.000000\n",
            "Epoch[8252/10000] | loss train:2.367816, test:1.621856 | lr:0.000000\n",
            "Epoch[8253/10000] | loss train:0.846107, test:0.383806 | lr:0.000000\n",
            "Epoch[8254/10000] | loss train:1.735266, test:0.242152 | lr:0.000000\n",
            "Epoch[8255/10000] | loss train:1.365587, test:0.745854 | lr:0.000000\n",
            "Epoch[8256/10000] | loss train:0.960579, test:0.053603 | lr:0.000000\n",
            "Epoch[8257/10000] | loss train:0.695817, test:0.347246 | lr:0.000000\n",
            "Epoch[8258/10000] | loss train:2.085364, test:0.228700 | lr:0.000000\n",
            "Epoch[8259/10000] | loss train:0.972365, test:1.218044 | lr:0.000000\n",
            "Epoch[8260/10000] | loss train:1.330628, test:1.733440 | lr:0.000000\n",
            "Epoch[8261/10000] | loss train:0.979902, test:1.428779 | lr:0.000000\n",
            "Epoch[8262/10000] | loss train:0.971876, test:1.073149 | lr:0.000000\n",
            "Epoch[8263/10000] | loss train:1.127564, test:0.219879 | lr:0.000000\n",
            "Epoch[8264/10000] | loss train:1.207274, test:0.403867 | lr:0.000000\n",
            "Epoch[8265/10000] | loss train:0.874735, test:0.860142 | lr:0.000000\n",
            "Epoch[8266/10000] | loss train:0.680176, test:0.159168 | lr:0.000000\n",
            "Epoch[8267/10000] | loss train:0.890280, test:0.051751 | lr:0.000000\n",
            "Epoch[8268/10000] | loss train:2.753382, test:0.397672 | lr:0.000000\n",
            "Epoch[8269/10000] | loss train:0.827684, test:1.092912 | lr:0.000000\n",
            "Epoch[8270/10000] | loss train:0.995992, test:0.450985 | lr:0.000000\n",
            "Epoch[8271/10000] | loss train:2.056149, test:0.218726 | lr:0.000000\n",
            "Epoch[8272/10000] | loss train:0.931528, test:0.196617 | lr:0.000000\n",
            "Epoch[8273/10000] | loss train:1.060941, test:0.075402 | lr:0.000000\n",
            "Epoch[8274/10000] | loss train:1.074267, test:1.604933 | lr:0.000000\n",
            "Epoch[8275/10000] | loss train:1.148757, test:0.825945 | lr:0.000000\n",
            "Epoch[8276/10000] | loss train:1.105650, test:0.189759 | lr:0.000000\n",
            "Epoch[8277/10000] | loss train:0.769732, test:0.321683 | lr:0.000000\n",
            "Epoch[8278/10000] | loss train:1.131099, test:0.068622 | lr:0.000000\n",
            "Epoch[8279/10000] | loss train:0.978152, test:0.193209 | lr:0.000000\n",
            "Epoch[8280/10000] | loss train:1.818457, test:0.533779 | lr:0.000000\n",
            "Epoch[8281/10000] | loss train:2.252702, test:0.223809 | lr:0.000000\n",
            "Epoch[8282/10000] | loss train:1.437998, test:0.477164 | lr:0.000000\n",
            "Epoch[8283/10000] | loss train:1.077417, test:1.492056 | lr:0.000000\n",
            "Epoch[8284/10000] | loss train:1.609932, test:0.265515 | lr:0.000000\n",
            "Epoch[8285/10000] | loss train:0.983257, test:0.928905 | lr:0.000000\n",
            "Epoch[8286/10000] | loss train:1.892555, test:0.533729 | lr:0.000000\n",
            "Epoch[8287/10000] | loss train:1.694857, test:1.587157 | lr:0.000000\n",
            "Epoch[8288/10000] | loss train:1.101721, test:0.910666 | lr:0.000000\n",
            "Epoch[8289/10000] | loss train:1.108497, test:1.960881 | lr:0.000000\n",
            "Epoch[8290/10000] | loss train:0.815439, test:1.169949 | lr:0.000000\n",
            "Epoch[8291/10000] | loss train:1.730823, test:1.021431 | lr:0.000000\n",
            "Epoch[8292/10000] | loss train:1.118108, test:0.456035 | lr:0.000000\n",
            "Epoch[8293/10000] | loss train:0.818056, test:0.249750 | lr:0.000000\n",
            "Epoch[8294/10000] | loss train:1.015125, test:0.197397 | lr:0.000000\n",
            "Epoch[8295/10000] | loss train:1.493447, test:0.328035 | lr:0.000000\n",
            "Epoch[8296/10000] | loss train:0.951827, test:0.601932 | lr:0.000000\n",
            "Epoch[8297/10000] | loss train:1.220434, test:0.303665 | lr:0.000000\n",
            "Epoch[8298/10000] | loss train:0.990231, test:0.277785 | lr:0.000000\n",
            "Epoch[8299/10000] | loss train:1.894085, test:1.031175 | lr:0.000000\n",
            "Epoch[8300/10000] | loss train:0.992980, test:1.512953 | lr:0.000000\n",
            "Epoch[8301/10000] | loss train:1.301930, test:0.425083 | lr:0.000000\n",
            "Epoch[8302/10000] | loss train:1.963875, test:2.188590 | lr:0.000000\n",
            "Epoch[8303/10000] | loss train:0.881030, test:0.981727 | lr:0.000000\n",
            "Epoch[8304/10000] | loss train:1.220324, test:0.511328 | lr:0.000000\n",
            "Epoch[8305/10000] | loss train:1.475621, test:1.042380 | lr:0.000000\n",
            "Epoch[8306/10000] | loss train:0.823957, test:1.988675 | lr:0.000000\n",
            "Epoch[8307/10000] | loss train:1.008939, test:0.588821 | lr:0.000000\n",
            "Epoch[8308/10000] | loss train:0.952386, test:0.690815 | lr:0.000000\n",
            "Epoch[8309/10000] | loss train:1.002903, test:0.688777 | lr:0.000000\n",
            "Epoch[8310/10000] | loss train:1.520160, test:0.287724 | lr:0.000000\n",
            "Epoch[8311/10000] | loss train:0.993424, test:0.277755 | lr:0.000000\n",
            "Epoch[8312/10000] | loss train:1.390204, test:0.138346 | lr:0.000000\n",
            "Epoch[8313/10000] | loss train:1.012986, test:0.346919 | lr:0.000000\n",
            "Epoch[8314/10000] | loss train:1.045842, test:0.366971 | lr:0.000000\n",
            "Epoch[8315/10000] | loss train:1.116619, test:0.338775 | lr:0.000000\n",
            "Epoch[8316/10000] | loss train:1.750627, test:0.365991 | lr:0.000000\n",
            "Epoch[8317/10000] | loss train:1.509477, test:0.619108 | lr:0.000000\n",
            "Epoch[8318/10000] | loss train:0.690329, test:0.257773 | lr:0.000000\n",
            "Epoch[8319/10000] | loss train:1.413937, test:0.949143 | lr:0.000000\n",
            "Epoch[8320/10000] | loss train:1.680660, test:0.086931 | lr:0.000000\n",
            "Epoch[8321/10000] | loss train:1.692374, test:1.074787 | lr:0.000000\n",
            "Epoch[8322/10000] | loss train:1.326183, test:0.432879 | lr:0.000000\n",
            "Epoch[8323/10000] | loss train:1.337308, test:0.901841 | lr:0.000000\n",
            "Epoch[8324/10000] | loss train:2.826613, test:0.485300 | lr:0.000000\n",
            "Epoch[8325/10000] | loss train:0.840027, test:0.317960 | lr:0.000000\n",
            "Epoch[8326/10000] | loss train:1.282549, test:0.186504 | lr:0.000000\n",
            "Epoch[8327/10000] | loss train:0.993421, test:1.301345 | lr:0.000000\n",
            "Epoch[8328/10000] | loss train:1.118449, test:0.238725 | lr:0.000000\n",
            "Epoch[8329/10000] | loss train:1.140906, test:0.540185 | lr:0.000000\n",
            "Epoch[8330/10000] | loss train:1.681370, test:1.398289 | lr:0.000000\n",
            "Epoch[8331/10000] | loss train:1.357198, test:0.340500 | lr:0.000000\n",
            "Epoch[8332/10000] | loss train:1.314076, test:0.330295 | lr:0.000000\n",
            "Epoch[8333/10000] | loss train:1.020479, test:0.148972 | lr:0.000000\n",
            "Epoch[8334/10000] | loss train:1.565576, test:0.451388 | lr:0.000000\n",
            "Epoch[8335/10000] | loss train:0.762924, test:0.364588 | lr:0.000000\n",
            "Epoch[8336/10000] | loss train:1.047646, test:0.192624 | lr:0.000000\n",
            "Epoch[8337/10000] | loss train:1.910374, test:0.328054 | lr:0.000000\n",
            "Epoch[8338/10000] | loss train:1.003739, test:0.311495 | lr:0.000000\n",
            "Epoch[8339/10000] | loss train:1.023265, test:1.664021 | lr:0.000000\n",
            "Epoch[8340/10000] | loss train:1.348962, test:1.318627 | lr:0.000000\n",
            "Epoch[8341/10000] | loss train:0.939659, test:1.242885 | lr:0.000000\n",
            "Epoch[8342/10000] | loss train:0.840745, test:0.466361 | lr:0.000000\n",
            "Epoch[8343/10000] | loss train:1.326524, test:0.920522 | lr:0.000000\n",
            "Epoch[8344/10000] | loss train:0.998515, test:0.448250 | lr:0.000000\n",
            "Epoch[8345/10000] | loss train:1.388087, test:0.630108 | lr:0.000000\n",
            "Epoch[8346/10000] | loss train:1.490305, test:0.155831 | lr:0.000000\n",
            "Epoch[8347/10000] | loss train:1.175221, test:1.193370 | lr:0.000000\n",
            "Epoch[8348/10000] | loss train:1.943982, test:0.707640 | lr:0.000000\n",
            "Epoch[8349/10000] | loss train:1.238538, test:0.296439 | lr:0.000000\n",
            "Epoch[8350/10000] | loss train:1.504081, test:0.237157 | lr:0.000000\n",
            "Epoch[8351/10000] | loss train:0.725290, test:1.258048 | lr:0.000000\n",
            "Epoch[8352/10000] | loss train:1.192092, test:0.462712 | lr:0.000000\n",
            "Epoch[8353/10000] | loss train:1.051679, test:0.456434 | lr:0.000000\n",
            "Epoch[8354/10000] | loss train:1.141859, test:0.327079 | lr:0.000000\n",
            "Epoch[8355/10000] | loss train:0.733683, test:0.724266 | lr:0.000000\n",
            "Epoch[8356/10000] | loss train:1.333038, test:0.426933 | lr:0.000000\n",
            "Epoch[8357/10000] | loss train:2.398452, test:1.080640 | lr:0.000000\n",
            "Epoch[8358/10000] | loss train:2.815809, test:0.598360 | lr:0.000000\n",
            "Epoch[8359/10000] | loss train:1.598884, test:0.478429 | lr:0.000000\n",
            "Epoch[8360/10000] | loss train:1.063720, test:0.217208 | lr:0.000000\n",
            "Epoch[8361/10000] | loss train:1.737996, test:0.319362 | lr:0.000000\n",
            "Epoch[8362/10000] | loss train:1.164495, test:0.927746 | lr:0.000000\n",
            "Epoch[8363/10000] | loss train:1.509810, test:0.243629 | lr:0.000000\n",
            "Epoch[8364/10000] | loss train:0.990628, test:0.973524 | lr:0.000000\n",
            "Epoch[8365/10000] | loss train:1.138282, test:0.489222 | lr:0.000000\n",
            "Epoch[8366/10000] | loss train:1.115857, test:0.581225 | lr:0.000000\n",
            "Epoch[8367/10000] | loss train:2.627901, test:0.324714 | lr:0.000000\n",
            "Epoch[8368/10000] | loss train:0.859309, test:0.246187 | lr:0.000000\n",
            "Epoch[8369/10000] | loss train:1.072604, test:0.690803 | lr:0.000000\n",
            "Epoch[8370/10000] | loss train:1.468160, test:0.638559 | lr:0.000000\n",
            "Epoch[8371/10000] | loss train:0.830456, test:0.409732 | lr:0.000000\n",
            "Epoch[8372/10000] | loss train:1.360160, test:0.623556 | lr:0.000000\n",
            "Epoch[8373/10000] | loss train:0.734926, test:0.569163 | lr:0.000000\n",
            "Epoch[8374/10000] | loss train:1.388045, test:0.383426 | lr:0.000000\n",
            "Epoch[8375/10000] | loss train:1.521734, test:0.286081 | lr:0.000000\n",
            "Epoch[8376/10000] | loss train:1.539614, test:0.295869 | lr:0.000000\n",
            "Epoch[8377/10000] | loss train:2.191617, test:0.245158 | lr:0.000000\n",
            "Epoch[8378/10000] | loss train:0.934686, test:1.360853 | lr:0.000000\n",
            "Epoch[8379/10000] | loss train:1.352025, test:1.667091 | lr:0.000000\n",
            "Epoch[8380/10000] | loss train:0.681882, test:0.399507 | lr:0.000000\n",
            "Epoch[8381/10000] | loss train:0.633136, test:0.168912 | lr:0.000000\n",
            "Epoch[8382/10000] | loss train:1.396137, test:1.087318 | lr:0.000000\n",
            "Epoch[8383/10000] | loss train:1.475872, test:1.735397 | lr:0.000000\n",
            "Epoch[8384/10000] | loss train:1.315375, test:0.169546 | lr:0.000000\n",
            "Epoch[8385/10000] | loss train:1.517977, test:1.362134 | lr:0.000000\n",
            "Epoch[8386/10000] | loss train:1.000337, test:0.655963 | lr:0.000000\n",
            "Epoch[8387/10000] | loss train:1.429824, test:0.098419 | lr:0.000000\n",
            "Epoch[8388/10000] | loss train:1.095273, test:1.086322 | lr:0.000000\n",
            "Epoch[8389/10000] | loss train:1.704899, test:1.327952 | lr:0.000000\n",
            "Epoch[8390/10000] | loss train:1.584354, test:0.446558 | lr:0.000000\n",
            "Epoch[8391/10000] | loss train:0.880589, test:0.265957 | lr:0.000000\n",
            "Epoch[8392/10000] | loss train:1.545685, test:0.163236 | lr:0.000000\n",
            "Epoch[8393/10000] | loss train:0.888114, test:0.382746 | lr:0.000000\n",
            "Epoch[8394/10000] | loss train:0.993065, test:1.328099 | lr:0.000000\n",
            "Epoch[8395/10000] | loss train:0.643372, test:0.755048 | lr:0.000000\n",
            "Epoch[8396/10000] | loss train:1.106871, test:0.552842 | lr:0.000000\n",
            "Epoch[8397/10000] | loss train:1.187528, test:0.411307 | lr:0.000000\n",
            "Epoch[8398/10000] | loss train:1.187728, test:0.478870 | lr:0.000000\n",
            "Epoch[8399/10000] | loss train:0.960149, test:1.041163 | lr:0.000000\n",
            "Epoch[8400/10000] | loss train:1.598305, test:0.242541 | lr:0.000000\n",
            "Epoch[8401/10000] | loss train:1.133078, test:1.483808 | lr:0.000000\n",
            "Epoch[8402/10000] | loss train:1.221749, test:0.172422 | lr:0.000000\n",
            "Epoch[8403/10000] | loss train:1.230466, test:1.885576 | lr:0.000000\n",
            "Epoch[8404/10000] | loss train:0.806785, test:0.691395 | lr:0.000000\n",
            "Epoch[8405/10000] | loss train:1.113432, test:0.934118 | lr:0.000000\n",
            "Epoch[8406/10000] | loss train:0.672788, test:0.718141 | lr:0.000000\n",
            "Epoch[8407/10000] | loss train:1.303310, test:0.491427 | lr:0.000000\n",
            "Epoch[8408/10000] | loss train:0.900814, test:1.360034 | lr:0.000000\n",
            "Epoch[8409/10000] | loss train:1.346842, test:0.338920 | lr:0.000000\n",
            "Epoch[8410/10000] | loss train:0.879287, test:0.541786 | lr:0.000000\n",
            "Epoch[8411/10000] | loss train:1.891611, test:0.148890 | lr:0.000000\n",
            "Epoch[8412/10000] | loss train:1.021314, test:0.164081 | lr:0.000000\n",
            "Epoch[8413/10000] | loss train:1.351254, test:2.758332 | lr:0.000000\n",
            "Epoch[8414/10000] | loss train:1.150893, test:0.273739 | lr:0.000000\n",
            "Epoch[8415/10000] | loss train:1.033426, test:0.651315 | lr:0.000000\n",
            "Epoch[8416/10000] | loss train:1.061970, test:0.321707 | lr:0.000000\n",
            "Epoch[8417/10000] | loss train:0.887213, test:0.683819 | lr:0.000000\n",
            "Epoch[8418/10000] | loss train:0.867047, test:0.516195 | lr:0.000000\n",
            "Epoch[8419/10000] | loss train:1.925923, test:1.084806 | lr:0.000000\n",
            "Epoch[8420/10000] | loss train:0.826426, test:0.123974 | lr:0.000000\n",
            "Epoch[8421/10000] | loss train:1.465562, test:0.970084 | lr:0.000000\n",
            "Epoch[8422/10000] | loss train:0.765551, test:0.253734 | lr:0.000000\n",
            "Epoch[8423/10000] | loss train:1.093991, test:0.385749 | lr:0.000000\n",
            "Epoch[8424/10000] | loss train:0.855927, test:0.493150 | lr:0.000000\n",
            "Epoch[8425/10000] | loss train:1.275180, test:0.243793 | lr:0.000000\n",
            "Epoch[8426/10000] | loss train:1.536334, test:0.400023 | lr:0.000000\n",
            "Epoch[8427/10000] | loss train:1.230580, test:0.659980 | lr:0.000000\n",
            "Epoch[8428/10000] | loss train:1.998208, test:1.073512 | lr:0.000000\n",
            "Epoch[8429/10000] | loss train:0.841800, test:1.407370 | lr:0.000000\n",
            "Epoch[8430/10000] | loss train:1.534861, test:0.665803 | lr:0.000000\n",
            "Epoch[8431/10000] | loss train:0.841190, test:0.284739 | lr:0.000000\n",
            "Epoch[8432/10000] | loss train:1.401037, test:0.690343 | lr:0.000000\n",
            "Epoch[8433/10000] | loss train:1.627126, test:0.707451 | lr:0.000000\n",
            "Epoch[8434/10000] | loss train:1.554220, test:0.589684 | lr:0.000000\n",
            "Epoch[8435/10000] | loss train:1.000537, test:0.467557 | lr:0.000000\n",
            "Epoch[8436/10000] | loss train:1.149892, test:0.908986 | lr:0.000000\n",
            "Epoch[8437/10000] | loss train:0.699338, test:0.235956 | lr:0.000000\n",
            "Epoch[8438/10000] | loss train:0.886361, test:0.224774 | lr:0.000000\n",
            "Epoch[8439/10000] | loss train:1.486127, test:0.206566 | lr:0.000000\n",
            "Epoch[8440/10000] | loss train:0.921105, test:1.182168 | lr:0.000000\n",
            "Epoch[8441/10000] | loss train:1.561941, test:0.731618 | lr:0.000000\n",
            "Epoch[8442/10000] | loss train:2.065902, test:0.173431 | lr:0.000000\n",
            "Epoch[8443/10000] | loss train:1.902671, test:0.324326 | lr:0.000000\n",
            "Epoch[8444/10000] | loss train:1.377265, test:0.195789 | lr:0.000000\n",
            "Epoch[8445/10000] | loss train:0.875699, test:0.514491 | lr:0.000000\n",
            "Epoch[8446/10000] | loss train:1.958890, test:0.488934 | lr:0.000000\n",
            "Epoch[8447/10000] | loss train:0.928527, test:0.395686 | lr:0.000000\n",
            "Epoch[8448/10000] | loss train:2.212236, test:0.442624 | lr:0.000000\n",
            "Epoch[8449/10000] | loss train:1.056829, test:0.581004 | lr:0.000000\n",
            "Epoch[8450/10000] | loss train:0.991918, test:0.658293 | lr:0.000000\n",
            "Epoch[8451/10000] | loss train:1.441779, test:0.980513 | lr:0.000000\n",
            "Epoch[8452/10000] | loss train:1.682942, test:0.747951 | lr:0.000000\n",
            "Epoch[8453/10000] | loss train:1.237967, test:0.593576 | lr:0.000000\n",
            "Epoch[8454/10000] | loss train:1.471494, test:0.258083 | lr:0.000000\n",
            "Epoch[8455/10000] | loss train:1.116795, test:1.439581 | lr:0.000000\n",
            "Epoch[8456/10000] | loss train:2.284644, test:1.275147 | lr:0.000000\n",
            "Epoch[8457/10000] | loss train:2.068996, test:0.229429 | lr:0.000000\n",
            "Epoch[8458/10000] | loss train:1.832179, test:0.244734 | lr:0.000000\n",
            "Epoch[8459/10000] | loss train:1.666411, test:0.168535 | lr:0.000000\n",
            "Epoch[8460/10000] | loss train:2.416979, test:0.229056 | lr:0.000000\n",
            "Epoch[8461/10000] | loss train:0.752569, test:1.800960 | lr:0.000000\n",
            "Epoch[8462/10000] | loss train:1.203699, test:0.668152 | lr:0.000000\n",
            "Epoch[8463/10000] | loss train:1.042807, test:0.422562 | lr:0.000000\n",
            "Epoch[8464/10000] | loss train:1.644403, test:0.173806 | lr:0.000000\n",
            "Epoch[8465/10000] | loss train:1.861467, test:1.042487 | lr:0.000000\n",
            "Epoch[8466/10000] | loss train:1.258063, test:0.208657 | lr:0.000000\n",
            "Epoch[8467/10000] | loss train:0.980207, test:0.491505 | lr:0.000000\n",
            "Epoch[8468/10000] | loss train:1.267397, test:0.302830 | lr:0.000000\n",
            "Epoch[8469/10000] | loss train:1.088600, test:0.225182 | lr:0.000000\n",
            "Epoch[8470/10000] | loss train:1.182519, test:0.157796 | lr:0.000000\n",
            "Epoch[8471/10000] | loss train:1.756866, test:0.193047 | lr:0.000000\n",
            "Epoch[8472/10000] | loss train:1.344295, test:0.687059 | lr:0.000000\n",
            "Epoch[8473/10000] | loss train:1.752766, test:0.635279 | lr:0.000000\n",
            "Epoch[8474/10000] | loss train:1.967203, test:0.142781 | lr:0.000000\n",
            "Epoch[8475/10000] | loss train:0.954825, test:0.762448 | lr:0.000000\n",
            "Epoch[8476/10000] | loss train:0.980317, test:1.629153 | lr:0.000000\n",
            "Epoch[8477/10000] | loss train:1.495841, test:1.779301 | lr:0.000000\n",
            "Epoch[8478/10000] | loss train:0.664696, test:1.397323 | lr:0.000000\n",
            "Epoch[8479/10000] | loss train:1.950345, test:0.571986 | lr:0.000000\n",
            "Epoch[8480/10000] | loss train:1.350800, test:1.318372 | lr:0.000000\n",
            "Epoch[8481/10000] | loss train:1.007352, test:1.061832 | lr:0.000000\n",
            "Epoch[8482/10000] | loss train:1.796048, test:0.346720 | lr:0.000000\n",
            "Epoch[8483/10000] | loss train:1.286954, test:0.577751 | lr:0.000000\n",
            "Epoch[8484/10000] | loss train:0.997175, test:1.286119 | lr:0.000000\n",
            "Epoch[8485/10000] | loss train:1.774802, test:1.074987 | lr:0.000000\n",
            "Epoch[8486/10000] | loss train:1.527296, test:0.256815 | lr:0.000000\n",
            "Epoch[8487/10000] | loss train:1.035755, test:0.841013 | lr:0.000000\n",
            "Epoch[8488/10000] | loss train:1.061622, test:0.407248 | lr:0.000000\n",
            "Epoch[8489/10000] | loss train:1.827147, test:0.259027 | lr:0.000000\n",
            "Epoch[8490/10000] | loss train:0.959565, test:0.050085 | lr:0.000000\n",
            "Epoch[8491/10000] | loss train:1.624635, test:0.596689 | lr:0.000000\n",
            "Epoch[8492/10000] | loss train:1.506478, test:0.237047 | lr:0.000000\n",
            "Epoch[8493/10000] | loss train:1.007795, test:0.252035 | lr:0.000000\n",
            "Epoch[8494/10000] | loss train:1.336750, test:0.069333 | lr:0.000000\n",
            "Epoch[8495/10000] | loss train:1.410115, test:1.434800 | lr:0.000000\n",
            "Epoch[8496/10000] | loss train:1.222052, test:0.132249 | lr:0.000000\n",
            "Epoch[8497/10000] | loss train:1.035930, test:0.146479 | lr:0.000000\n",
            "Epoch[8498/10000] | loss train:2.018592, test:0.201152 | lr:0.000000\n",
            "Epoch[8499/10000] | loss train:0.714685, test:0.340658 | lr:0.000000\n",
            "Epoch[8500/10000] | loss train:1.190706, test:0.933371 | lr:0.000000\n",
            "Epoch[8501/10000] | loss train:1.020467, test:0.563517 | lr:0.000000\n",
            "Epoch[8502/10000] | loss train:1.198632, test:0.582724 | lr:0.000000\n",
            "Epoch[8503/10000] | loss train:0.759921, test:0.161767 | lr:0.000000\n",
            "Epoch[8504/10000] | loss train:1.532143, test:0.247386 | lr:0.000000\n",
            "Epoch[8505/10000] | loss train:0.821846, test:0.212377 | lr:0.000000\n",
            "Epoch[8506/10000] | loss train:0.842181, test:0.207023 | lr:0.000000\n",
            "Epoch[8507/10000] | loss train:1.268288, test:0.178626 | lr:0.000000\n",
            "Epoch[8508/10000] | loss train:1.155589, test:0.907388 | lr:0.000000\n",
            "Epoch[8509/10000] | loss train:1.132607, test:0.677383 | lr:0.000000\n",
            "Epoch[8510/10000] | loss train:2.075817, test:0.926492 | lr:0.000000\n",
            "Epoch[8511/10000] | loss train:2.227835, test:0.497465 | lr:0.000000\n",
            "Epoch[8512/10000] | loss train:1.281922, test:1.287279 | lr:0.000000\n",
            "Epoch[8513/10000] | loss train:2.264075, test:1.268625 | lr:0.000000\n",
            "Epoch[8514/10000] | loss train:1.464121, test:0.249466 | lr:0.000000\n",
            "Epoch[8515/10000] | loss train:1.533581, test:0.344506 | lr:0.000000\n",
            "Epoch[8516/10000] | loss train:1.104081, test:0.310300 | lr:0.000000\n",
            "Epoch[8517/10000] | loss train:1.791847, test:0.821543 | lr:0.000000\n",
            "Epoch[8518/10000] | loss train:1.166623, test:0.049970 | lr:0.000000\n",
            "Epoch[8519/10000] | loss train:1.644464, test:0.569399 | lr:0.000000\n",
            "Epoch[8520/10000] | loss train:0.705813, test:0.234443 | lr:0.000000\n",
            "Epoch[8521/10000] | loss train:0.698400, test:1.485508 | lr:0.000000\n",
            "Epoch[8522/10000] | loss train:1.561575, test:0.348337 | lr:0.000000\n",
            "Epoch[8523/10000] | loss train:1.414911, test:1.688440 | lr:0.000000\n",
            "Epoch[8524/10000] | loss train:2.370398, test:0.207592 | lr:0.000000\n",
            "Epoch[8525/10000] | loss train:1.836162, test:1.768785 | lr:0.000000\n",
            "Epoch[8526/10000] | loss train:1.521281, test:0.444504 | lr:0.000000\n",
            "Epoch[8527/10000] | loss train:0.777011, test:0.476758 | lr:0.000000\n",
            "Epoch[8528/10000] | loss train:0.720960, test:1.280137 | lr:0.000000\n",
            "Epoch[8529/10000] | loss train:0.824196, test:0.359740 | lr:0.000000\n",
            "Epoch[8530/10000] | loss train:1.184221, test:0.238141 | lr:0.000000\n",
            "Epoch[8531/10000] | loss train:1.336448, test:1.137196 | lr:0.000000\n",
            "Epoch[8532/10000] | loss train:1.182902, test:1.079471 | lr:0.000000\n",
            "Epoch[8533/10000] | loss train:1.526771, test:1.914546 | lr:0.000000\n",
            "Epoch[8534/10000] | loss train:1.469471, test:1.668958 | lr:0.000000\n",
            "Epoch[8535/10000] | loss train:0.973980, test:0.745159 | lr:0.000000\n",
            "Epoch[8536/10000] | loss train:0.713135, test:0.917184 | lr:0.000000\n",
            "Epoch[8537/10000] | loss train:0.717555, test:0.837260 | lr:0.000000\n",
            "Epoch[8538/10000] | loss train:1.086449, test:1.278075 | lr:0.000000\n",
            "Epoch[8539/10000] | loss train:1.205692, test:0.672537 | lr:0.000000\n",
            "Epoch[8540/10000] | loss train:1.713855, test:0.655613 | lr:0.000000\n",
            "Epoch[8541/10000] | loss train:2.066844, test:0.241797 | lr:0.000000\n",
            "Epoch[8542/10000] | loss train:1.177796, test:1.812482 | lr:0.000000\n",
            "Epoch[8543/10000] | loss train:1.216240, test:0.936636 | lr:0.000000\n",
            "Epoch[8544/10000] | loss train:1.268283, test:0.108624 | lr:0.000000\n",
            "Epoch[8545/10000] | loss train:1.103379, test:1.599608 | lr:0.000000\n",
            "Epoch[8546/10000] | loss train:0.750000, test:0.598779 | lr:0.000000\n",
            "Epoch[8547/10000] | loss train:1.190109, test:0.866618 | lr:0.000000\n",
            "Epoch[8548/10000] | loss train:0.729025, test:0.338607 | lr:0.000000\n",
            "Epoch[8549/10000] | loss train:0.970503, test:0.245158 | lr:0.000000\n",
            "Epoch[8550/10000] | loss train:1.123941, test:0.504734 | lr:0.000000\n",
            "Epoch[8551/10000] | loss train:0.867307, test:0.250297 | lr:0.000000\n",
            "Epoch[8552/10000] | loss train:1.125387, test:0.429854 | lr:0.000000\n",
            "Epoch[8553/10000] | loss train:1.045140, test:0.229148 | lr:0.000000\n",
            "Epoch[8554/10000] | loss train:0.918110, test:2.263888 | lr:0.000000\n",
            "Epoch[8555/10000] | loss train:1.224937, test:1.890171 | lr:0.000000\n",
            "Epoch[8556/10000] | loss train:1.476646, test:0.543310 | lr:0.000000\n",
            "Epoch[8557/10000] | loss train:1.097831, test:0.692968 | lr:0.000000\n",
            "Epoch[8558/10000] | loss train:0.766863, test:0.720969 | lr:0.000000\n",
            "Epoch[8559/10000] | loss train:1.349325, test:0.168736 | lr:0.000000\n",
            "Epoch[8560/10000] | loss train:1.127553, test:1.091486 | lr:0.000000\n",
            "Epoch[8561/10000] | loss train:1.825355, test:0.709549 | lr:0.000000\n",
            "Epoch[8562/10000] | loss train:1.562613, test:0.437710 | lr:0.000000\n",
            "Epoch[8563/10000] | loss train:1.562677, test:0.399278 | lr:0.000000\n",
            "Epoch[8564/10000] | loss train:1.180639, test:0.545084 | lr:0.000000\n",
            "Epoch[8565/10000] | loss train:1.580644, test:0.808158 | lr:0.000000\n",
            "Epoch[8566/10000] | loss train:0.975113, test:0.140399 | lr:0.000000\n",
            "Epoch[8567/10000] | loss train:1.467760, test:0.405132 | lr:0.000000\n",
            "Epoch[8568/10000] | loss train:1.520460, test:0.355697 | lr:0.000000\n",
            "Epoch[8569/10000] | loss train:1.267769, test:1.837900 | lr:0.000000\n",
            "Epoch[8570/10000] | loss train:2.473064, test:0.167937 | lr:0.000000\n",
            "Epoch[8571/10000] | loss train:1.223984, test:0.544502 | lr:0.000000\n",
            "Epoch[8572/10000] | loss train:0.856983, test:0.212302 | lr:0.000000\n",
            "Epoch[8573/10000] | loss train:0.948760, test:0.608504 | lr:0.000000\n",
            "Epoch[8574/10000] | loss train:1.363987, test:0.234874 | lr:0.000000\n",
            "Epoch[8575/10000] | loss train:0.631567, test:0.328918 | lr:0.000000\n",
            "Epoch[8576/10000] | loss train:1.148332, test:0.293956 | lr:0.000000\n",
            "Epoch[8577/10000] | loss train:1.508871, test:1.025816 | lr:0.000000\n",
            "Epoch[8578/10000] | loss train:1.640628, test:1.540057 | lr:0.000000\n",
            "Epoch[8579/10000] | loss train:0.627053, test:0.965207 | lr:0.000000\n",
            "Epoch[8580/10000] | loss train:0.845986, test:0.098835 | lr:0.000000\n",
            "Epoch[8581/10000] | loss train:1.757721, test:1.792074 | lr:0.000000\n",
            "Epoch[8582/10000] | loss train:0.961390, test:0.374814 | lr:0.000000\n",
            "Epoch[8583/10000] | loss train:1.241435, test:0.369413 | lr:0.000000\n",
            "Epoch[8584/10000] | loss train:1.512634, test:0.121528 | lr:0.000000\n",
            "Epoch[8585/10000] | loss train:2.040339, test:0.409624 | lr:0.000000\n",
            "Epoch[8586/10000] | loss train:1.903194, test:0.752961 | lr:0.000000\n",
            "Epoch[8587/10000] | loss train:1.631511, test:0.241784 | lr:0.000000\n",
            "Epoch[8588/10000] | loss train:1.694367, test:1.377426 | lr:0.000000\n",
            "Epoch[8589/10000] | loss train:0.743744, test:0.145778 | lr:0.000000\n",
            "Epoch[8590/10000] | loss train:2.442222, test:0.564261 | lr:0.000000\n",
            "Epoch[8591/10000] | loss train:1.980458, test:0.750030 | lr:0.000000\n",
            "Epoch[8592/10000] | loss train:1.181993, test:0.197634 | lr:0.000000\n",
            "Epoch[8593/10000] | loss train:1.539711, test:1.593340 | lr:0.000000\n",
            "Epoch[8594/10000] | loss train:1.226333, test:0.599690 | lr:0.000000\n",
            "Epoch[8595/10000] | loss train:1.379969, test:1.490437 | lr:0.000000\n",
            "Epoch[8596/10000] | loss train:0.992401, test:1.299784 | lr:0.000000\n",
            "Epoch[8597/10000] | loss train:0.805282, test:0.294462 | lr:0.000000\n",
            "Epoch[8598/10000] | loss train:1.458894, test:0.542791 | lr:0.000000\n",
            "Epoch[8599/10000] | loss train:1.765325, test:0.573249 | lr:0.000000\n",
            "Epoch[8600/10000] | loss train:0.835077, test:0.761666 | lr:0.000000\n",
            "Epoch[8601/10000] | loss train:1.174869, test:0.662528 | lr:0.000000\n",
            "Epoch[8602/10000] | loss train:1.319351, test:0.655701 | lr:0.000000\n",
            "Epoch[8603/10000] | loss train:1.220521, test:1.179522 | lr:0.000000\n",
            "Epoch[8604/10000] | loss train:1.042897, test:1.122510 | lr:0.000000\n",
            "Epoch[8605/10000] | loss train:1.258930, test:0.473712 | lr:0.000000\n",
            "Epoch[8606/10000] | loss train:1.117321, test:0.661932 | lr:0.000000\n",
            "Epoch[8607/10000] | loss train:0.717175, test:0.576855 | lr:0.000000\n",
            "Epoch[8608/10000] | loss train:1.451253, test:0.763483 | lr:0.000000\n",
            "Epoch[8609/10000] | loss train:2.142947, test:0.567140 | lr:0.000000\n",
            "Epoch[8610/10000] | loss train:1.797978, test:0.451210 | lr:0.000000\n",
            "Epoch[8611/10000] | loss train:1.702949, test:0.240686 | lr:0.000000\n",
            "Epoch[8612/10000] | loss train:1.060769, test:0.726310 | lr:0.000000\n",
            "Epoch[8613/10000] | loss train:1.128975, test:0.579003 | lr:0.000000\n",
            "Epoch[8614/10000] | loss train:1.046962, test:0.921431 | lr:0.000000\n",
            "Epoch[8615/10000] | loss train:1.665803, test:0.680872 | lr:0.000000\n",
            "Epoch[8616/10000] | loss train:1.013997, test:0.731990 | lr:0.000000\n",
            "Epoch[8617/10000] | loss train:1.494689, test:0.368121 | lr:0.000000\n",
            "Epoch[8618/10000] | loss train:1.369350, test:0.229388 | lr:0.000000\n",
            "Epoch[8619/10000] | loss train:1.613906, test:0.543472 | lr:0.000000\n",
            "Epoch[8620/10000] | loss train:1.189344, test:0.556210 | lr:0.000000\n",
            "Epoch[8621/10000] | loss train:0.896795, test:1.963881 | lr:0.000000\n",
            "Epoch[8622/10000] | loss train:1.079564, test:0.742159 | lr:0.000000\n",
            "Epoch[8623/10000] | loss train:0.722644, test:0.692212 | lr:0.000000\n",
            "Epoch[8624/10000] | loss train:1.959051, test:0.932714 | lr:0.000000\n",
            "Epoch[8625/10000] | loss train:1.362281, test:0.424998 | lr:0.000000\n",
            "Epoch[8626/10000] | loss train:0.874908, test:1.083202 | lr:0.000000\n",
            "Epoch[8627/10000] | loss train:1.070918, test:0.328338 | lr:0.000000\n",
            "Epoch[8628/10000] | loss train:1.005810, test:0.197568 | lr:0.000000\n",
            "Epoch[8629/10000] | loss train:1.144944, test:1.052656 | lr:0.000000\n",
            "Epoch[8630/10000] | loss train:2.401615, test:0.214975 | lr:0.000000\n",
            "Epoch[8631/10000] | loss train:1.161873, test:0.612578 | lr:0.000000\n",
            "Epoch[8632/10000] | loss train:1.672569, test:1.421122 | lr:0.000000\n",
            "Epoch[8633/10000] | loss train:2.071546, test:1.983559 | lr:0.000000\n",
            "Epoch[8634/10000] | loss train:1.324623, test:0.619723 | lr:0.000000\n",
            "Epoch[8635/10000] | loss train:1.441640, test:0.139909 | lr:0.000000\n",
            "Epoch[8636/10000] | loss train:2.141649, test:0.588655 | lr:0.000000\n",
            "Epoch[8637/10000] | loss train:0.675609, test:1.007720 | lr:0.000000\n",
            "Epoch[8638/10000] | loss train:0.864971, test:0.732243 | lr:0.000000\n",
            "Epoch[8639/10000] | loss train:1.896357, test:0.244819 | lr:0.000000\n",
            "Epoch[8640/10000] | loss train:1.492078, test:0.385526 | lr:0.000000\n",
            "Epoch[8641/10000] | loss train:1.339091, test:1.243515 | lr:0.000000\n",
            "Epoch[8642/10000] | loss train:1.940456, test:0.266732 | lr:0.000000\n",
            "Epoch[8643/10000] | loss train:0.895798, test:0.680160 | lr:0.000000\n",
            "Epoch[8644/10000] | loss train:1.770434, test:0.388937 | lr:0.000000\n",
            "Epoch[8645/10000] | loss train:1.041619, test:0.292660 | lr:0.000000\n",
            "Epoch[8646/10000] | loss train:1.445962, test:0.438368 | lr:0.000000\n",
            "Epoch[8647/10000] | loss train:0.848703, test:0.533560 | lr:0.000000\n",
            "Epoch[8648/10000] | loss train:1.011226, test:0.205220 | lr:0.000000\n",
            "Epoch[8649/10000] | loss train:0.837314, test:0.450422 | lr:0.000000\n",
            "Epoch[8650/10000] | loss train:1.159339, test:1.003688 | lr:0.000000\n",
            "Epoch[8651/10000] | loss train:1.042885, test:1.415456 | lr:0.000000\n",
            "Epoch[8652/10000] | loss train:2.371964, test:0.249532 | lr:0.000000\n",
            "Epoch[8653/10000] | loss train:1.256194, test:0.889423 | lr:0.000000\n",
            "Epoch[8654/10000] | loss train:0.751293, test:1.977016 | lr:0.000000\n",
            "Epoch[8655/10000] | loss train:1.154898, test:1.225166 | lr:0.000000\n",
            "Epoch[8656/10000] | loss train:0.951018, test:0.098221 | lr:0.000000\n",
            "Epoch[8657/10000] | loss train:2.550873, test:0.532367 | lr:0.000000\n",
            "Epoch[8658/10000] | loss train:0.818445, test:0.635628 | lr:0.000000\n",
            "Epoch[8659/10000] | loss train:1.269785, test:0.697654 | lr:0.000000\n",
            "Epoch[8660/10000] | loss train:0.960623, test:1.048306 | lr:0.000000\n",
            "Epoch[8661/10000] | loss train:0.861294, test:0.803792 | lr:0.000000\n",
            "Epoch[8662/10000] | loss train:1.103418, test:0.547189 | lr:0.000000\n",
            "Epoch[8663/10000] | loss train:1.211884, test:0.492852 | lr:0.000000\n",
            "Epoch[8664/10000] | loss train:1.205432, test:0.737671 | lr:0.000000\n",
            "Epoch[8665/10000] | loss train:1.070052, test:0.688224 | lr:0.000000\n",
            "Epoch[8666/10000] | loss train:2.299740, test:0.245013 | lr:0.000000\n",
            "Epoch[8667/10000] | loss train:2.938059, test:0.625714 | lr:0.000000\n",
            "Epoch[8668/10000] | loss train:0.958027, test:0.790487 | lr:0.000000\n",
            "Epoch[8669/10000] | loss train:1.491365, test:0.153862 | lr:0.000000\n",
            "Epoch[8670/10000] | loss train:1.028532, test:0.381747 | lr:0.000000\n",
            "Epoch[8671/10000] | loss train:1.134648, test:0.952828 | lr:0.000000\n",
            "Epoch[8672/10000] | loss train:1.553558, test:2.172969 | lr:0.000000\n",
            "Epoch[8673/10000] | loss train:0.942162, test:0.635368 | lr:0.000000\n",
            "Epoch[8674/10000] | loss train:1.524693, test:0.152344 | lr:0.000000\n",
            "Epoch[8675/10000] | loss train:1.931650, test:0.207881 | lr:0.000000\n",
            "Epoch[8676/10000] | loss train:1.061404, test:0.350705 | lr:0.000000\n",
            "Epoch[8677/10000] | loss train:0.896736, test:1.161304 | lr:0.000000\n",
            "Epoch[8678/10000] | loss train:1.596651, test:0.377351 | lr:0.000000\n",
            "Epoch[8679/10000] | loss train:1.292430, test:0.648548 | lr:0.000000\n",
            "Epoch[8680/10000] | loss train:0.923582, test:0.739904 | lr:0.000000\n",
            "Epoch[8681/10000] | loss train:1.625922, test:0.199848 | lr:0.000000\n",
            "Epoch[8682/10000] | loss train:2.064441, test:0.527579 | lr:0.000000\n",
            "Epoch[8683/10000] | loss train:0.886207, test:1.970610 | lr:0.000000\n",
            "Epoch[8684/10000] | loss train:1.115231, test:1.220498 | lr:0.000000\n",
            "Epoch[8685/10000] | loss train:3.376946, test:1.008245 | lr:0.000000\n",
            "Epoch[8686/10000] | loss train:1.143464, test:0.199182 | lr:0.000000\n",
            "Epoch[8687/10000] | loss train:2.544415, test:2.136744 | lr:0.000000\n",
            "Epoch[8688/10000] | loss train:1.622843, test:0.140886 | lr:0.000000\n",
            "Epoch[8689/10000] | loss train:0.961141, test:0.516073 | lr:0.000000\n",
            "Epoch[8690/10000] | loss train:1.159440, test:1.391821 | lr:0.000000\n",
            "Epoch[8691/10000] | loss train:1.905481, test:0.259812 | lr:0.000000\n",
            "Epoch[8692/10000] | loss train:1.558166, test:0.149959 | lr:0.000000\n",
            "Epoch[8693/10000] | loss train:1.080450, test:0.475137 | lr:0.000000\n",
            "Epoch[8694/10000] | loss train:1.201742, test:0.192772 | lr:0.000000\n",
            "Epoch[8695/10000] | loss train:1.557401, test:0.256836 | lr:0.000000\n",
            "Epoch[8696/10000] | loss train:0.769487, test:0.101703 | lr:0.000000\n",
            "Epoch[8697/10000] | loss train:1.697988, test:1.196192 | lr:0.000000\n",
            "Epoch[8698/10000] | loss train:0.936358, test:0.490328 | lr:0.000000\n",
            "Epoch[8699/10000] | loss train:0.796873, test:1.034185 | lr:0.000000\n",
            "Epoch[8700/10000] | loss train:1.397115, test:0.202006 | lr:0.000000\n",
            "Epoch[8701/10000] | loss train:1.793955, test:0.355028 | lr:0.000000\n",
            "Epoch[8702/10000] | loss train:0.685702, test:0.436336 | lr:0.000000\n",
            "Epoch[8703/10000] | loss train:0.723964, test:0.168739 | lr:0.000000\n",
            "Epoch[8704/10000] | loss train:1.858134, test:0.324343 | lr:0.000000\n",
            "Epoch[8705/10000] | loss train:1.293464, test:0.537986 | lr:0.000000\n",
            "Epoch[8706/10000] | loss train:0.901957, test:0.211337 | lr:0.000000\n",
            "Epoch[8707/10000] | loss train:1.776559, test:0.869122 | lr:0.000000\n",
            "Epoch[8708/10000] | loss train:1.018313, test:0.439516 | lr:0.000000\n",
            "Epoch[8709/10000] | loss train:1.222116, test:0.954823 | lr:0.000000\n",
            "Epoch[8710/10000] | loss train:1.149524, test:0.488620 | lr:0.000000\n",
            "Epoch[8711/10000] | loss train:1.406455, test:0.743465 | lr:0.000000\n",
            "Epoch[8712/10000] | loss train:0.937267, test:0.681445 | lr:0.000000\n",
            "Epoch[8713/10000] | loss train:0.755581, test:1.164506 | lr:0.000000\n",
            "Epoch[8714/10000] | loss train:0.896942, test:1.199479 | lr:0.000000\n",
            "Epoch[8715/10000] | loss train:1.766686, test:0.451460 | lr:0.000000\n",
            "Epoch[8716/10000] | loss train:0.746029, test:1.593633 | lr:0.000000\n",
            "Epoch[8717/10000] | loss train:1.188218, test:0.624010 | lr:0.000000\n",
            "Epoch[8718/10000] | loss train:1.818854, test:0.656628 | lr:0.000000\n",
            "Epoch[8719/10000] | loss train:1.031550, test:0.244393 | lr:0.000000\n",
            "Epoch[8720/10000] | loss train:1.061198, test:0.113876 | lr:0.000000\n",
            "Epoch[8721/10000] | loss train:0.959871, test:0.284962 | lr:0.000000\n",
            "Epoch[8722/10000] | loss train:1.198350, test:0.646055 | lr:0.000000\n",
            "Epoch[8723/10000] | loss train:1.111769, test:1.311262 | lr:0.000000\n",
            "Epoch[8724/10000] | loss train:1.061101, test:0.149589 | lr:0.000000\n",
            "Epoch[8725/10000] | loss train:1.795922, test:0.656596 | lr:0.000000\n",
            "Epoch[8726/10000] | loss train:1.012451, test:0.141237 | lr:0.000000\n",
            "Epoch[8727/10000] | loss train:1.069154, test:0.383946 | lr:0.000000\n",
            "Epoch[8728/10000] | loss train:0.681210, test:0.244404 | lr:0.000000\n",
            "Epoch[8729/10000] | loss train:1.022949, test:0.426832 | lr:0.000000\n",
            "Epoch[8730/10000] | loss train:1.141109, test:1.347477 | lr:0.000000\n",
            "Epoch[8731/10000] | loss train:0.692407, test:0.921437 | lr:0.000000\n",
            "Epoch[8732/10000] | loss train:1.075410, test:0.497268 | lr:0.000000\n",
            "Epoch[8733/10000] | loss train:2.438109, test:0.966412 | lr:0.000000\n",
            "Epoch[8734/10000] | loss train:1.790770, test:0.085816 | lr:0.000000\n",
            "Epoch[8735/10000] | loss train:0.999304, test:0.368554 | lr:0.000000\n",
            "Epoch[8736/10000] | loss train:1.138084, test:0.275544 | lr:0.000000\n",
            "Epoch[8737/10000] | loss train:1.050781, test:0.363181 | lr:0.000000\n",
            "Epoch[8738/10000] | loss train:1.776309, test:0.209472 | lr:0.000000\n",
            "Epoch[8739/10000] | loss train:2.217647, test:0.256672 | lr:0.000000\n",
            "Epoch[8740/10000] | loss train:0.809888, test:0.957496 | lr:0.000000\n",
            "Epoch[8741/10000] | loss train:1.833614, test:0.442516 | lr:0.000000\n",
            "Epoch[8742/10000] | loss train:1.591587, test:0.301859 | lr:0.000000\n",
            "Epoch[8743/10000] | loss train:1.080911, test:0.847700 | lr:0.000000\n",
            "Epoch[8744/10000] | loss train:1.400962, test:1.046313 | lr:0.000000\n",
            "Epoch[8745/10000] | loss train:1.846394, test:0.766111 | lr:0.000000\n",
            "Epoch[8746/10000] | loss train:1.065450, test:0.951641 | lr:0.000000\n",
            "Epoch[8747/10000] | loss train:1.781080, test:0.387968 | lr:0.000000\n",
            "Epoch[8748/10000] | loss train:0.886155, test:0.900079 | lr:0.000000\n",
            "Epoch[8749/10000] | loss train:1.312150, test:0.308731 | lr:0.000000\n",
            "Epoch[8750/10000] | loss train:1.468582, test:0.697439 | lr:0.000000\n",
            "Epoch[8751/10000] | loss train:0.854729, test:0.942892 | lr:0.000000\n",
            "Epoch[8752/10000] | loss train:0.974898, test:0.644010 | lr:0.000000\n",
            "Epoch[8753/10000] | loss train:0.850327, test:0.565398 | lr:0.000000\n",
            "Epoch[8754/10000] | loss train:1.250959, test:0.630595 | lr:0.000000\n",
            "Epoch[8755/10000] | loss train:1.947592, test:0.411006 | lr:0.000000\n",
            "Epoch[8756/10000] | loss train:1.218218, test:0.809500 | lr:0.000000\n",
            "Epoch[8757/10000] | loss train:0.740832, test:0.937919 | lr:0.000000\n",
            "Epoch[8758/10000] | loss train:1.301041, test:0.595667 | lr:0.000000\n",
            "Epoch[8759/10000] | loss train:1.743435, test:0.166838 | lr:0.000000\n",
            "Epoch[8760/10000] | loss train:1.441870, test:0.673690 | lr:0.000000\n",
            "Epoch[8761/10000] | loss train:1.435349, test:0.656756 | lr:0.000000\n",
            "Epoch[8762/10000] | loss train:1.398274, test:0.236658 | lr:0.000000\n",
            "Epoch[8763/10000] | loss train:0.687037, test:0.436155 | lr:0.000000\n",
            "Epoch[8764/10000] | loss train:1.507106, test:0.318353 | lr:0.000000\n",
            "Epoch[8765/10000] | loss train:0.869196, test:0.639829 | lr:0.000000\n",
            "Epoch[8766/10000] | loss train:1.178159, test:1.010736 | lr:0.000000\n",
            "Epoch[8767/10000] | loss train:1.247624, test:0.362272 | lr:0.000000\n",
            "Epoch[8768/10000] | loss train:1.880189, test:1.726244 | lr:0.000000\n",
            "Epoch[8769/10000] | loss train:1.024145, test:0.461948 | lr:0.000000\n",
            "Epoch[8770/10000] | loss train:1.272182, test:0.788815 | lr:0.000000\n",
            "Epoch[8771/10000] | loss train:1.668737, test:0.647907 | lr:0.000000\n",
            "Epoch[8772/10000] | loss train:0.890750, test:0.515180 | lr:0.000000\n",
            "Epoch[8773/10000] | loss train:1.059903, test:1.041082 | lr:0.000000\n",
            "Epoch[8774/10000] | loss train:0.712005, test:0.927454 | lr:0.000000\n",
            "Epoch[8775/10000] | loss train:1.223794, test:0.194468 | lr:0.000000\n",
            "Epoch[8776/10000] | loss train:2.548185, test:0.554908 | lr:0.000000\n",
            "Epoch[8777/10000] | loss train:1.235612, test:0.384578 | lr:0.000000\n",
            "Epoch[8778/10000] | loss train:1.928330, test:0.482168 | lr:0.000000\n",
            "Epoch[8779/10000] | loss train:0.877162, test:0.369511 | lr:0.000000\n",
            "Epoch[8780/10000] | loss train:1.385004, test:0.226064 | lr:0.000000\n",
            "Epoch[8781/10000] | loss train:0.777520, test:0.102448 | lr:0.000000\n",
            "Epoch[8782/10000] | loss train:1.282864, test:1.760799 | lr:0.000000\n",
            "Epoch[8783/10000] | loss train:0.989557, test:0.442173 | lr:0.000000\n",
            "Epoch[8784/10000] | loss train:1.018322, test:0.255323 | lr:0.000000\n",
            "Epoch[8785/10000] | loss train:0.993274, test:0.243715 | lr:0.000000\n",
            "Epoch[8786/10000] | loss train:1.007887, test:1.168561 | lr:0.000000\n",
            "Epoch[8787/10000] | loss train:0.801084, test:0.392406 | lr:0.000000\n",
            "Epoch[8788/10000] | loss train:2.729709, test:0.246472 | lr:0.000000\n",
            "Epoch[8789/10000] | loss train:1.259684, test:0.997885 | lr:0.000000\n",
            "Epoch[8790/10000] | loss train:0.984462, test:0.819730 | lr:0.000000\n",
            "Epoch[8791/10000] | loss train:0.985162, test:0.703676 | lr:0.000000\n",
            "Epoch[8792/10000] | loss train:1.236415, test:0.194972 | lr:0.000000\n",
            "Epoch[8793/10000] | loss train:1.290542, test:1.111784 | lr:0.000000\n",
            "Epoch[8794/10000] | loss train:0.752473, test:2.025144 | lr:0.000000\n",
            "Epoch[8795/10000] | loss train:1.445821, test:1.255633 | lr:0.000000\n",
            "Epoch[8796/10000] | loss train:1.199449, test:0.529256 | lr:0.000000\n",
            "Epoch[8797/10000] | loss train:1.119437, test:0.283643 | lr:0.000000\n",
            "Epoch[8798/10000] | loss train:0.940224, test:0.418468 | lr:0.000000\n",
            "Epoch[8799/10000] | loss train:2.721800, test:0.352341 | lr:0.000000\n",
            "Epoch[8800/10000] | loss train:1.069652, test:0.376677 | lr:0.000000\n",
            "Epoch[8801/10000] | loss train:2.183989, test:0.810749 | lr:0.000000\n",
            "Epoch[8802/10000] | loss train:2.231802, test:0.716348 | lr:0.000000\n",
            "Epoch[8803/10000] | loss train:1.165814, test:0.352281 | lr:0.000000\n",
            "Epoch[8804/10000] | loss train:0.790288, test:0.164646 | lr:0.000000\n",
            "Epoch[8805/10000] | loss train:1.232912, test:0.216576 | lr:0.000000\n",
            "Epoch[8806/10000] | loss train:1.018393, test:0.485590 | lr:0.000000\n",
            "Epoch[8807/10000] | loss train:1.626945, test:0.711601 | lr:0.000000\n",
            "Epoch[8808/10000] | loss train:1.098919, test:0.190556 | lr:0.000000\n",
            "Epoch[8809/10000] | loss train:1.173221, test:0.905709 | lr:0.000000\n",
            "Epoch[8810/10000] | loss train:1.240504, test:1.507588 | lr:0.000000\n",
            "Epoch[8811/10000] | loss train:0.839103, test:0.728156 | lr:0.000000\n",
            "Epoch[8812/10000] | loss train:2.001929, test:0.533061 | lr:0.000000\n",
            "Epoch[8813/10000] | loss train:1.225626, test:0.366242 | lr:0.000000\n",
            "Epoch[8814/10000] | loss train:0.658166, test:1.570640 | lr:0.000000\n",
            "Epoch[8815/10000] | loss train:0.795139, test:0.470275 | lr:0.000000\n",
            "Epoch[8816/10000] | loss train:0.817184, test:1.533424 | lr:0.000000\n",
            "Epoch[8817/10000] | loss train:1.012677, test:0.433655 | lr:0.000000\n",
            "Epoch[8818/10000] | loss train:0.874155, test:0.358364 | lr:0.000000\n",
            "Epoch[8819/10000] | loss train:0.926589, test:0.323213 | lr:0.000000\n",
            "Epoch[8820/10000] | loss train:0.983760, test:0.460264 | lr:0.000000\n",
            "Epoch[8821/10000] | loss train:0.791004, test:0.282947 | lr:0.000000\n",
            "Epoch[8822/10000] | loss train:1.157522, test:0.143499 | lr:0.000000\n",
            "Epoch[8823/10000] | loss train:1.629803, test:0.475689 | lr:0.000000\n",
            "Epoch[8824/10000] | loss train:1.446259, test:0.684940 | lr:0.000000\n",
            "Epoch[8825/10000] | loss train:1.675953, test:0.057324 | lr:0.000000\n",
            "Epoch[8826/10000] | loss train:1.397462, test:0.535706 | lr:0.000000\n",
            "Epoch[8827/10000] | loss train:1.390240, test:0.550521 | lr:0.000000\n",
            "Epoch[8828/10000] | loss train:0.977429, test:1.524460 | lr:0.000000\n",
            "Epoch[8829/10000] | loss train:1.186782, test:1.238991 | lr:0.000000\n",
            "Epoch[8830/10000] | loss train:1.098920, test:0.929203 | lr:0.000000\n",
            "Epoch[8831/10000] | loss train:1.194095, test:0.561678 | lr:0.000000\n",
            "Epoch[8832/10000] | loss train:0.822458, test:1.260238 | lr:0.000000\n",
            "Epoch[8833/10000] | loss train:0.773662, test:0.087265 | lr:0.000000\n",
            "Epoch[8834/10000] | loss train:0.974546, test:0.189595 | lr:0.000000\n",
            "Epoch[8835/10000] | loss train:1.428218, test:0.161917 | lr:0.000000\n",
            "Epoch[8836/10000] | loss train:1.814506, test:0.272555 | lr:0.000000\n",
            "Epoch[8837/10000] | loss train:1.229158, test:0.645974 | lr:0.000000\n",
            "Epoch[8838/10000] | loss train:0.988172, test:1.220320 | lr:0.000000\n",
            "Epoch[8839/10000] | loss train:1.824004, test:0.615346 | lr:0.000000\n",
            "Epoch[8840/10000] | loss train:1.085616, test:0.085410 | lr:0.000000\n",
            "Epoch[8841/10000] | loss train:0.999822, test:0.219094 | lr:0.000000\n",
            "Epoch[8842/10000] | loss train:0.882411, test:0.290443 | lr:0.000000\n",
            "Epoch[8843/10000] | loss train:0.833007, test:0.211895 | lr:0.000000\n",
            "Epoch[8844/10000] | loss train:1.706520, test:1.091558 | lr:0.000000\n",
            "Epoch[8845/10000] | loss train:1.376919, test:0.519416 | lr:0.000000\n",
            "Epoch[8846/10000] | loss train:2.070534, test:0.326706 | lr:0.000000\n",
            "Epoch[8847/10000] | loss train:1.017506, test:0.265097 | lr:0.000000\n",
            "Epoch[8848/10000] | loss train:0.804972, test:1.095081 | lr:0.000000\n",
            "Epoch[8849/10000] | loss train:1.316476, test:0.787607 | lr:0.000000\n",
            "Epoch[8850/10000] | loss train:0.829241, test:0.429431 | lr:0.000000\n",
            "Epoch[8851/10000] | loss train:0.617148, test:0.839467 | lr:0.000000\n",
            "Epoch[8852/10000] | loss train:1.564742, test:0.489886 | lr:0.000000\n",
            "Epoch[8853/10000] | loss train:1.555830, test:1.244659 | lr:0.000000\n",
            "Epoch[8854/10000] | loss train:0.889027, test:0.528442 | lr:0.000000\n",
            "Epoch[8855/10000] | loss train:1.057623, test:0.957745 | lr:0.000000\n",
            "Epoch[8856/10000] | loss train:2.211246, test:1.148711 | lr:0.000000\n",
            "Epoch[8857/10000] | loss train:0.974583, test:1.224174 | lr:0.000000\n",
            "Epoch[8858/10000] | loss train:1.034553, test:0.352386 | lr:0.000000\n",
            "Epoch[8859/10000] | loss train:1.277332, test:0.128547 | lr:0.000000\n",
            "Epoch[8860/10000] | loss train:1.477614, test:0.851253 | lr:0.000000\n",
            "Epoch[8861/10000] | loss train:1.444541, test:0.297375 | lr:0.000000\n",
            "Epoch[8862/10000] | loss train:1.084510, test:1.317043 | lr:0.000000\n",
            "Epoch[8863/10000] | loss train:0.734163, test:0.110330 | lr:0.000000\n",
            "Epoch[8864/10000] | loss train:1.048045, test:0.538862 | lr:0.000000\n",
            "Epoch[8865/10000] | loss train:0.879283, test:0.254558 | lr:0.000000\n",
            "Epoch[8866/10000] | loss train:1.515174, test:0.263287 | lr:0.000000\n",
            "Epoch[8867/10000] | loss train:1.006781, test:0.657189 | lr:0.000000\n",
            "Epoch[8868/10000] | loss train:1.270961, test:0.211330 | lr:0.000000\n",
            "Epoch[8869/10000] | loss train:0.929027, test:0.469283 | lr:0.000000\n",
            "Epoch[8870/10000] | loss train:1.366308, test:0.291646 | lr:0.000000\n",
            "Epoch[8871/10000] | loss train:1.080741, test:0.668751 | lr:0.000000\n",
            "Epoch[8872/10000] | loss train:1.841883, test:0.593130 | lr:0.000000\n",
            "Epoch[8873/10000] | loss train:1.048469, test:0.165294 | lr:0.000000\n",
            "Epoch[8874/10000] | loss train:1.687939, test:0.668921 | lr:0.000000\n",
            "Epoch[8875/10000] | loss train:0.965223, test:0.665706 | lr:0.000000\n",
            "Epoch[8876/10000] | loss train:0.752309, test:0.376095 | lr:0.000000\n",
            "Epoch[8877/10000] | loss train:0.703606, test:0.400402 | lr:0.000000\n",
            "Epoch[8878/10000] | loss train:0.908621, test:0.280167 | lr:0.000000\n",
            "Epoch[8879/10000] | loss train:1.691178, test:1.490519 | lr:0.000000\n",
            "Epoch[8880/10000] | loss train:1.528976, test:0.931886 | lr:0.000000\n",
            "Epoch[8881/10000] | loss train:1.853901, test:0.512121 | lr:0.000000\n",
            "Epoch[8882/10000] | loss train:1.675277, test:0.478451 | lr:0.000000\n",
            "Epoch[8883/10000] | loss train:1.438249, test:0.857884 | lr:0.000000\n",
            "Epoch[8884/10000] | loss train:0.980291, test:0.685768 | lr:0.000000\n",
            "Epoch[8885/10000] | loss train:0.954642, test:0.181429 | lr:0.000000\n",
            "Epoch[8886/10000] | loss train:0.576824, test:0.849682 | lr:0.000000\n",
            "Epoch[8887/10000] | loss train:1.316239, test:0.175814 | lr:0.000000\n",
            "Epoch[8888/10000] | loss train:1.305744, test:0.816057 | lr:0.000000\n",
            "Epoch[8889/10000] | loss train:1.137078, test:0.167389 | lr:0.000000\n",
            "Epoch[8890/10000] | loss train:0.775262, test:0.804117 | lr:0.000000\n",
            "Epoch[8891/10000] | loss train:1.756806, test:0.164491 | lr:0.000000\n",
            "Epoch[8892/10000] | loss train:1.252453, test:0.432747 | lr:0.000000\n",
            "Epoch[8893/10000] | loss train:1.212346, test:0.801227 | lr:0.000000\n",
            "Epoch[8894/10000] | loss train:2.752249, test:0.380572 | lr:0.000000\n",
            "Epoch[8895/10000] | loss train:0.896457, test:1.168186 | lr:0.000000\n",
            "Epoch[8896/10000] | loss train:1.166025, test:0.548635 | lr:0.000000\n",
            "Epoch[8897/10000] | loss train:0.720072, test:0.531584 | lr:0.000000\n",
            "Epoch[8898/10000] | loss train:1.925336, test:0.277832 | lr:0.000000\n",
            "Epoch[8899/10000] | loss train:1.502449, test:0.193888 | lr:0.000000\n",
            "Epoch[8900/10000] | loss train:0.790614, test:0.818328 | lr:0.000000\n",
            "Epoch[8901/10000] | loss train:1.900510, test:0.166240 | lr:0.000000\n",
            "Epoch[8902/10000] | loss train:1.099521, test:0.796189 | lr:0.000000\n",
            "Epoch[8903/10000] | loss train:1.088374, test:1.587715 | lr:0.000000\n",
            "Epoch[8904/10000] | loss train:1.199834, test:0.457305 | lr:0.000000\n",
            "Epoch[8905/10000] | loss train:0.899439, test:0.365037 | lr:0.000000\n",
            "Epoch[8906/10000] | loss train:1.073379, test:0.401797 | lr:0.000000\n",
            "Epoch[8907/10000] | loss train:0.782746, test:0.235302 | lr:0.000000\n",
            "Epoch[8908/10000] | loss train:1.116149, test:0.697256 | lr:0.000000\n",
            "Epoch[8909/10000] | loss train:1.295504, test:0.197063 | lr:0.000000\n",
            "Epoch[8910/10000] | loss train:0.935602, test:0.241327 | lr:0.000000\n",
            "Epoch[8911/10000] | loss train:1.713428, test:0.343303 | lr:0.000000\n",
            "Epoch[8912/10000] | loss train:1.081114, test:0.318745 | lr:0.000000\n",
            "Epoch[8913/10000] | loss train:1.107347, test:0.340305 | lr:0.000000\n",
            "Epoch[8914/10000] | loss train:1.431534, test:0.779538 | lr:0.000000\n",
            "Epoch[8915/10000] | loss train:1.693752, test:1.400610 | lr:0.000000\n",
            "Epoch[8916/10000] | loss train:2.251334, test:0.573586 | lr:0.000000\n",
            "Epoch[8917/10000] | loss train:0.907179, test:0.484838 | lr:0.000000\n",
            "Epoch[8918/10000] | loss train:1.067110, test:0.662552 | lr:0.000000\n",
            "Epoch[8919/10000] | loss train:1.093149, test:0.269817 | lr:0.000000\n",
            "Epoch[8920/10000] | loss train:3.486911, test:0.425701 | lr:0.000000\n",
            "Epoch[8921/10000] | loss train:1.367681, test:1.044454 | lr:0.000000\n",
            "Epoch[8922/10000] | loss train:1.305277, test:1.029799 | lr:0.000000\n",
            "Epoch[8923/10000] | loss train:1.317727, test:0.658018 | lr:0.000000\n",
            "Epoch[8924/10000] | loss train:1.547165, test:0.312582 | lr:0.000000\n",
            "Epoch[8925/10000] | loss train:1.123329, test:1.218143 | lr:0.000000\n",
            "Epoch[8926/10000] | loss train:0.735838, test:0.692484 | lr:0.000000\n",
            "Epoch[8927/10000] | loss train:0.785733, test:1.646018 | lr:0.000000\n",
            "Epoch[8928/10000] | loss train:1.704730, test:0.382433 | lr:0.000000\n",
            "Epoch[8929/10000] | loss train:1.065906, test:1.621778 | lr:0.000000\n",
            "Epoch[8930/10000] | loss train:1.436471, test:0.933973 | lr:0.000000\n",
            "Epoch[8931/10000] | loss train:1.135178, test:0.478846 | lr:0.000000\n",
            "Epoch[8932/10000] | loss train:1.677854, test:1.092821 | lr:0.000000\n",
            "Epoch[8933/10000] | loss train:2.063705, test:1.495798 | lr:0.000000\n",
            "Epoch[8934/10000] | loss train:1.210334, test:0.266474 | lr:0.000000\n",
            "Epoch[8935/10000] | loss train:2.693855, test:0.780043 | lr:0.000000\n",
            "Epoch[8936/10000] | loss train:0.642783, test:0.234341 | lr:0.000000\n",
            "Epoch[8937/10000] | loss train:1.298331, test:0.347873 | lr:0.000000\n",
            "Epoch[8938/10000] | loss train:0.799927, test:0.252218 | lr:0.000000\n",
            "Epoch[8939/10000] | loss train:1.515848, test:0.574395 | lr:0.000000\n",
            "Epoch[8940/10000] | loss train:1.904340, test:0.625188 | lr:0.000000\n",
            "Epoch[8941/10000] | loss train:1.343103, test:0.318315 | lr:0.000000\n",
            "Epoch[8942/10000] | loss train:0.798756, test:1.556706 | lr:0.000000\n",
            "Epoch[8943/10000] | loss train:1.091117, test:0.938012 | lr:0.000000\n",
            "Epoch[8944/10000] | loss train:1.193164, test:0.581364 | lr:0.000000\n",
            "Epoch[8945/10000] | loss train:1.733772, test:0.118993 | lr:0.000000\n",
            "Epoch[8946/10000] | loss train:0.907838, test:0.528853 | lr:0.000000\n",
            "Epoch[8947/10000] | loss train:1.811922, test:0.557169 | lr:0.000000\n",
            "Epoch[8948/10000] | loss train:0.963613, test:0.621897 | lr:0.000000\n",
            "Epoch[8949/10000] | loss train:0.769055, test:0.601039 | lr:0.000000\n",
            "Epoch[8950/10000] | loss train:1.290190, test:0.850746 | lr:0.000000\n",
            "Epoch[8951/10000] | loss train:0.823394, test:0.293375 | lr:0.000000\n",
            "Epoch[8952/10000] | loss train:0.851071, test:0.255329 | lr:0.000000\n",
            "Epoch[8953/10000] | loss train:1.145371, test:0.650144 | lr:0.000000\n",
            "Epoch[8954/10000] | loss train:1.931766, test:0.942452 | lr:0.000000\n",
            "Epoch[8955/10000] | loss train:2.383378, test:0.282822 | lr:0.000000\n",
            "Epoch[8956/10000] | loss train:1.803864, test:1.594370 | lr:0.000000\n",
            "Epoch[8957/10000] | loss train:1.123113, test:0.467106 | lr:0.000000\n",
            "Epoch[8958/10000] | loss train:0.741533, test:0.152970 | lr:0.000000\n",
            "Epoch[8959/10000] | loss train:1.206866, test:0.866279 | lr:0.000000\n",
            "Epoch[8960/10000] | loss train:2.029969, test:1.248238 | lr:0.000000\n",
            "Epoch[8961/10000] | loss train:0.909085, test:0.192498 | lr:0.000000\n",
            "Epoch[8962/10000] | loss train:1.081455, test:0.507642 | lr:0.000000\n",
            "Epoch[8963/10000] | loss train:1.375468, test:0.758407 | lr:0.000000\n",
            "Epoch[8964/10000] | loss train:0.998600, test:0.485791 | lr:0.000000\n",
            "Epoch[8965/10000] | loss train:1.447782, test:0.900750 | lr:0.000000\n",
            "Epoch[8966/10000] | loss train:0.978368, test:0.375948 | lr:0.000000\n",
            "Epoch[8967/10000] | loss train:1.293543, test:0.303414 | lr:0.000000\n",
            "Epoch[8968/10000] | loss train:0.984162, test:1.320208 | lr:0.000000\n",
            "Epoch[8969/10000] | loss train:1.322717, test:0.108110 | lr:0.000000\n",
            "Epoch[8970/10000] | loss train:1.041521, test:0.558312 | lr:0.000000\n",
            "Epoch[8971/10000] | loss train:1.570724, test:0.395581 | lr:0.000000\n",
            "Epoch[8972/10000] | loss train:1.218715, test:0.258985 | lr:0.000000\n",
            "Epoch[8973/10000] | loss train:1.481109, test:0.291480 | lr:0.000000\n",
            "Epoch[8974/10000] | loss train:1.051287, test:0.452126 | lr:0.000000\n",
            "Epoch[8975/10000] | loss train:0.907749, test:0.481695 | lr:0.000000\n",
            "Epoch[8976/10000] | loss train:1.328821, test:0.987781 | lr:0.000000\n",
            "Epoch[8977/10000] | loss train:1.056232, test:0.581849 | lr:0.000000\n",
            "Epoch[8978/10000] | loss train:0.901240, test:0.774450 | lr:0.000000\n",
            "Epoch[8979/10000] | loss train:1.174982, test:0.338057 | lr:0.000000\n",
            "Epoch[8980/10000] | loss train:1.075931, test:0.536256 | lr:0.000000\n",
            "Epoch[8981/10000] | loss train:0.815158, test:0.334941 | lr:0.000000\n",
            "Epoch[8982/10000] | loss train:0.800456, test:0.289780 | lr:0.000000\n",
            "Epoch[8983/10000] | loss train:1.245284, test:0.294345 | lr:0.000000\n",
            "Epoch[8984/10000] | loss train:1.171362, test:0.670425 | lr:0.000000\n",
            "Epoch[8985/10000] | loss train:1.659478, test:1.007024 | lr:0.000000\n",
            "Epoch[8986/10000] | loss train:1.198194, test:0.588010 | lr:0.000000\n",
            "Epoch[8987/10000] | loss train:0.776174, test:1.371931 | lr:0.000000\n",
            "Epoch[8988/10000] | loss train:1.028247, test:0.967961 | lr:0.000000\n",
            "Epoch[8989/10000] | loss train:1.181879, test:0.301247 | lr:0.000000\n",
            "Epoch[8990/10000] | loss train:0.841896, test:1.421300 | lr:0.000000\n",
            "Epoch[8991/10000] | loss train:1.711540, test:0.313180 | lr:0.000000\n",
            "Epoch[8992/10000] | loss train:0.648558, test:0.275121 | lr:0.000000\n",
            "Epoch[8993/10000] | loss train:0.832757, test:0.248835 | lr:0.000000\n",
            "Epoch[8994/10000] | loss train:0.808432, test:0.384662 | lr:0.000000\n",
            "Epoch[8995/10000] | loss train:1.408363, test:0.449753 | lr:0.000000\n",
            "Epoch[8996/10000] | loss train:1.047556, test:0.521375 | lr:0.000000\n",
            "Epoch[8997/10000] | loss train:1.408041, test:0.651697 | lr:0.000000\n",
            "Epoch[8998/10000] | loss train:1.111234, test:0.314759 | lr:0.000000\n",
            "Epoch[8999/10000] | loss train:1.031287, test:0.577410 | lr:0.000000\n",
            "Epoch[9000/10000] | loss train:0.720133, test:0.563075 | lr:0.000000\n",
            "Epoch[9001/10000] | loss train:1.113875, test:0.395461 | lr:0.000000\n",
            "Epoch[9002/10000] | loss train:1.809341, test:1.402880 | lr:0.000000\n",
            "Epoch[9003/10000] | loss train:1.027837, test:0.548884 | lr:0.000000\n",
            "Epoch[9004/10000] | loss train:1.137887, test:0.410024 | lr:0.000000\n",
            "Epoch[9005/10000] | loss train:1.797091, test:0.472344 | lr:0.000000\n",
            "Epoch[9006/10000] | loss train:1.593625, test:1.006996 | lr:0.000000\n",
            "Epoch[9007/10000] | loss train:1.513106, test:0.992085 | lr:0.000000\n",
            "Epoch[9008/10000] | loss train:0.815782, test:0.192383 | lr:0.000000\n",
            "Epoch[9009/10000] | loss train:0.833230, test:0.166150 | lr:0.000000\n",
            "Epoch[9010/10000] | loss train:1.014599, test:0.447318 | lr:0.000000\n",
            "Epoch[9011/10000] | loss train:0.855142, test:1.846568 | lr:0.000000\n",
            "Epoch[9012/10000] | loss train:0.857437, test:0.766285 | lr:0.000000\n",
            "Epoch[9013/10000] | loss train:1.557476, test:0.117853 | lr:0.000000\n",
            "Epoch[9014/10000] | loss train:1.030622, test:0.404228 | lr:0.000000\n",
            "Epoch[9015/10000] | loss train:1.471199, test:0.293183 | lr:0.000000\n",
            "Epoch[9016/10000] | loss train:1.359196, test:1.308175 | lr:0.000000\n",
            "Epoch[9017/10000] | loss train:1.128785, test:0.209209 | lr:0.000000\n",
            "Epoch[9018/10000] | loss train:2.492099, test:0.889934 | lr:0.000000\n",
            "Epoch[9019/10000] | loss train:0.952419, test:1.227647 | lr:0.000000\n",
            "Epoch[9020/10000] | loss train:1.538878, test:0.192772 | lr:0.000000\n",
            "Epoch[9021/10000] | loss train:1.212321, test:0.223806 | lr:0.000000\n",
            "Epoch[9022/10000] | loss train:1.034449, test:0.567728 | lr:0.000000\n",
            "Epoch[9023/10000] | loss train:0.752225, test:0.495966 | lr:0.000000\n",
            "Epoch[9024/10000] | loss train:1.524507, test:0.528309 | lr:0.000000\n",
            "Epoch[9025/10000] | loss train:1.435011, test:0.287730 | lr:0.000000\n",
            "Epoch[9026/10000] | loss train:1.006698, test:0.197865 | lr:0.000000\n",
            "Epoch[9027/10000] | loss train:2.540366, test:1.696711 | lr:0.000000\n",
            "Epoch[9028/10000] | loss train:1.099385, test:0.784065 | lr:0.000000\n",
            "Epoch[9029/10000] | loss train:0.966853, test:1.850815 | lr:0.000000\n",
            "Epoch[9030/10000] | loss train:0.819836, test:0.260288 | lr:0.000000\n",
            "Epoch[9031/10000] | loss train:0.933857, test:0.369780 | lr:0.000000\n",
            "Epoch[9032/10000] | loss train:1.000164, test:0.323078 | lr:0.000000\n",
            "Epoch[9033/10000] | loss train:1.322063, test:0.313115 | lr:0.000000\n",
            "Epoch[9034/10000] | loss train:0.808499, test:0.124217 | lr:0.000000\n",
            "Epoch[9035/10000] | loss train:1.259533, test:0.430783 | lr:0.000000\n",
            "Epoch[9036/10000] | loss train:1.375544, test:0.958986 | lr:0.000000\n",
            "Epoch[9037/10000] | loss train:1.059978, test:0.790933 | lr:0.000000\n",
            "Epoch[9038/10000] | loss train:1.566176, test:0.498386 | lr:0.000000\n",
            "Epoch[9039/10000] | loss train:2.102809, test:0.644565 | lr:0.000000\n",
            "Epoch[9040/10000] | loss train:1.889105, test:0.827109 | lr:0.000000\n",
            "Epoch[9041/10000] | loss train:2.037987, test:0.479435 | lr:0.000000\n",
            "Epoch[9042/10000] | loss train:0.950055, test:0.941550 | lr:0.000000\n",
            "Epoch[9043/10000] | loss train:1.298577, test:0.359492 | lr:0.000000\n",
            "Epoch[9044/10000] | loss train:1.167703, test:1.195888 | lr:0.000000\n",
            "Epoch[9045/10000] | loss train:0.871583, test:0.223770 | lr:0.000000\n",
            "Epoch[9046/10000] | loss train:1.269120, test:0.117678 | lr:0.000000\n",
            "Epoch[9047/10000] | loss train:1.384788, test:1.093451 | lr:0.000000\n",
            "Epoch[9048/10000] | loss train:2.365958, test:0.462057 | lr:0.000000\n",
            "Epoch[9049/10000] | loss train:0.801255, test:0.433355 | lr:0.000000\n",
            "Epoch[9050/10000] | loss train:1.242717, test:1.295999 | lr:0.000000\n",
            "Epoch[9051/10000] | loss train:1.105939, test:1.193055 | lr:0.000000\n",
            "Epoch[9052/10000] | loss train:0.700632, test:0.373992 | lr:0.000000\n",
            "Epoch[9053/10000] | loss train:1.926045, test:0.355424 | lr:0.000000\n",
            "Epoch[9054/10000] | loss train:0.854661, test:0.581479 | lr:0.000000\n",
            "Epoch[9055/10000] | loss train:1.581759, test:0.731263 | lr:0.000000\n",
            "Epoch[9056/10000] | loss train:1.576870, test:0.112307 | lr:0.000000\n",
            "Epoch[9057/10000] | loss train:0.880139, test:1.393250 | lr:0.000000\n",
            "Epoch[9058/10000] | loss train:0.875303, test:0.412226 | lr:0.000000\n",
            "Epoch[9059/10000] | loss train:1.315152, test:0.623857 | lr:0.000000\n",
            "Epoch[9060/10000] | loss train:1.352742, test:0.553650 | lr:0.000000\n",
            "Epoch[9061/10000] | loss train:1.547667, test:0.187931 | lr:0.000000\n",
            "Epoch[9062/10000] | loss train:1.436119, test:0.358238 | lr:0.000000\n",
            "Epoch[9063/10000] | loss train:1.608811, test:0.387983 | lr:0.000000\n",
            "Epoch[9064/10000] | loss train:0.805947, test:0.480479 | lr:0.000000\n",
            "Epoch[9065/10000] | loss train:1.045823, test:1.036072 | lr:0.000000\n",
            "Epoch[9066/10000] | loss train:2.687416, test:0.753605 | lr:0.000000\n",
            "Epoch[9067/10000] | loss train:1.157126, test:0.702204 | lr:0.000000\n",
            "Epoch[9068/10000] | loss train:0.746665, test:1.170458 | lr:0.000000\n",
            "Epoch[9069/10000] | loss train:1.541229, test:0.804051 | lr:0.000000\n",
            "Epoch[9070/10000] | loss train:0.866074, test:0.460820 | lr:0.000000\n",
            "Epoch[9071/10000] | loss train:1.320954, test:0.403424 | lr:0.000000\n",
            "Epoch[9072/10000] | loss train:2.306166, test:0.212757 | lr:0.000000\n",
            "Epoch[9073/10000] | loss train:1.755080, test:1.152807 | lr:0.000000\n",
            "Epoch[9074/10000] | loss train:1.017176, test:0.395956 | lr:0.000000\n",
            "Epoch[9075/10000] | loss train:1.061555, test:0.519970 | lr:0.000000\n",
            "Epoch[9076/10000] | loss train:1.794997, test:0.187654 | lr:0.000000\n",
            "Epoch[9077/10000] | loss train:0.900283, test:0.334152 | lr:0.000000\n",
            "Epoch[9078/10000] | loss train:1.334887, test:0.238092 | lr:0.000000\n",
            "Epoch[9079/10000] | loss train:0.981462, test:0.575506 | lr:0.000000\n",
            "Epoch[9080/10000] | loss train:0.897442, test:0.353097 | lr:0.000000\n",
            "Epoch[9081/10000] | loss train:1.264187, test:1.336049 | lr:0.000000\n",
            "Epoch[9082/10000] | loss train:0.849717, test:0.813032 | lr:0.000000\n",
            "Epoch[9083/10000] | loss train:1.568053, test:0.519694 | lr:0.000000\n",
            "Epoch[9084/10000] | loss train:1.579948, test:0.329887 | lr:0.000000\n",
            "Epoch[9085/10000] | loss train:1.287424, test:0.053704 | lr:0.000000\n",
            "Epoch[9086/10000] | loss train:0.921719, test:0.866916 | lr:0.000000\n",
            "Epoch[9087/10000] | loss train:1.218198, test:1.430132 | lr:0.000000\n",
            "Epoch[9088/10000] | loss train:2.118910, test:0.421339 | lr:0.000000\n",
            "Epoch[9089/10000] | loss train:1.231244, test:0.323116 | lr:0.000000\n",
            "Epoch[9090/10000] | loss train:1.179179, test:0.166976 | lr:0.000000\n",
            "Epoch[9091/10000] | loss train:1.811480, test:1.094937 | lr:0.000000\n",
            "Epoch[9092/10000] | loss train:1.003995, test:0.299479 | lr:0.000000\n",
            "Epoch[9093/10000] | loss train:1.397196, test:0.618815 | lr:0.000000\n",
            "Epoch[9094/10000] | loss train:2.113927, test:1.052528 | lr:0.000000\n",
            "Epoch[9095/10000] | loss train:0.999408, test:0.205676 | lr:0.000000\n",
            "Epoch[9096/10000] | loss train:1.125130, test:0.851925 | lr:0.000000\n",
            "Epoch[9097/10000] | loss train:1.242244, test:0.513623 | lr:0.000000\n",
            "Epoch[9098/10000] | loss train:2.016209, test:0.573321 | lr:0.000000\n",
            "Epoch[9099/10000] | loss train:0.830041, test:0.564888 | lr:0.000000\n",
            "Epoch[9100/10000] | loss train:0.919515, test:0.926492 | lr:0.000000\n",
            "Epoch[9101/10000] | loss train:0.973084, test:0.866363 | lr:0.000000\n",
            "Epoch[9102/10000] | loss train:1.680232, test:0.320322 | lr:0.000000\n",
            "Epoch[9103/10000] | loss train:0.803775, test:0.640414 | lr:0.000000\n",
            "Epoch[9104/10000] | loss train:1.372788, test:0.915126 | lr:0.000000\n",
            "Epoch[9105/10000] | loss train:1.954195, test:0.517686 | lr:0.000000\n",
            "Epoch[9106/10000] | loss train:0.949805, test:1.005251 | lr:0.000000\n",
            "Epoch[9107/10000] | loss train:0.948889, test:1.094954 | lr:0.000000\n",
            "Epoch[9108/10000] | loss train:1.872697, test:1.340485 | lr:0.000000\n",
            "Epoch[9109/10000] | loss train:0.958553, test:0.652471 | lr:0.000000\n",
            "Epoch[9110/10000] | loss train:1.091616, test:0.752026 | lr:0.000000\n",
            "Epoch[9111/10000] | loss train:1.303135, test:0.269090 | lr:0.000000\n",
            "Epoch[9112/10000] | loss train:1.744385, test:0.319224 | lr:0.000000\n",
            "Epoch[9113/10000] | loss train:1.011202, test:0.337463 | lr:0.000000\n",
            "Epoch[9114/10000] | loss train:1.334571, test:0.175939 | lr:0.000000\n",
            "Epoch[9115/10000] | loss train:0.846798, test:0.454098 | lr:0.000000\n",
            "Epoch[9116/10000] | loss train:1.310944, test:0.322493 | lr:0.000000\n",
            "Epoch[9117/10000] | loss train:1.608973, test:1.313294 | lr:0.000000\n",
            "Epoch[9118/10000] | loss train:1.534619, test:0.689807 | lr:0.000000\n",
            "Epoch[9119/10000] | loss train:1.832575, test:0.394065 | lr:0.000000\n",
            "Epoch[9120/10000] | loss train:1.792372, test:0.519285 | lr:0.000000\n",
            "Epoch[9121/10000] | loss train:2.198984, test:0.676247 | lr:0.000000\n",
            "Epoch[9122/10000] | loss train:0.765732, test:0.139391 | lr:0.000000\n",
            "Epoch[9123/10000] | loss train:0.848935, test:0.064361 | lr:0.000000\n",
            "Epoch[9124/10000] | loss train:1.405591, test:0.455638 | lr:0.000000\n",
            "Epoch[9125/10000] | loss train:1.347080, test:0.340430 | lr:0.000000\n",
            "Epoch[9126/10000] | loss train:1.574324, test:0.946842 | lr:0.000000\n",
            "Epoch[9127/10000] | loss train:1.439382, test:0.834783 | lr:0.000000\n",
            "Epoch[9128/10000] | loss train:0.784300, test:1.351077 | lr:0.000000\n",
            "Epoch[9129/10000] | loss train:2.190225, test:0.547749 | lr:0.000000\n",
            "Epoch[9130/10000] | loss train:1.218560, test:1.467393 | lr:0.000000\n",
            "Epoch[9131/10000] | loss train:2.378424, test:1.448126 | lr:0.000000\n",
            "Epoch[9132/10000] | loss train:1.627493, test:0.482411 | lr:0.000000\n",
            "Epoch[9133/10000] | loss train:2.772644, test:0.346067 | lr:0.000000\n",
            "Epoch[9134/10000] | loss train:1.126585, test:0.384435 | lr:0.000000\n",
            "Epoch[9135/10000] | loss train:1.466043, test:1.595489 | lr:0.000000\n",
            "Epoch[9136/10000] | loss train:1.325009, test:0.830231 | lr:0.000000\n",
            "Epoch[9137/10000] | loss train:2.208702, test:0.597134 | lr:0.000000\n",
            "Epoch[9138/10000] | loss train:1.184259, test:0.494620 | lr:0.000000\n",
            "Epoch[9139/10000] | loss train:1.384175, test:0.518082 | lr:0.000000\n",
            "Epoch[9140/10000] | loss train:0.975264, test:1.637958 | lr:0.000000\n",
            "Epoch[9141/10000] | loss train:1.238050, test:0.245944 | lr:0.000000\n",
            "Epoch[9142/10000] | loss train:2.262480, test:1.489258 | lr:0.000000\n",
            "Epoch[9143/10000] | loss train:0.795554, test:0.597081 | lr:0.000000\n",
            "Epoch[9144/10000] | loss train:1.292439, test:0.583241 | lr:0.000000\n",
            "Epoch[9145/10000] | loss train:1.101504, test:0.330227 | lr:0.000000\n",
            "Epoch[9146/10000] | loss train:1.821243, test:1.129300 | lr:0.000000\n",
            "Epoch[9147/10000] | loss train:1.779820, test:1.260858 | lr:0.000000\n",
            "Epoch[9148/10000] | loss train:2.047750, test:0.329837 | lr:0.000000\n",
            "Epoch[9149/10000] | loss train:1.936667, test:0.953551 | lr:0.000000\n",
            "Epoch[9150/10000] | loss train:2.941480, test:1.222135 | lr:0.000000\n",
            "Epoch[9151/10000] | loss train:1.089648, test:0.636832 | lr:0.000000\n",
            "Epoch[9152/10000] | loss train:1.491148, test:1.914919 | lr:0.000000\n",
            "Epoch[9153/10000] | loss train:1.320372, test:0.715635 | lr:0.000000\n",
            "Epoch[9154/10000] | loss train:1.627684, test:0.192475 | lr:0.000000\n",
            "Epoch[9155/10000] | loss train:1.025251, test:1.965015 | lr:0.000000\n",
            "Epoch[9156/10000] | loss train:1.468050, test:0.248751 | lr:0.000000\n",
            "Epoch[9157/10000] | loss train:1.281639, test:0.461026 | lr:0.000000\n",
            "Epoch[9158/10000] | loss train:1.334217, test:1.642034 | lr:0.000000\n",
            "Epoch[9159/10000] | loss train:0.772039, test:1.197480 | lr:0.000000\n",
            "Epoch[9160/10000] | loss train:2.200212, test:0.067560 | lr:0.000000\n",
            "Epoch[9161/10000] | loss train:0.752870, test:0.623955 | lr:0.000000\n",
            "Epoch[9162/10000] | loss train:0.984774, test:0.552663 | lr:0.000000\n",
            "Epoch[9163/10000] | loss train:1.595351, test:0.670664 | lr:0.000000\n",
            "Epoch[9164/10000] | loss train:0.738075, test:0.079677 | lr:0.000000\n",
            "Epoch[9165/10000] | loss train:2.172843, test:1.137194 | lr:0.000000\n",
            "Epoch[9166/10000] | loss train:1.663267, test:1.002104 | lr:0.000000\n",
            "Epoch[9167/10000] | loss train:1.367167, test:0.867641 | lr:0.000000\n",
            "Epoch[9168/10000] | loss train:1.671715, test:0.262025 | lr:0.000000\n",
            "Epoch[9169/10000] | loss train:0.843494, test:0.889433 | lr:0.000000\n",
            "Epoch[9170/10000] | loss train:1.251313, test:2.821150 | lr:0.000000\n",
            "Epoch[9171/10000] | loss train:0.718612, test:0.708957 | lr:0.000000\n",
            "Epoch[9172/10000] | loss train:2.124457, test:0.263534 | lr:0.000000\n",
            "Epoch[9173/10000] | loss train:1.554041, test:0.529134 | lr:0.000000\n",
            "Epoch[9174/10000] | loss train:1.099090, test:1.240900 | lr:0.000000\n",
            "Epoch[9175/10000] | loss train:1.341128, test:0.597221 | lr:0.000000\n",
            "Epoch[9176/10000] | loss train:1.046291, test:1.465617 | lr:0.000000\n",
            "Epoch[9177/10000] | loss train:1.050291, test:0.628429 | lr:0.000000\n",
            "Epoch[9178/10000] | loss train:1.208368, test:0.418460 | lr:0.000000\n",
            "Epoch[9179/10000] | loss train:2.497855, test:1.050883 | lr:0.000000\n",
            "Epoch[9180/10000] | loss train:1.901108, test:0.764757 | lr:0.000000\n",
            "Epoch[9181/10000] | loss train:0.896719, test:0.277576 | lr:0.000000\n",
            "Epoch[9182/10000] | loss train:1.001207, test:0.833454 | lr:0.000000\n",
            "Epoch[9183/10000] | loss train:1.102710, test:0.429031 | lr:0.000000\n",
            "Epoch[9184/10000] | loss train:1.251196, test:0.934693 | lr:0.000000\n",
            "Epoch[9185/10000] | loss train:1.262727, test:1.894952 | lr:0.000000\n",
            "Epoch[9186/10000] | loss train:0.986280, test:0.338556 | lr:0.000000\n",
            "Epoch[9187/10000] | loss train:0.808033, test:0.512859 | lr:0.000000\n",
            "Epoch[9188/10000] | loss train:1.007870, test:0.249805 | lr:0.000000\n",
            "Epoch[9189/10000] | loss train:0.769127, test:0.735102 | lr:0.000000\n",
            "Epoch[9190/10000] | loss train:1.371666, test:0.250898 | lr:0.000000\n",
            "Epoch[9191/10000] | loss train:1.284251, test:2.225085 | lr:0.000000\n",
            "Epoch[9192/10000] | loss train:0.647109, test:1.687787 | lr:0.000000\n",
            "Epoch[9193/10000] | loss train:2.256675, test:0.249190 | lr:0.000000\n",
            "Epoch[9194/10000] | loss train:0.702712, test:0.571077 | lr:0.000000\n",
            "Epoch[9195/10000] | loss train:0.917936, test:1.008299 | lr:0.000000\n",
            "Epoch[9196/10000] | loss train:1.193967, test:0.294093 | lr:0.000000\n",
            "Epoch[9197/10000] | loss train:1.207639, test:0.448106 | lr:0.000000\n",
            "Epoch[9198/10000] | loss train:1.068409, test:1.549121 | lr:0.000000\n",
            "Epoch[9199/10000] | loss train:1.002911, test:1.390306 | lr:0.000000\n",
            "Epoch[9200/10000] | loss train:0.714556, test:0.223150 | lr:0.000000\n",
            "Epoch[9201/10000] | loss train:0.884909, test:0.373243 | lr:0.000000\n",
            "Epoch[9202/10000] | loss train:1.633689, test:0.309905 | lr:0.000000\n",
            "Epoch[9203/10000] | loss train:1.867116, test:0.596369 | lr:0.000000\n",
            "Epoch[9204/10000] | loss train:1.431049, test:1.379275 | lr:0.000000\n",
            "Epoch[9205/10000] | loss train:0.917740, test:0.163648 | lr:0.000000\n",
            "Epoch[9206/10000] | loss train:0.978800, test:0.537434 | lr:0.000000\n",
            "Epoch[9207/10000] | loss train:1.135263, test:0.306367 | lr:0.000000\n",
            "Epoch[9208/10000] | loss train:2.122841, test:0.402351 | lr:0.000000\n",
            "Epoch[9209/10000] | loss train:1.123320, test:1.130548 | lr:0.000000\n",
            "Epoch[9210/10000] | loss train:1.166737, test:0.902318 | lr:0.000000\n",
            "Epoch[9211/10000] | loss train:1.247187, test:1.537987 | lr:0.000000\n",
            "Epoch[9212/10000] | loss train:1.205495, test:0.528135 | lr:0.000000\n",
            "Epoch[9213/10000] | loss train:1.361770, test:0.647698 | lr:0.000000\n",
            "Epoch[9214/10000] | loss train:1.162644, test:1.070187 | lr:0.000000\n",
            "Epoch[9215/10000] | loss train:1.279239, test:0.364539 | lr:0.000000\n",
            "Epoch[9216/10000] | loss train:1.242863, test:0.386424 | lr:0.000000\n",
            "Epoch[9217/10000] | loss train:2.372562, test:0.587690 | lr:0.000000\n",
            "Epoch[9218/10000] | loss train:2.040736, test:1.993647 | lr:0.000000\n",
            "Epoch[9219/10000] | loss train:1.089467, test:0.451385 | lr:0.000000\n",
            "Epoch[9220/10000] | loss train:1.674802, test:1.371151 | lr:0.000000\n",
            "Epoch[9221/10000] | loss train:1.272969, test:0.537623 | lr:0.000000\n",
            "Epoch[9222/10000] | loss train:1.040119, test:0.478428 | lr:0.000000\n",
            "Epoch[9223/10000] | loss train:1.188177, test:0.247699 | lr:0.000000\n",
            "Epoch[9224/10000] | loss train:0.752258, test:0.161667 | lr:0.000000\n",
            "Epoch[9225/10000] | loss train:0.775143, test:0.277755 | lr:0.000000\n",
            "Epoch[9226/10000] | loss train:0.643521, test:1.407951 | lr:0.000000\n",
            "Epoch[9227/10000] | loss train:0.764166, test:0.067308 | lr:0.000000\n",
            "Epoch[9228/10000] | loss train:1.042110, test:0.643481 | lr:0.000000\n",
            "Epoch[9229/10000] | loss train:0.974343, test:0.189032 | lr:0.000000\n",
            "Epoch[9230/10000] | loss train:1.260354, test:1.021869 | lr:0.000000\n",
            "Epoch[9231/10000] | loss train:1.050048, test:0.549783 | lr:0.000000\n",
            "Epoch[9232/10000] | loss train:1.775617, test:0.716444 | lr:0.000000\n",
            "Epoch[9233/10000] | loss train:0.934524, test:0.367000 | lr:0.000000\n",
            "Epoch[9234/10000] | loss train:2.116015, test:0.178324 | lr:0.000000\n",
            "Epoch[9235/10000] | loss train:1.468456, test:0.183230 | lr:0.000000\n",
            "Epoch[9236/10000] | loss train:1.001246, test:1.587369 | lr:0.000000\n",
            "Epoch[9237/10000] | loss train:1.125678, test:0.233715 | lr:0.000000\n",
            "Epoch[9238/10000] | loss train:1.882528, test:0.391515 | lr:0.000000\n",
            "Epoch[9239/10000] | loss train:1.571755, test:0.096878 | lr:0.000000\n",
            "Epoch[9240/10000] | loss train:0.912846, test:0.241031 | lr:0.000000\n",
            "Epoch[9241/10000] | loss train:0.885225, test:0.675052 | lr:0.000000\n",
            "Epoch[9242/10000] | loss train:1.170884, test:1.521065 | lr:0.000000\n",
            "Epoch[9243/10000] | loss train:1.061263, test:0.571973 | lr:0.000000\n",
            "Epoch[9244/10000] | loss train:1.488269, test:0.151859 | lr:0.000000\n",
            "Epoch[9245/10000] | loss train:1.016587, test:0.163860 | lr:0.000000\n",
            "Epoch[9246/10000] | loss train:1.827862, test:1.153382 | lr:0.000000\n",
            "Epoch[9247/10000] | loss train:1.955869, test:0.302357 | lr:0.000000\n",
            "Epoch[9248/10000] | loss train:1.253029, test:0.726309 | lr:0.000000\n",
            "Epoch[9249/10000] | loss train:1.230096, test:0.260313 | lr:0.000000\n",
            "Epoch[9250/10000] | loss train:1.629849, test:0.165799 | lr:0.000000\n",
            "Epoch[9251/10000] | loss train:0.679559, test:0.116642 | lr:0.000000\n",
            "Epoch[9252/10000] | loss train:1.169200, test:0.858681 | lr:0.000000\n",
            "Epoch[9253/10000] | loss train:2.201303, test:0.754522 | lr:0.000000\n",
            "Epoch[9254/10000] | loss train:1.343833, test:1.513647 | lr:0.000000\n",
            "Epoch[9255/10000] | loss train:2.013608, test:0.461875 | lr:0.000000\n",
            "Epoch[9256/10000] | loss train:1.407760, test:0.195543 | lr:0.000000\n",
            "Epoch[9257/10000] | loss train:1.108591, test:0.674535 | lr:0.000000\n",
            "Epoch[9258/10000] | loss train:1.023332, test:0.221365 | lr:0.000000\n",
            "Epoch[9259/10000] | loss train:1.015731, test:0.893572 | lr:0.000000\n",
            "Epoch[9260/10000] | loss train:1.191824, test:0.358399 | lr:0.000000\n",
            "Epoch[9261/10000] | loss train:1.460573, test:0.271852 | lr:0.000000\n",
            "Epoch[9262/10000] | loss train:1.060721, test:0.824579 | lr:0.000000\n",
            "Epoch[9263/10000] | loss train:2.110256, test:0.731840 | lr:0.000000\n",
            "Epoch[9264/10000] | loss train:1.833964, test:0.377696 | lr:0.000000\n",
            "Epoch[9265/10000] | loss train:0.801406, test:0.640361 | lr:0.000000\n",
            "Epoch[9266/10000] | loss train:2.000388, test:1.071069 | lr:0.000000\n",
            "Epoch[9267/10000] | loss train:1.078645, test:0.686388 | lr:0.000000\n",
            "Epoch[9268/10000] | loss train:1.512579, test:0.583044 | lr:0.000000\n",
            "Epoch[9269/10000] | loss train:0.870738, test:0.342065 | lr:0.000000\n",
            "Epoch[9270/10000] | loss train:1.056045, test:0.865909 | lr:0.000000\n",
            "Epoch[9271/10000] | loss train:0.760878, test:0.928371 | lr:0.000000\n",
            "Epoch[9272/10000] | loss train:1.066921, test:0.579238 | lr:0.000000\n",
            "Epoch[9273/10000] | loss train:0.796692, test:0.550497 | lr:0.000000\n",
            "Epoch[9274/10000] | loss train:1.073245, test:0.304615 | lr:0.000000\n",
            "Epoch[9275/10000] | loss train:1.941663, test:0.693721 | lr:0.000000\n",
            "Epoch[9276/10000] | loss train:1.697310, test:1.688400 | lr:0.000000\n",
            "Epoch[9277/10000] | loss train:0.897113, test:0.325449 | lr:0.000000\n",
            "Epoch[9278/10000] | loss train:0.773424, test:0.496844 | lr:0.000000\n",
            "Epoch[9279/10000] | loss train:1.259034, test:0.170562 | lr:0.000000\n",
            "Epoch[9280/10000] | loss train:0.709342, test:0.176467 | lr:0.000000\n",
            "Epoch[9281/10000] | loss train:0.671971, test:0.770624 | lr:0.000000\n",
            "Epoch[9282/10000] | loss train:2.290687, test:0.724978 | lr:0.000000\n",
            "Epoch[9283/10000] | loss train:0.893771, test:0.726890 | lr:0.000000\n",
            "Epoch[9284/10000] | loss train:1.169332, test:0.843580 | lr:0.000000\n",
            "Epoch[9285/10000] | loss train:2.092762, test:0.353377 | lr:0.000000\n",
            "Epoch[9286/10000] | loss train:1.249538, test:0.580753 | lr:0.000000\n",
            "Epoch[9287/10000] | loss train:1.798165, test:1.676520 | lr:0.000000\n",
            "Epoch[9288/10000] | loss train:1.536743, test:0.450677 | lr:0.000000\n",
            "Epoch[9289/10000] | loss train:0.868549, test:0.105153 | lr:0.000000\n",
            "Epoch[9290/10000] | loss train:1.091048, test:0.518003 | lr:0.000000\n",
            "Epoch[9291/10000] | loss train:1.069442, test:0.094673 | lr:0.000000\n",
            "Epoch[9292/10000] | loss train:1.040307, test:0.488975 | lr:0.000000\n",
            "Epoch[9293/10000] | loss train:1.433867, test:0.127392 | lr:0.000000\n",
            "Epoch[9294/10000] | loss train:1.085030, test:0.265515 | lr:0.000000\n",
            "Epoch[9295/10000] | loss train:1.661351, test:0.198340 | lr:0.000000\n",
            "Epoch[9296/10000] | loss train:0.810822, test:0.681099 | lr:0.000000\n",
            "Epoch[9297/10000] | loss train:0.839837, test:0.288442 | lr:0.000000\n",
            "Epoch[9298/10000] | loss train:0.988561, test:0.328075 | lr:0.000000\n",
            "Epoch[9299/10000] | loss train:1.035533, test:0.382215 | lr:0.000000\n",
            "Epoch[9300/10000] | loss train:1.117790, test:0.489444 | lr:0.000000\n",
            "Epoch[9301/10000] | loss train:1.098635, test:0.164150 | lr:0.000000\n",
            "Epoch[9302/10000] | loss train:1.451901, test:0.492799 | lr:0.000000\n",
            "Epoch[9303/10000] | loss train:1.693922, test:0.835783 | lr:0.000000\n",
            "Epoch[9304/10000] | loss train:0.959694, test:0.666654 | lr:0.000000\n",
            "Epoch[9305/10000] | loss train:0.796350, test:0.999553 | lr:0.000000\n",
            "Epoch[9306/10000] | loss train:0.887574, test:0.429132 | lr:0.000000\n",
            "Epoch[9307/10000] | loss train:1.441303, test:0.205944 | lr:0.000000\n",
            "Epoch[9308/10000] | loss train:1.526049, test:1.119174 | lr:0.000000\n",
            "Epoch[9309/10000] | loss train:0.981440, test:0.840725 | lr:0.000000\n",
            "Epoch[9310/10000] | loss train:1.437894, test:0.504328 | lr:0.000000\n",
            "Epoch[9311/10000] | loss train:2.426557, test:0.376419 | lr:0.000000\n",
            "Epoch[9312/10000] | loss train:1.205517, test:0.897070 | lr:0.000000\n",
            "Epoch[9313/10000] | loss train:1.840377, test:1.575762 | lr:0.000000\n",
            "Epoch[9314/10000] | loss train:2.566610, test:1.365914 | lr:0.000000\n",
            "Epoch[9315/10000] | loss train:1.372932, test:0.693409 | lr:0.000000\n",
            "Epoch[9316/10000] | loss train:2.024341, test:0.200267 | lr:0.000000\n",
            "Epoch[9317/10000] | loss train:1.465532, test:1.438144 | lr:0.000000\n",
            "Epoch[9318/10000] | loss train:1.185311, test:0.398186 | lr:0.000000\n",
            "Epoch[9319/10000] | loss train:1.863988, test:1.289722 | lr:0.000000\n",
            "Epoch[9320/10000] | loss train:2.108950, test:0.969325 | lr:0.000000\n",
            "Epoch[9321/10000] | loss train:0.776781, test:0.209261 | lr:0.000000\n",
            "Epoch[9322/10000] | loss train:0.736459, test:0.295703 | lr:0.000000\n",
            "Epoch[9323/10000] | loss train:3.096483, test:1.091881 | lr:0.000000\n",
            "Epoch[9324/10000] | loss train:1.166383, test:0.460420 | lr:0.000000\n",
            "Epoch[9325/10000] | loss train:1.190064, test:0.629369 | lr:0.000000\n",
            "Epoch[9326/10000] | loss train:1.544968, test:0.884991 | lr:0.000000\n",
            "Epoch[9327/10000] | loss train:0.885230, test:0.744308 | lr:0.000000\n",
            "Epoch[9328/10000] | loss train:0.882273, test:0.648556 | lr:0.000000\n",
            "Epoch[9329/10000] | loss train:0.967068, test:0.121415 | lr:0.000000\n",
            "Epoch[9330/10000] | loss train:1.614900, test:0.323328 | lr:0.000000\n",
            "Epoch[9331/10000] | loss train:1.336774, test:0.201553 | lr:0.000000\n",
            "Epoch[9332/10000] | loss train:1.292940, test:0.654266 | lr:0.000000\n",
            "Epoch[9333/10000] | loss train:1.039733, test:0.220828 | lr:0.000000\n",
            "Epoch[9334/10000] | loss train:0.903113, test:0.780789 | lr:0.000000\n",
            "Epoch[9335/10000] | loss train:0.787420, test:0.436044 | lr:0.000000\n",
            "Epoch[9336/10000] | loss train:1.039797, test:0.089075 | lr:0.000000\n",
            "Epoch[9337/10000] | loss train:0.817548, test:0.889607 | lr:0.000000\n",
            "Epoch[9338/10000] | loss train:1.287588, test:0.675024 | lr:0.000000\n",
            "Epoch[9339/10000] | loss train:0.950317, test:0.492461 | lr:0.000000\n",
            "Epoch[9340/10000] | loss train:0.755026, test:1.289634 | lr:0.000000\n",
            "Epoch[9341/10000] | loss train:1.087872, test:1.202984 | lr:0.000000\n",
            "Epoch[9342/10000] | loss train:1.933130, test:0.480394 | lr:0.000000\n",
            "Epoch[9343/10000] | loss train:1.296353, test:0.295345 | lr:0.000000\n",
            "Epoch[9344/10000] | loss train:1.209412, test:0.398365 | lr:0.000000\n",
            "Epoch[9345/10000] | loss train:0.826046, test:0.130011 | lr:0.000000\n",
            "Epoch[9346/10000] | loss train:1.285438, test:0.130110 | lr:0.000000\n",
            "Epoch[9347/10000] | loss train:0.649452, test:0.439727 | lr:0.000000\n",
            "Epoch[9348/10000] | loss train:1.034964, test:0.599510 | lr:0.000000\n",
            "Epoch[9349/10000] | loss train:3.358795, test:0.393003 | lr:0.000000\n",
            "Epoch[9350/10000] | loss train:1.274034, test:2.159668 | lr:0.000000\n",
            "Epoch[9351/10000] | loss train:0.763161, test:0.935138 | lr:0.000000\n",
            "Epoch[9352/10000] | loss train:1.658746, test:0.243085 | lr:0.000000\n",
            "Epoch[9353/10000] | loss train:1.412164, test:0.247488 | lr:0.000000\n",
            "Epoch[9354/10000] | loss train:2.100255, test:0.672343 | lr:0.000000\n",
            "Epoch[9355/10000] | loss train:2.170158, test:0.273511 | lr:0.000000\n",
            "Epoch[9356/10000] | loss train:1.325525, test:0.255302 | lr:0.000000\n",
            "Epoch[9357/10000] | loss train:1.220781, test:0.494433 | lr:0.000000\n",
            "Epoch[9358/10000] | loss train:1.039523, test:0.407599 | lr:0.000000\n",
            "Epoch[9359/10000] | loss train:0.677624, test:0.772408 | lr:0.000000\n",
            "Epoch[9360/10000] | loss train:0.835706, test:1.174850 | lr:0.000000\n",
            "Epoch[9361/10000] | loss train:1.212956, test:1.661347 | lr:0.000000\n",
            "Epoch[9362/10000] | loss train:1.594678, test:0.331414 | lr:0.000000\n",
            "Epoch[9363/10000] | loss train:0.845238, test:1.179716 | lr:0.000000\n",
            "Epoch[9364/10000] | loss train:0.933578, test:0.982215 | lr:0.000000\n",
            "Epoch[9365/10000] | loss train:1.815590, test:1.566432 | lr:0.000000\n",
            "Epoch[9366/10000] | loss train:1.046950, test:0.669209 | lr:0.000000\n",
            "Epoch[9367/10000] | loss train:0.961229, test:0.394923 | lr:0.000000\n",
            "Epoch[9368/10000] | loss train:1.097920, test:1.269414 | lr:0.000000\n",
            "Epoch[9369/10000] | loss train:0.787804, test:1.388968 | lr:0.000000\n",
            "Epoch[9370/10000] | loss train:1.584276, test:0.237681 | lr:0.000000\n",
            "Epoch[9371/10000] | loss train:1.103240, test:0.964667 | lr:0.000000\n",
            "Epoch[9372/10000] | loss train:0.869858, test:0.340044 | lr:0.000000\n",
            "Epoch[9373/10000] | loss train:1.033438, test:0.325654 | lr:0.000000\n",
            "Epoch[9374/10000] | loss train:0.865549, test:0.647263 | lr:0.000000\n",
            "Epoch[9375/10000] | loss train:1.942824, test:1.428428 | lr:0.000000\n",
            "Epoch[9376/10000] | loss train:1.289614, test:0.719067 | lr:0.000000\n",
            "Epoch[9377/10000] | loss train:1.182637, test:0.258431 | lr:0.000000\n",
            "Epoch[9378/10000] | loss train:1.593081, test:0.512820 | lr:0.000000\n",
            "Epoch[9379/10000] | loss train:1.089636, test:0.937837 | lr:0.000000\n",
            "Epoch[9380/10000] | loss train:0.875464, test:0.293826 | lr:0.000000\n",
            "Epoch[9381/10000] | loss train:0.686480, test:0.702200 | lr:0.000000\n",
            "Epoch[9382/10000] | loss train:1.122549, test:0.408997 | lr:0.000000\n",
            "Epoch[9383/10000] | loss train:1.121588, test:0.549213 | lr:0.000000\n",
            "Epoch[9384/10000] | loss train:1.359701, test:2.304925 | lr:0.000000\n",
            "Epoch[9385/10000] | loss train:0.727246, test:0.621603 | lr:0.000000\n",
            "Epoch[9386/10000] | loss train:2.986990, test:0.346243 | lr:0.000000\n",
            "Epoch[9387/10000] | loss train:0.868688, test:0.296259 | lr:0.000000\n",
            "Epoch[9388/10000] | loss train:1.043751, test:0.372148 | lr:0.000000\n",
            "Epoch[9389/10000] | loss train:0.798130, test:0.363129 | lr:0.000000\n",
            "Epoch[9390/10000] | loss train:1.430102, test:0.239646 | lr:0.000000\n",
            "Epoch[9391/10000] | loss train:0.960426, test:0.423803 | lr:0.000000\n",
            "Epoch[9392/10000] | loss train:0.696137, test:0.095921 | lr:0.000000\n",
            "Epoch[9393/10000] | loss train:1.254409, test:0.219235 | lr:0.000000\n",
            "Epoch[9394/10000] | loss train:1.460044, test:1.523249 | lr:0.000000\n",
            "Epoch[9395/10000] | loss train:1.916989, test:1.152763 | lr:0.000000\n",
            "Epoch[9396/10000] | loss train:2.014754, test:0.127852 | lr:0.000000\n",
            "Epoch[9397/10000] | loss train:0.827931, test:1.755919 | lr:0.000000\n",
            "Epoch[9398/10000] | loss train:1.176320, test:0.482466 | lr:0.000000\n",
            "Epoch[9399/10000] | loss train:1.583138, test:0.385646 | lr:0.000000\n",
            "Epoch[9400/10000] | loss train:1.192366, test:1.066665 | lr:0.000000\n",
            "Epoch[9401/10000] | loss train:1.316412, test:0.574940 | lr:0.000000\n",
            "Epoch[9402/10000] | loss train:0.960641, test:0.456047 | lr:0.000000\n",
            "Epoch[9403/10000] | loss train:1.460237, test:1.238542 | lr:0.000000\n",
            "Epoch[9404/10000] | loss train:2.373768, test:0.252566 | lr:0.000000\n",
            "Epoch[9405/10000] | loss train:1.044741, test:0.239853 | lr:0.000000\n",
            "Epoch[9406/10000] | loss train:0.949046, test:0.252462 | lr:0.000000\n",
            "Epoch[9407/10000] | loss train:0.983190, test:1.691851 | lr:0.000000\n",
            "Epoch[9408/10000] | loss train:1.532569, test:0.330878 | lr:0.000000\n",
            "Epoch[9409/10000] | loss train:1.007996, test:0.898838 | lr:0.000000\n",
            "Epoch[9410/10000] | loss train:1.330537, test:0.555089 | lr:0.000000\n",
            "Epoch[9411/10000] | loss train:1.679281, test:1.295319 | lr:0.000000\n",
            "Epoch[9412/10000] | loss train:1.137438, test:1.565211 | lr:0.000000\n",
            "Epoch[9413/10000] | loss train:1.420188, test:0.270714 | lr:0.000000\n",
            "Epoch[9414/10000] | loss train:1.482235, test:1.156787 | lr:0.000000\n",
            "Epoch[9415/10000] | loss train:1.460984, test:1.347832 | lr:0.000000\n",
            "Epoch[9416/10000] | loss train:1.159790, test:1.061197 | lr:0.000000\n",
            "Epoch[9417/10000] | loss train:0.840179, test:0.321077 | lr:0.000000\n",
            "Epoch[9418/10000] | loss train:0.981770, test:0.633124 | lr:0.000000\n",
            "Epoch[9419/10000] | loss train:1.467883, test:0.613247 | lr:0.000000\n",
            "Epoch[9420/10000] | loss train:1.768767, test:0.237621 | lr:0.000000\n",
            "Epoch[9421/10000] | loss train:0.764640, test:0.424643 | lr:0.000000\n",
            "Epoch[9422/10000] | loss train:2.443120, test:0.492156 | lr:0.000000\n",
            "Epoch[9423/10000] | loss train:0.775359, test:0.631628 | lr:0.000000\n",
            "Epoch[9424/10000] | loss train:1.755295, test:0.774821 | lr:0.000000\n",
            "Epoch[9425/10000] | loss train:1.069452, test:1.054094 | lr:0.000000\n",
            "Epoch[9426/10000] | loss train:0.927880, test:0.173398 | lr:0.000000\n",
            "Epoch[9427/10000] | loss train:1.426783, test:0.229115 | lr:0.000000\n",
            "Epoch[9428/10000] | loss train:1.238352, test:0.611466 | lr:0.000000\n",
            "Epoch[9429/10000] | loss train:1.389901, test:0.142781 | lr:0.000000\n",
            "Epoch[9430/10000] | loss train:1.713475, test:0.594727 | lr:0.000000\n",
            "Epoch[9431/10000] | loss train:1.677504, test:1.086852 | lr:0.000000\n",
            "Epoch[9432/10000] | loss train:0.899304, test:0.597825 | lr:0.000000\n",
            "Epoch[9433/10000] | loss train:1.165409, test:0.483668 | lr:0.000000\n",
            "Epoch[9434/10000] | loss train:1.423867, test:0.571763 | lr:0.000000\n",
            "Epoch[9435/10000] | loss train:1.458773, test:0.646951 | lr:0.000000\n",
            "Epoch[9436/10000] | loss train:1.029606, test:0.213301 | lr:0.000000\n",
            "Epoch[9437/10000] | loss train:1.086650, test:1.361004 | lr:0.000000\n",
            "Epoch[9438/10000] | loss train:1.299073, test:0.211303 | lr:0.000000\n",
            "Epoch[9439/10000] | loss train:1.616125, test:0.134221 | lr:0.000000\n",
            "Epoch[9440/10000] | loss train:1.006650, test:1.212070 | lr:0.000000\n",
            "Epoch[9441/10000] | loss train:2.034023, test:1.430896 | lr:0.000000\n",
            "Epoch[9442/10000] | loss train:3.024616, test:1.182532 | lr:0.000000\n",
            "Epoch[9443/10000] | loss train:1.201863, test:0.295952 | lr:0.000000\n",
            "Epoch[9444/10000] | loss train:0.864952, test:1.075357 | lr:0.000000\n",
            "Epoch[9445/10000] | loss train:1.939354, test:0.531057 | lr:0.000000\n",
            "Epoch[9446/10000] | loss train:1.579967, test:0.513380 | lr:0.000000\n",
            "Epoch[9447/10000] | loss train:1.211433, test:0.555596 | lr:0.000000\n",
            "Epoch[9448/10000] | loss train:1.150663, test:0.206977 | lr:0.000000\n",
            "Epoch[9449/10000] | loss train:0.773203, test:0.235709 | lr:0.000000\n",
            "Epoch[9450/10000] | loss train:1.250245, test:1.400987 | lr:0.000000\n",
            "Epoch[9451/10000] | loss train:0.703149, test:0.653269 | lr:0.000000\n",
            "Epoch[9452/10000] | loss train:1.131398, test:1.751333 | lr:0.000000\n",
            "Epoch[9453/10000] | loss train:1.613612, test:0.802036 | lr:0.000000\n",
            "Epoch[9454/10000] | loss train:1.683146, test:0.509354 | lr:0.000000\n",
            "Epoch[9455/10000] | loss train:2.152189, test:0.504684 | lr:0.000000\n",
            "Epoch[9456/10000] | loss train:1.564488, test:0.426990 | lr:0.000000\n",
            "Epoch[9457/10000] | loss train:1.630679, test:1.308561 | lr:0.000000\n",
            "Epoch[9458/10000] | loss train:1.296900, test:0.693490 | lr:0.000000\n",
            "Epoch[9459/10000] | loss train:1.456118, test:0.281726 | lr:0.000000\n",
            "Epoch[9460/10000] | loss train:1.316046, test:0.474721 | lr:0.000000\n",
            "Epoch[9461/10000] | loss train:0.853471, test:0.407030 | lr:0.000000\n",
            "Epoch[9462/10000] | loss train:1.143100, test:1.227749 | lr:0.000000\n",
            "Epoch[9463/10000] | loss train:0.783798, test:0.973231 | lr:0.000000\n",
            "Epoch[9464/10000] | loss train:0.728136, test:0.452025 | lr:0.000000\n",
            "Epoch[9465/10000] | loss train:1.963875, test:0.674233 | lr:0.000000\n",
            "Epoch[9466/10000] | loss train:0.785920, test:0.266111 | lr:0.000000\n",
            "Epoch[9467/10000] | loss train:1.204464, test:0.329073 | lr:0.000000\n",
            "Epoch[9468/10000] | loss train:0.746931, test:0.877812 | lr:0.000000\n",
            "Epoch[9469/10000] | loss train:1.128623, test:1.110838 | lr:0.000000\n",
            "Epoch[9470/10000] | loss train:1.264271, test:0.356449 | lr:0.000000\n",
            "Epoch[9471/10000] | loss train:1.255859, test:0.498393 | lr:0.000000\n",
            "Epoch[9472/10000] | loss train:0.743437, test:0.248541 | lr:0.000000\n",
            "Epoch[9473/10000] | loss train:0.846939, test:0.656703 | lr:0.000000\n",
            "Epoch[9474/10000] | loss train:1.411132, test:0.195758 | lr:0.000000\n",
            "Epoch[9475/10000] | loss train:1.265724, test:0.636362 | lr:0.000000\n",
            "Epoch[9476/10000] | loss train:1.833861, test:0.315338 | lr:0.000000\n",
            "Epoch[9477/10000] | loss train:0.639577, test:0.211708 | lr:0.000000\n",
            "Epoch[9478/10000] | loss train:1.463782, test:1.130797 | lr:0.000000\n",
            "Epoch[9479/10000] | loss train:1.923164, test:0.345446 | lr:0.000000\n",
            "Epoch[9480/10000] | loss train:2.264710, test:0.361901 | lr:0.000000\n",
            "Epoch[9481/10000] | loss train:1.155228, test:0.200110 | lr:0.000000\n",
            "Epoch[9482/10000] | loss train:1.042830, test:0.156980 | lr:0.000000\n",
            "Epoch[9483/10000] | loss train:1.139112, test:0.367848 | lr:0.000000\n",
            "Epoch[9484/10000] | loss train:0.863380, test:0.216606 | lr:0.000000\n",
            "Epoch[9485/10000] | loss train:1.390921, test:1.319979 | lr:0.000000\n",
            "Epoch[9486/10000] | loss train:1.370311, test:0.658369 | lr:0.000000\n",
            "Epoch[9487/10000] | loss train:1.060634, test:0.283940 | lr:0.000000\n",
            "Epoch[9488/10000] | loss train:0.882827, test:0.551993 | lr:0.000000\n",
            "Epoch[9489/10000] | loss train:1.428888, test:0.831382 | lr:0.000000\n",
            "Epoch[9490/10000] | loss train:1.080510, test:0.295143 | lr:0.000000\n",
            "Epoch[9491/10000] | loss train:1.609222, test:0.052182 | lr:0.000000\n",
            "Epoch[9492/10000] | loss train:1.439378, test:0.655018 | lr:0.000000\n",
            "Epoch[9493/10000] | loss train:1.631585, test:0.559901 | lr:0.000000\n",
            "Epoch[9494/10000] | loss train:2.018289, test:0.473052 | lr:0.000000\n",
            "Epoch[9495/10000] | loss train:1.558400, test:0.600306 | lr:0.000000\n",
            "Epoch[9496/10000] | loss train:1.306441, test:0.454239 | lr:0.000000\n",
            "Epoch[9497/10000] | loss train:1.461375, test:0.782284 | lr:0.000000\n",
            "Epoch[9498/10000] | loss train:0.770336, test:0.869604 | lr:0.000000\n",
            "Epoch[9499/10000] | loss train:1.113218, test:0.315830 | lr:0.000000\n",
            "Epoch[9500/10000] | loss train:1.562544, test:0.416769 | lr:0.000000\n",
            "Epoch[9501/10000] | loss train:1.220604, test:0.162208 | lr:0.000000\n",
            "Epoch[9502/10000] | loss train:1.829732, test:1.218146 | lr:0.000000\n",
            "Epoch[9503/10000] | loss train:0.737084, test:0.283067 | lr:0.000000\n",
            "Epoch[9504/10000] | loss train:1.706845, test:0.673774 | lr:0.000000\n",
            "Epoch[9505/10000] | loss train:1.257097, test:0.239400 | lr:0.000000\n",
            "Epoch[9506/10000] | loss train:1.320423, test:0.587985 | lr:0.000000\n",
            "Epoch[9507/10000] | loss train:1.378670, test:0.287759 | lr:0.000000\n",
            "Epoch[9508/10000] | loss train:1.381156, test:0.710249 | lr:0.000000\n",
            "Epoch[9509/10000] | loss train:1.170448, test:0.567249 | lr:0.000000\n",
            "Epoch[9510/10000] | loss train:2.190747, test:0.508681 | lr:0.000000\n",
            "Epoch[9511/10000] | loss train:0.954360, test:1.673711 | lr:0.000000\n",
            "Epoch[9512/10000] | loss train:1.626222, test:0.085165 | lr:0.000000\n",
            "Epoch[9513/10000] | loss train:1.422453, test:0.667960 | lr:0.000000\n",
            "Epoch[9514/10000] | loss train:1.985718, test:0.180501 | lr:0.000000\n",
            "Epoch[9515/10000] | loss train:1.928131, test:0.802018 | lr:0.000000\n",
            "Epoch[9516/10000] | loss train:1.194293, test:1.035685 | lr:0.000000\n",
            "Epoch[9517/10000] | loss train:0.719866, test:1.259131 | lr:0.000000\n",
            "Epoch[9518/10000] | loss train:1.331109, test:0.742870 | lr:0.000000\n",
            "Epoch[9519/10000] | loss train:1.203451, test:1.488509 | lr:0.000000\n",
            "Epoch[9520/10000] | loss train:0.984229, test:0.746860 | lr:0.000000\n",
            "Epoch[9521/10000] | loss train:1.517504, test:0.158408 | lr:0.000000\n",
            "Epoch[9522/10000] | loss train:1.457926, test:0.131157 | lr:0.000000\n",
            "Epoch[9523/10000] | loss train:1.178212, test:0.517429 | lr:0.000000\n",
            "Epoch[9524/10000] | loss train:1.044175, test:0.473753 | lr:0.000000\n",
            "Epoch[9525/10000] | loss train:1.576161, test:1.375795 | lr:0.000000\n",
            "Epoch[9526/10000] | loss train:1.721216, test:1.053093 | lr:0.000000\n",
            "Epoch[9527/10000] | loss train:1.908918, test:1.143369 | lr:0.000000\n",
            "Epoch[9528/10000] | loss train:1.525732, test:0.520310 | lr:0.000000\n",
            "Epoch[9529/10000] | loss train:1.180996, test:1.267131 | lr:0.000000\n",
            "Epoch[9530/10000] | loss train:1.402042, test:0.344909 | lr:0.000000\n",
            "Epoch[9531/10000] | loss train:1.384190, test:0.159386 | lr:0.000000\n",
            "Epoch[9532/10000] | loss train:1.359814, test:0.049481 | lr:0.000000\n",
            "Epoch[9533/10000] | loss train:0.879812, test:0.212156 | lr:0.000000\n",
            "Epoch[9534/10000] | loss train:1.568212, test:0.603300 | lr:0.000000\n",
            "Epoch[9535/10000] | loss train:0.987786, test:0.930587 | lr:0.000000\n",
            "Epoch[9536/10000] | loss train:0.833900, test:1.037567 | lr:0.000000\n",
            "Epoch[9537/10000] | loss train:1.102602, test:0.483967 | lr:0.000000\n",
            "Epoch[9538/10000] | loss train:0.926060, test:0.957663 | lr:0.000000\n",
            "Epoch[9539/10000] | loss train:0.710925, test:1.153155 | lr:0.000000\n",
            "Epoch[9540/10000] | loss train:1.065636, test:0.244337 | lr:0.000000\n",
            "Epoch[9541/10000] | loss train:0.911398, test:0.383608 | lr:0.000000\n",
            "Epoch[9542/10000] | loss train:1.167441, test:0.814667 | lr:0.000000\n",
            "Epoch[9543/10000] | loss train:1.866690, test:0.497699 | lr:0.000000\n",
            "Epoch[9544/10000] | loss train:1.417625, test:1.113083 | lr:0.000000\n",
            "Epoch[9545/10000] | loss train:0.802180, test:1.364927 | lr:0.000000\n",
            "Epoch[9546/10000] | loss train:0.919344, test:1.179122 | lr:0.000000\n",
            "Epoch[9547/10000] | loss train:0.793172, test:0.170395 | lr:0.000000\n",
            "Epoch[9548/10000] | loss train:0.890897, test:0.245445 | lr:0.000000\n",
            "Epoch[9549/10000] | loss train:1.761828, test:0.265204 | lr:0.000000\n",
            "Epoch[9550/10000] | loss train:1.514452, test:0.206565 | lr:0.000000\n",
            "Epoch[9551/10000] | loss train:1.072305, test:0.125206 | lr:0.000000\n",
            "Epoch[9552/10000] | loss train:0.877536, test:0.734624 | lr:0.000000\n",
            "Epoch[9553/10000] | loss train:1.189529, test:0.397874 | lr:0.000000\n",
            "Epoch[9554/10000] | loss train:1.282377, test:0.276956 | lr:0.000000\n",
            "Epoch[9555/10000] | loss train:1.176693, test:0.191378 | lr:0.000000\n",
            "Epoch[9556/10000] | loss train:1.235242, test:1.606200 | lr:0.000000\n",
            "Epoch[9557/10000] | loss train:1.351229, test:0.374539 | lr:0.000000\n",
            "Epoch[9558/10000] | loss train:1.358817, test:0.461659 | lr:0.000000\n",
            "Epoch[9559/10000] | loss train:1.287179, test:0.306024 | lr:0.000000\n",
            "Epoch[9560/10000] | loss train:1.130059, test:0.244290 | lr:0.000000\n",
            "Epoch[9561/10000] | loss train:0.951811, test:0.375840 | lr:0.000000\n",
            "Epoch[9562/10000] | loss train:1.402309, test:0.562006 | lr:0.000000\n",
            "Epoch[9563/10000] | loss train:1.258146, test:0.288173 | lr:0.000000\n",
            "Epoch[9564/10000] | loss train:1.017042, test:0.615927 | lr:0.000000\n",
            "Epoch[9565/10000] | loss train:1.150096, test:0.212809 | lr:0.000000\n",
            "Epoch[9566/10000] | loss train:1.939344, test:1.122637 | lr:0.000000\n",
            "Epoch[9567/10000] | loss train:0.985829, test:0.479389 | lr:0.000000\n",
            "Epoch[9568/10000] | loss train:0.989290, test:0.512272 | lr:0.000000\n",
            "Epoch[9569/10000] | loss train:1.220616, test:0.091272 | lr:0.000000\n",
            "Epoch[9570/10000] | loss train:0.708501, test:0.629180 | lr:0.000000\n",
            "Epoch[9571/10000] | loss train:1.488589, test:0.683499 | lr:0.000000\n",
            "Epoch[9572/10000] | loss train:0.887181, test:0.416037 | lr:0.000000\n",
            "Epoch[9573/10000] | loss train:1.312248, test:0.536928 | lr:0.000000\n",
            "Epoch[9574/10000] | loss train:1.103146, test:0.094900 | lr:0.000000\n",
            "Epoch[9575/10000] | loss train:1.198206, test:0.434233 | lr:0.000000\n",
            "Epoch[9576/10000] | loss train:2.275248, test:0.447862 | lr:0.000000\n",
            "Epoch[9577/10000] | loss train:0.761133, test:0.131218 | lr:0.000000\n",
            "Epoch[9578/10000] | loss train:0.693860, test:0.979849 | lr:0.000000\n",
            "Epoch[9579/10000] | loss train:0.894242, test:0.336737 | lr:0.000000\n",
            "Epoch[9580/10000] | loss train:1.341972, test:0.664666 | lr:0.000000\n",
            "Epoch[9581/10000] | loss train:1.050906, test:0.361608 | lr:0.000000\n",
            "Epoch[9582/10000] | loss train:0.892983, test:0.274328 | lr:0.000000\n",
            "Epoch[9583/10000] | loss train:2.434568, test:0.206441 | lr:0.000000\n",
            "Epoch[9584/10000] | loss train:1.285350, test:1.880394 | lr:0.000000\n",
            "Epoch[9585/10000] | loss train:0.835340, test:0.355657 | lr:0.000000\n",
            "Epoch[9586/10000] | loss train:1.276066, test:1.963633 | lr:0.000000\n",
            "Epoch[9587/10000] | loss train:1.143306, test:0.521168 | lr:0.000000\n",
            "Epoch[9588/10000] | loss train:1.510150, test:0.361958 | lr:0.000000\n",
            "Epoch[9589/10000] | loss train:0.882855, test:0.115520 | lr:0.000000\n",
            "Epoch[9590/10000] | loss train:0.787703, test:0.620346 | lr:0.000000\n",
            "Epoch[9591/10000] | loss train:1.304302, test:1.129668 | lr:0.000000\n",
            "Epoch[9592/10000] | loss train:0.994912, test:0.229767 | lr:0.000000\n",
            "Epoch[9593/10000] | loss train:1.475603, test:0.403017 | lr:0.000000\n",
            "Epoch[9594/10000] | loss train:1.719362, test:0.642287 | lr:0.000000\n",
            "Epoch[9595/10000] | loss train:1.274914, test:0.458886 | lr:0.000000\n",
            "Epoch[9596/10000] | loss train:1.215370, test:0.255015 | lr:0.000000\n",
            "Epoch[9597/10000] | loss train:1.412825, test:0.491372 | lr:0.000000\n",
            "Epoch[9598/10000] | loss train:1.471404, test:0.329641 | lr:0.000000\n",
            "Epoch[9599/10000] | loss train:1.877193, test:0.425223 | lr:0.000000\n",
            "Epoch[9600/10000] | loss train:1.366969, test:0.488978 | lr:0.000000\n",
            "Epoch[9601/10000] | loss train:0.866786, test:0.250298 | lr:0.000000\n",
            "Epoch[9602/10000] | loss train:0.986672, test:0.194356 | lr:0.000000\n",
            "Epoch[9603/10000] | loss train:1.670838, test:0.400709 | lr:0.000000\n",
            "Epoch[9604/10000] | loss train:1.367936, test:0.205030 | lr:0.000000\n",
            "Epoch[9605/10000] | loss train:0.759717, test:1.138908 | lr:0.000000\n",
            "Epoch[9606/10000] | loss train:0.916247, test:1.303077 | lr:0.000000\n",
            "Epoch[9607/10000] | loss train:1.397871, test:1.276557 | lr:0.000000\n",
            "Epoch[9608/10000] | loss train:0.856233, test:0.049591 | lr:0.000000\n",
            "Epoch[9609/10000] | loss train:2.480305, test:0.181726 | lr:0.000000\n",
            "Epoch[9610/10000] | loss train:1.395216, test:0.276785 | lr:0.000000\n",
            "Epoch[9611/10000] | loss train:2.591736, test:0.374298 | lr:0.000000\n",
            "Epoch[9612/10000] | loss train:1.333432, test:0.268961 | lr:0.000000\n",
            "Epoch[9613/10000] | loss train:1.405359, test:1.097315 | lr:0.000000\n",
            "Epoch[9614/10000] | loss train:1.075838, test:0.689888 | lr:0.000000\n",
            "Epoch[9615/10000] | loss train:1.146576, test:0.887122 | lr:0.000000\n",
            "Epoch[9616/10000] | loss train:1.254029, test:0.627995 | lr:0.000000\n",
            "Epoch[9617/10000] | loss train:2.326210, test:0.612508 | lr:0.000000\n",
            "Epoch[9618/10000] | loss train:1.160180, test:0.770669 | lr:0.000000\n",
            "Epoch[9619/10000] | loss train:1.223958, test:1.821990 | lr:0.000000\n",
            "Epoch[9620/10000] | loss train:1.362460, test:0.709699 | lr:0.000000\n",
            "Epoch[9621/10000] | loss train:0.763174, test:1.188005 | lr:0.000000\n",
            "Epoch[9622/10000] | loss train:0.807396, test:0.197857 | lr:0.000000\n",
            "Epoch[9623/10000] | loss train:1.671006, test:0.821298 | lr:0.000000\n",
            "Epoch[9624/10000] | loss train:0.971857, test:0.252337 | lr:0.000000\n",
            "Epoch[9625/10000] | loss train:0.700665, test:0.814623 | lr:0.000000\n",
            "Epoch[9626/10000] | loss train:1.566975, test:0.383320 | lr:0.000000\n",
            "Epoch[9627/10000] | loss train:1.634924, test:0.305046 | lr:0.000000\n",
            "Epoch[9628/10000] | loss train:1.245281, test:0.334064 | lr:0.000000\n",
            "Epoch[9629/10000] | loss train:1.055766, test:2.074751 | lr:0.000000\n",
            "Epoch[9630/10000] | loss train:1.076029, test:0.404622 | lr:0.000000\n",
            "Epoch[9631/10000] | loss train:1.728752, test:0.511520 | lr:0.000000\n",
            "Epoch[9632/10000] | loss train:1.759658, test:1.004708 | lr:0.000000\n",
            "Epoch[9633/10000] | loss train:2.256186, test:0.365122 | lr:0.000000\n",
            "Epoch[9634/10000] | loss train:1.267964, test:0.974190 | lr:0.000000\n",
            "Epoch[9635/10000] | loss train:1.317156, test:0.139777 | lr:0.000000\n",
            "Epoch[9636/10000] | loss train:1.942158, test:1.278412 | lr:0.000000\n",
            "Epoch[9637/10000] | loss train:0.812576, test:0.377535 | lr:0.000000\n",
            "Epoch[9638/10000] | loss train:0.974581, test:0.710399 | lr:0.000000\n",
            "Epoch[9639/10000] | loss train:1.078402, test:0.326553 | lr:0.000000\n",
            "Epoch[9640/10000] | loss train:1.029486, test:0.149961 | lr:0.000000\n",
            "Epoch[9641/10000] | loss train:2.080583, test:0.799007 | lr:0.000000\n",
            "Epoch[9642/10000] | loss train:0.773589, test:0.604570 | lr:0.000000\n",
            "Epoch[9643/10000] | loss train:0.975846, test:0.381528 | lr:0.000000\n",
            "Epoch[9644/10000] | loss train:1.369810, test:1.039514 | lr:0.000000\n",
            "Epoch[9645/10000] | loss train:0.794465, test:0.297571 | lr:0.000000\n",
            "Epoch[9646/10000] | loss train:1.422988, test:0.711213 | lr:0.000000\n",
            "Epoch[9647/10000] | loss train:2.153927, test:1.210707 | lr:0.000000\n",
            "Epoch[9648/10000] | loss train:1.630716, test:0.763348 | lr:0.000000\n",
            "Epoch[9649/10000] | loss train:1.230397, test:1.602892 | lr:0.000000\n",
            "Epoch[9650/10000] | loss train:0.625435, test:0.049137 | lr:0.000000\n",
            "Epoch[9651/10000] | loss train:1.535160, test:0.142061 | lr:0.000000\n",
            "Epoch[9652/10000] | loss train:0.915726, test:0.262459 | lr:0.000000\n",
            "Epoch[9653/10000] | loss train:1.699057, test:0.679235 | lr:0.000000\n",
            "Epoch[9654/10000] | loss train:1.022107, test:0.263129 | lr:0.000000\n",
            "Epoch[9655/10000] | loss train:1.448740, test:0.827402 | lr:0.000000\n",
            "Epoch[9656/10000] | loss train:0.791441, test:0.345297 | lr:0.000000\n",
            "Epoch[9657/10000] | loss train:0.864986, test:0.142904 | lr:0.000000\n",
            "Epoch[9658/10000] | loss train:1.250193, test:1.199359 | lr:0.000000\n",
            "Epoch[9659/10000] | loss train:1.979677, test:0.331195 | lr:0.000000\n",
            "Epoch[9660/10000] | loss train:1.326883, test:0.166418 | lr:0.000000\n",
            "Epoch[9661/10000] | loss train:2.979516, test:0.276036 | lr:0.000000\n",
            "Epoch[9662/10000] | loss train:1.861452, test:0.915280 | lr:0.000000\n",
            "Epoch[9663/10000] | loss train:1.043876, test:0.166418 | lr:0.000000\n",
            "Epoch[9664/10000] | loss train:1.863980, test:0.458761 | lr:0.000000\n",
            "Epoch[9665/10000] | loss train:1.569933, test:1.483633 | lr:0.000000\n",
            "Epoch[9666/10000] | loss train:1.177384, test:0.600527 | lr:0.000000\n",
            "Epoch[9667/10000] | loss train:1.008593, test:0.058851 | lr:0.000000\n",
            "Epoch[9668/10000] | loss train:1.362836, test:1.115442 | lr:0.000000\n",
            "Epoch[9669/10000] | loss train:1.297467, test:0.746733 | lr:0.000000\n",
            "Epoch[9670/10000] | loss train:0.762157, test:0.583884 | lr:0.000000\n",
            "Epoch[9671/10000] | loss train:1.321142, test:0.434623 | lr:0.000000\n",
            "Epoch[9672/10000] | loss train:1.399280, test:0.584991 | lr:0.000000\n",
            "Epoch[9673/10000] | loss train:1.697427, test:1.332632 | lr:0.000000\n",
            "Epoch[9674/10000] | loss train:1.315380, test:1.242697 | lr:0.000000\n",
            "Epoch[9675/10000] | loss train:1.320330, test:0.273292 | lr:0.000000\n",
            "Epoch[9676/10000] | loss train:2.007515, test:1.278899 | lr:0.000000\n",
            "Epoch[9677/10000] | loss train:1.047354, test:0.342273 | lr:0.000000\n",
            "Epoch[9678/10000] | loss train:1.157987, test:0.115165 | lr:0.000000\n",
            "Epoch[9679/10000] | loss train:0.972373, test:1.657342 | lr:0.000000\n",
            "Epoch[9680/10000] | loss train:1.018064, test:0.879669 | lr:0.000000\n",
            "Epoch[9681/10000] | loss train:0.829888, test:0.303881 | lr:0.000000\n",
            "Epoch[9682/10000] | loss train:2.257246, test:0.247839 | lr:0.000000\n",
            "Epoch[9683/10000] | loss train:1.472472, test:0.571317 | lr:0.000000\n",
            "Epoch[9684/10000] | loss train:1.317494, test:0.203654 | lr:0.000000\n",
            "Epoch[9685/10000] | loss train:1.005982, test:0.138189 | lr:0.000000\n",
            "Epoch[9686/10000] | loss train:1.003621, test:1.368726 | lr:0.000000\n",
            "Epoch[9687/10000] | loss train:1.562059, test:0.854393 | lr:0.000000\n",
            "Epoch[9688/10000] | loss train:1.121887, test:0.217234 | lr:0.000000\n",
            "Epoch[9689/10000] | loss train:0.877940, test:1.035969 | lr:0.000000\n",
            "Epoch[9690/10000] | loss train:0.878187, test:0.168925 | lr:0.000000\n",
            "Epoch[9691/10000] | loss train:1.052519, test:0.603300 | lr:0.000000\n",
            "Epoch[9692/10000] | loss train:0.711814, test:0.247486 | lr:0.000000\n",
            "Epoch[9693/10000] | loss train:1.319196, test:0.138469 | lr:0.000000\n",
            "Epoch[9694/10000] | loss train:1.202949, test:1.164767 | lr:0.000000\n",
            "Epoch[9695/10000] | loss train:1.508778, test:1.164737 | lr:0.000000\n",
            "Epoch[9696/10000] | loss train:1.214937, test:0.193351 | lr:0.000000\n",
            "Epoch[9697/10000] | loss train:1.889074, test:1.229952 | lr:0.000000\n",
            "Epoch[9698/10000] | loss train:1.394517, test:0.335289 | lr:0.000000\n",
            "Epoch[9699/10000] | loss train:1.196085, test:0.548576 | lr:0.000000\n",
            "Epoch[9700/10000] | loss train:0.734576, test:1.235868 | lr:0.000000\n",
            "Epoch[9701/10000] | loss train:1.983626, test:0.297545 | lr:0.000000\n",
            "Epoch[9702/10000] | loss train:1.562411, test:1.782917 | lr:0.000000\n",
            "Epoch[9703/10000] | loss train:1.465448, test:0.495329 | lr:0.000000\n",
            "Epoch[9704/10000] | loss train:1.113513, test:1.887375 | lr:0.000000\n",
            "Epoch[9705/10000] | loss train:1.405795, test:0.821132 | lr:0.000000\n",
            "Epoch[9706/10000] | loss train:0.847190, test:0.194236 | lr:0.000000\n",
            "Epoch[9707/10000] | loss train:1.466058, test:0.289912 | lr:0.000000\n",
            "Epoch[9708/10000] | loss train:0.987138, test:0.875844 | lr:0.000000\n",
            "Epoch[9709/10000] | loss train:0.707905, test:0.587905 | lr:0.000000\n",
            "Epoch[9710/10000] | loss train:1.415088, test:0.254109 | lr:0.000000\n",
            "Epoch[9711/10000] | loss train:0.840837, test:0.147134 | lr:0.000000\n",
            "Epoch[9712/10000] | loss train:1.063535, test:0.271195 | lr:0.000000\n",
            "Epoch[9713/10000] | loss train:1.576205, test:0.232946 | lr:0.000000\n",
            "Epoch[9714/10000] | loss train:1.090644, test:0.657987 | lr:0.000000\n",
            "Epoch[9715/10000] | loss train:2.348353, test:0.459539 | lr:0.000000\n",
            "Epoch[9716/10000] | loss train:1.374592, test:1.842382 | lr:0.000000\n",
            "Epoch[9717/10000] | loss train:1.385844, test:0.321207 | lr:0.000000\n",
            "Epoch[9718/10000] | loss train:0.931846, test:1.245369 | lr:0.000000\n",
            "Epoch[9719/10000] | loss train:0.929067, test:0.614125 | lr:0.000000\n",
            "Epoch[9720/10000] | loss train:2.267935, test:0.147842 | lr:0.000000\n",
            "Epoch[9721/10000] | loss train:1.936090, test:0.410455 | lr:0.000000\n",
            "Epoch[9722/10000] | loss train:1.542862, test:0.262467 | lr:0.000000\n",
            "Epoch[9723/10000] | loss train:0.674968, test:0.538575 | lr:0.000000\n",
            "Epoch[9724/10000] | loss train:1.279676, test:0.359838 | lr:0.000000\n",
            "Epoch[9725/10000] | loss train:1.214043, test:0.053951 | lr:0.000000\n",
            "Epoch[9726/10000] | loss train:1.157478, test:0.400088 | lr:0.000000\n",
            "Epoch[9727/10000] | loss train:1.599318, test:0.168035 | lr:0.000000\n",
            "Epoch[9728/10000] | loss train:1.214012, test:0.628051 | lr:0.000000\n",
            "Epoch[9729/10000] | loss train:0.867853, test:1.177527 | lr:0.000000\n",
            "Epoch[9730/10000] | loss train:0.965991, test:0.294847 | lr:0.000000\n",
            "Epoch[9731/10000] | loss train:0.908774, test:0.472628 | lr:0.000000\n",
            "Epoch[9732/10000] | loss train:1.837866, test:1.194800 | lr:0.000000\n",
            "Epoch[9733/10000] | loss train:1.018367, test:0.425581 | lr:0.000000\n",
            "Epoch[9734/10000] | loss train:3.548351, test:0.500408 | lr:0.000000\n",
            "Epoch[9735/10000] | loss train:0.767539, test:1.944296 | lr:0.000000\n",
            "Epoch[9736/10000] | loss train:1.297106, test:0.521806 | lr:0.000000\n",
            "Epoch[9737/10000] | loss train:0.740544, test:0.553227 | lr:0.000000\n",
            "Epoch[9738/10000] | loss train:0.688195, test:0.434769 | lr:0.000000\n",
            "Epoch[9739/10000] | loss train:1.001757, test:0.367920 | lr:0.000000\n",
            "Epoch[9740/10000] | loss train:0.951733, test:0.552872 | lr:0.000000\n",
            "Epoch[9741/10000] | loss train:0.762984, test:0.241341 | lr:0.000000\n",
            "Epoch[9742/10000] | loss train:2.226498, test:0.754444 | lr:0.000000\n",
            "Epoch[9743/10000] | loss train:0.764499, test:0.471162 | lr:0.000000\n",
            "Epoch[9744/10000] | loss train:1.054238, test:0.338775 | lr:0.000000\n",
            "Epoch[9745/10000] | loss train:0.696903, test:1.035256 | lr:0.000000\n",
            "Epoch[9746/10000] | loss train:2.039191, test:0.577049 | lr:0.000000\n",
            "Epoch[9747/10000] | loss train:0.687694, test:0.562861 | lr:0.000000\n",
            "Epoch[9748/10000] | loss train:1.062888, test:0.221496 | lr:0.000000\n",
            "Epoch[9749/10000] | loss train:1.414486, test:0.182567 | lr:0.000000\n",
            "Epoch[9750/10000] | loss train:2.255098, test:0.210991 | lr:0.000000\n",
            "Epoch[9751/10000] | loss train:1.261692, test:0.679033 | lr:0.000000\n",
            "Epoch[9752/10000] | loss train:1.271504, test:1.115410 | lr:0.000000\n",
            "Epoch[9753/10000] | loss train:0.636693, test:0.741342 | lr:0.000000\n",
            "Epoch[9754/10000] | loss train:1.484641, test:1.025702 | lr:0.000000\n",
            "Epoch[9755/10000] | loss train:3.117611, test:0.392395 | lr:0.000000\n",
            "Epoch[9756/10000] | loss train:1.245324, test:1.224795 | lr:0.000000\n",
            "Epoch[9757/10000] | loss train:1.501355, test:1.792074 | lr:0.000000\n",
            "Epoch[9758/10000] | loss train:1.485194, test:1.220805 | lr:0.000000\n",
            "Epoch[9759/10000] | loss train:0.775843, test:0.735952 | lr:0.000000\n",
            "Epoch[9760/10000] | loss train:0.759904, test:0.221015 | lr:0.000000\n",
            "Epoch[9761/10000] | loss train:1.002715, test:1.271644 | lr:0.000000\n",
            "Epoch[9762/10000] | loss train:0.787284, test:0.197107 | lr:0.000000\n",
            "Epoch[9763/10000] | loss train:0.957048, test:0.058645 | lr:0.000000\n",
            "Epoch[9764/10000] | loss train:0.672926, test:0.659240 | lr:0.000000\n",
            "Epoch[9765/10000] | loss train:1.348741, test:0.570351 | lr:0.000000\n",
            "Epoch[9766/10000] | loss train:1.063736, test:1.306089 | lr:0.000000\n",
            "Epoch[9767/10000] | loss train:1.571437, test:0.221228 | lr:0.000000\n",
            "Epoch[9768/10000] | loss train:1.001851, test:0.290616 | lr:0.000000\n",
            "Epoch[9769/10000] | loss train:1.547783, test:0.638553 | lr:0.000000\n",
            "Epoch[9770/10000] | loss train:0.828964, test:0.877467 | lr:0.000000\n",
            "Epoch[9771/10000] | loss train:1.514940, test:0.369778 | lr:0.000000\n",
            "Epoch[9772/10000] | loss train:1.689571, test:0.125277 | lr:0.000000\n",
            "Epoch[9773/10000] | loss train:0.917966, test:0.188013 | lr:0.000000\n",
            "Epoch[9774/10000] | loss train:0.975197, test:0.239564 | lr:0.000000\n",
            "Epoch[9775/10000] | loss train:0.916101, test:0.798330 | lr:0.000000\n",
            "Epoch[9776/10000] | loss train:1.165593, test:0.629724 | lr:0.000000\n",
            "Epoch[9777/10000] | loss train:0.915379, test:0.652529 | lr:0.000000\n",
            "Epoch[9778/10000] | loss train:1.836361, test:0.200143 | lr:0.000000\n",
            "Epoch[9779/10000] | loss train:1.189194, test:0.650293 | lr:0.000000\n",
            "Epoch[9780/10000] | loss train:1.276212, test:0.389434 | lr:0.000000\n",
            "Epoch[9781/10000] | loss train:0.908544, test:0.106239 | lr:0.000000\n",
            "Epoch[9782/10000] | loss train:1.215832, test:0.340456 | lr:0.000000\n",
            "Epoch[9783/10000] | loss train:2.988258, test:0.496263 | lr:0.000000\n",
            "Epoch[9784/10000] | loss train:1.632836, test:1.257753 | lr:0.000000\n",
            "Epoch[9785/10000] | loss train:1.248116, test:0.317083 | lr:0.000000\n",
            "Epoch[9786/10000] | loss train:1.205168, test:1.125209 | lr:0.000000\n",
            "Epoch[9787/10000] | loss train:1.876496, test:0.474804 | lr:0.000000\n",
            "Epoch[9788/10000] | loss train:3.274862, test:0.349610 | lr:0.000000\n",
            "Epoch[9789/10000] | loss train:0.913606, test:1.443350 | lr:0.000000\n",
            "Epoch[9790/10000] | loss train:1.512990, test:0.340561 | lr:0.000000\n",
            "Epoch[9791/10000] | loss train:1.466087, test:1.326340 | lr:0.000000\n",
            "Epoch[9792/10000] | loss train:0.592911, test:0.373737 | lr:0.000000\n",
            "Epoch[9793/10000] | loss train:1.137312, test:1.777372 | lr:0.000000\n",
            "Epoch[9794/10000] | loss train:0.624465, test:0.578841 | lr:0.000000\n",
            "Epoch[9795/10000] | loss train:2.229538, test:1.249771 | lr:0.000000\n",
            "Epoch[9796/10000] | loss train:1.247030, test:1.704084 | lr:0.000000\n",
            "Epoch[9797/10000] | loss train:0.836231, test:0.432680 | lr:0.000000\n",
            "Epoch[9798/10000] | loss train:1.733131, test:0.818963 | lr:0.000000\n",
            "Epoch[9799/10000] | loss train:0.734916, test:0.183544 | lr:0.000000\n",
            "Epoch[9800/10000] | loss train:1.176328, test:1.907488 | lr:0.000000\n",
            "Epoch[9801/10000] | loss train:1.198628, test:0.643000 | lr:0.000000\n",
            "Epoch[9802/10000] | loss train:1.654896, test:1.749078 | lr:0.000000\n",
            "Epoch[9803/10000] | loss train:0.816593, test:0.254126 | lr:0.000000\n",
            "Epoch[9804/10000] | loss train:0.808248, test:0.425592 | lr:0.000000\n",
            "Epoch[9805/10000] | loss train:0.626488, test:1.736024 | lr:0.000000\n",
            "Epoch[9806/10000] | loss train:1.095448, test:0.372928 | lr:0.000000\n",
            "Epoch[9807/10000] | loss train:1.443818, test:2.472985 | lr:0.000000\n",
            "Epoch[9808/10000] | loss train:1.929392, test:1.645172 | lr:0.000000\n",
            "Epoch[9809/10000] | loss train:0.988092, test:0.722473 | lr:0.000000\n",
            "Epoch[9810/10000] | loss train:1.149257, test:0.561162 | lr:0.000000\n",
            "Epoch[9811/10000] | loss train:1.227883, test:1.453690 | lr:0.000000\n",
            "Epoch[9812/10000] | loss train:1.082620, test:0.123106 | lr:0.000000\n",
            "Epoch[9813/10000] | loss train:1.584778, test:0.630966 | lr:0.000000\n",
            "Epoch[9814/10000] | loss train:0.824251, test:0.652250 | lr:0.000000\n",
            "Epoch[9815/10000] | loss train:1.151658, test:0.598445 | lr:0.000000\n",
            "Epoch[9816/10000] | loss train:1.326046, test:0.550694 | lr:0.000000\n",
            "Epoch[9817/10000] | loss train:1.421300, test:1.408987 | lr:0.000000\n",
            "Epoch[9818/10000] | loss train:0.607339, test:0.123294 | lr:0.000000\n",
            "Epoch[9819/10000] | loss train:1.986808, test:1.042913 | lr:0.000000\n",
            "Epoch[9820/10000] | loss train:0.920710, test:0.655407 | lr:0.000000\n",
            "Epoch[9821/10000] | loss train:1.480115, test:0.324777 | lr:0.000000\n",
            "Epoch[9822/10000] | loss train:0.997134, test:0.468512 | lr:0.000000\n",
            "Epoch[9823/10000] | loss train:1.464807, test:0.472841 | lr:0.000000\n",
            "Epoch[9824/10000] | loss train:1.140881, test:0.441197 | lr:0.000000\n",
            "Epoch[9825/10000] | loss train:1.934675, test:0.110992 | lr:0.000000\n",
            "Epoch[9826/10000] | loss train:1.516186, test:1.094052 | lr:0.000000\n",
            "Epoch[9827/10000] | loss train:0.819300, test:0.322586 | lr:0.000000\n",
            "Epoch[9828/10000] | loss train:1.722022, test:0.120721 | lr:0.000000\n",
            "Epoch[9829/10000] | loss train:1.994395, test:0.192630 | lr:0.000000\n",
            "Epoch[9830/10000] | loss train:1.520492, test:0.197649 | lr:0.000000\n",
            "Epoch[9831/10000] | loss train:1.225146, test:0.379251 | lr:0.000000\n",
            "Epoch[9832/10000] | loss train:0.761702, test:0.713395 | lr:0.000000\n",
            "Epoch[9833/10000] | loss train:1.551751, test:1.928528 | lr:0.000000\n",
            "Epoch[9834/10000] | loss train:0.784868, test:0.584694 | lr:0.000000\n",
            "Epoch[9835/10000] | loss train:1.177183, test:0.534765 | lr:0.000000\n",
            "Epoch[9836/10000] | loss train:1.356472, test:1.005476 | lr:0.000000\n",
            "Epoch[9837/10000] | loss train:1.683660, test:0.697673 | lr:0.000000\n",
            "Epoch[9838/10000] | loss train:2.003548, test:0.382508 | lr:0.000000\n",
            "Epoch[9839/10000] | loss train:0.798013, test:0.252138 | lr:0.000000\n",
            "Epoch[9840/10000] | loss train:1.178759, test:0.706987 | lr:0.000000\n",
            "Epoch[9841/10000] | loss train:1.243862, test:1.178472 | lr:0.000000\n",
            "Epoch[9842/10000] | loss train:1.754747, test:0.394471 | lr:0.000000\n",
            "Epoch[9843/10000] | loss train:1.556170, test:0.640983 | lr:0.000000\n",
            "Epoch[9844/10000] | loss train:1.400126, test:0.740975 | lr:0.000000\n",
            "Epoch[9845/10000] | loss train:1.567330, test:0.122359 | lr:0.000000\n",
            "Epoch[9846/10000] | loss train:0.700777, test:1.307113 | lr:0.000000\n",
            "Epoch[9847/10000] | loss train:1.231036, test:0.982900 | lr:0.000000\n",
            "Epoch[9848/10000] | loss train:2.045647, test:0.454991 | lr:0.000000\n",
            "Epoch[9849/10000] | loss train:2.247772, test:0.187759 | lr:0.000000\n",
            "Epoch[9850/10000] | loss train:0.849614, test:0.232812 | lr:0.000000\n",
            "Epoch[9851/10000] | loss train:2.253418, test:0.204190 | lr:0.000000\n",
            "Epoch[9852/10000] | loss train:1.187287, test:0.208945 | lr:0.000000\n",
            "Epoch[9853/10000] | loss train:1.026739, test:0.716878 | lr:0.000000\n",
            "Epoch[9854/10000] | loss train:0.775669, test:0.667600 | lr:0.000000\n",
            "Epoch[9855/10000] | loss train:1.611611, test:0.519653 | lr:0.000000\n",
            "Epoch[9856/10000] | loss train:0.871037, test:0.250728 | lr:0.000000\n",
            "Epoch[9857/10000] | loss train:0.712070, test:0.274608 | lr:0.000000\n",
            "Epoch[9858/10000] | loss train:1.385184, test:0.175131 | lr:0.000000\n",
            "Epoch[9859/10000] | loss train:1.221674, test:0.827142 | lr:0.000000\n",
            "Epoch[9860/10000] | loss train:1.691506, test:0.337863 | lr:0.000000\n",
            "Epoch[9861/10000] | loss train:0.940005, test:1.066932 | lr:0.000000\n",
            "Epoch[9862/10000] | loss train:1.197382, test:0.968274 | lr:0.000000\n",
            "Epoch[9863/10000] | loss train:1.596611, test:0.884583 | lr:0.000000\n",
            "Epoch[9864/10000] | loss train:0.709031, test:0.636091 | lr:0.000000\n",
            "Epoch[9865/10000] | loss train:1.368596, test:1.053203 | lr:0.000000\n",
            "Epoch[9866/10000] | loss train:1.061790, test:1.417451 | lr:0.000000\n",
            "Epoch[9867/10000] | loss train:2.234297, test:0.793736 | lr:0.000000\n",
            "Epoch[9868/10000] | loss train:1.207196, test:1.656669 | lr:0.000000\n",
            "Epoch[9869/10000] | loss train:1.643614, test:0.494098 | lr:0.000000\n",
            "Epoch[9870/10000] | loss train:1.005709, test:1.507304 | lr:0.000000\n",
            "Epoch[9871/10000] | loss train:1.027795, test:1.592573 | lr:0.000000\n",
            "Epoch[9872/10000] | loss train:1.826479, test:0.935269 | lr:0.000000\n",
            "Epoch[9873/10000] | loss train:1.159449, test:1.273819 | lr:0.000000\n",
            "Epoch[9874/10000] | loss train:1.476883, test:0.261422 | lr:0.000000\n",
            "Epoch[9875/10000] | loss train:0.902736, test:0.295928 | lr:0.000000\n",
            "Epoch[9876/10000] | loss train:0.747523, test:0.170620 | lr:0.000000\n",
            "Epoch[9877/10000] | loss train:1.203795, test:0.589009 | lr:0.000000\n",
            "Epoch[9878/10000] | loss train:0.877211, test:0.230385 | lr:0.000000\n",
            "Epoch[9879/10000] | loss train:0.855351, test:0.204526 | lr:0.000000\n",
            "Epoch[9880/10000] | loss train:1.320985, test:0.702648 | lr:0.000000\n",
            "Epoch[9881/10000] | loss train:1.083382, test:1.211794 | lr:0.000000\n",
            "Epoch[9882/10000] | loss train:1.268122, test:0.608308 | lr:0.000000\n",
            "Epoch[9883/10000] | loss train:1.223662, test:0.426164 | lr:0.000000\n",
            "Epoch[9884/10000] | loss train:1.568167, test:0.143029 | lr:0.000000\n",
            "Epoch[9885/10000] | loss train:1.974254, test:0.408328 | lr:0.000000\n",
            "Epoch[9886/10000] | loss train:1.636575, test:1.507875 | lr:0.000000\n",
            "Epoch[9887/10000] | loss train:0.688674, test:0.974955 | lr:0.000000\n",
            "Epoch[9888/10000] | loss train:2.084956, test:0.725123 | lr:0.000000\n",
            "Epoch[9889/10000] | loss train:1.798852, test:0.715775 | lr:0.000000\n",
            "Epoch[9890/10000] | loss train:1.641408, test:1.299822 | lr:0.000000\n",
            "Epoch[9891/10000] | loss train:0.878033, test:0.398240 | lr:0.000000\n",
            "Epoch[9892/10000] | loss train:0.705536, test:0.491003 | lr:0.000000\n",
            "Epoch[9893/10000] | loss train:1.557148, test:0.456022 | lr:0.000000\n",
            "Epoch[9894/10000] | loss train:1.124740, test:0.421956 | lr:0.000000\n",
            "Epoch[9895/10000] | loss train:0.856319, test:0.969051 | lr:0.000000\n",
            "Epoch[9896/10000] | loss train:1.218197, test:0.606203 | lr:0.000000\n",
            "Epoch[9897/10000] | loss train:1.037454, test:1.334783 | lr:0.000000\n",
            "Epoch[9898/10000] | loss train:0.860644, test:0.178956 | lr:0.000000\n",
            "Epoch[9899/10000] | loss train:0.859946, test:0.727350 | lr:0.000000\n",
            "Epoch[9900/10000] | loss train:1.175489, test:0.339743 | lr:0.000000\n",
            "Epoch[9901/10000] | loss train:0.763137, test:0.155594 | lr:0.000000\n",
            "Epoch[9902/10000] | loss train:3.348104, test:0.264478 | lr:0.000000\n",
            "Epoch[9903/10000] | loss train:1.297200, test:0.365023 | lr:0.000000\n",
            "Epoch[9904/10000] | loss train:1.377894, test:1.077241 | lr:0.000000\n",
            "Epoch[9905/10000] | loss train:1.113812, test:1.868428 | lr:0.000000\n",
            "Epoch[9906/10000] | loss train:1.246834, test:0.437080 | lr:0.000000\n",
            "Epoch[9907/10000] | loss train:1.389922, test:0.911606 | lr:0.000000\n",
            "Epoch[9908/10000] | loss train:1.830556, test:1.053912 | lr:0.000000\n",
            "Epoch[9909/10000] | loss train:1.051994, test:0.189599 | lr:0.000000\n",
            "Epoch[9910/10000] | loss train:0.794601, test:1.338419 | lr:0.000000\n",
            "Epoch[9911/10000] | loss train:1.194397, test:0.885597 | lr:0.000000\n",
            "Epoch[9912/10000] | loss train:1.621525, test:0.293461 | lr:0.000000\n",
            "Epoch[9913/10000] | loss train:1.807682, test:0.349521 | lr:0.000000\n",
            "Epoch[9914/10000] | loss train:1.269331, test:0.378518 | lr:0.000000\n",
            "Epoch[9915/10000] | loss train:1.056208, test:0.654249 | lr:0.000000\n",
            "Epoch[9916/10000] | loss train:0.778957, test:0.334568 | lr:0.000000\n",
            "Epoch[9917/10000] | loss train:1.378007, test:1.307202 | lr:0.000000\n",
            "Epoch[9918/10000] | loss train:2.129755, test:1.027713 | lr:0.000000\n",
            "Epoch[9919/10000] | loss train:1.547888, test:0.187804 | lr:0.000000\n",
            "Epoch[9920/10000] | loss train:1.060572, test:0.300588 | lr:0.000000\n",
            "Epoch[9921/10000] | loss train:1.186414, test:0.824430 | lr:0.000000\n",
            "Epoch[9922/10000] | loss train:1.185325, test:0.305147 | lr:0.000000\n",
            "Epoch[9923/10000] | loss train:1.089385, test:1.356337 | lr:0.000000\n",
            "Epoch[9924/10000] | loss train:1.318541, test:1.346044 | lr:0.000000\n",
            "Epoch[9925/10000] | loss train:1.050816, test:0.523321 | lr:0.000000\n",
            "Epoch[9926/10000] | loss train:1.782131, test:1.132115 | lr:0.000000\n",
            "Epoch[9927/10000] | loss train:1.725642, test:0.577308 | lr:0.000000\n",
            "Epoch[9928/10000] | loss train:2.223850, test:0.359821 | lr:0.000000\n",
            "Epoch[9929/10000] | loss train:1.326756, test:0.428521 | lr:0.000000\n",
            "Epoch[9930/10000] | loss train:0.987476, test:0.225244 | lr:0.000000\n",
            "Epoch[9931/10000] | loss train:1.081097, test:0.169343 | lr:0.000000\n",
            "Epoch[9932/10000] | loss train:2.292941, test:0.172042 | lr:0.000000\n",
            "Epoch[9933/10000] | loss train:1.163005, test:0.375933 | lr:0.000000\n",
            "Epoch[9934/10000] | loss train:0.980951, test:0.551501 | lr:0.000000\n",
            "Epoch[9935/10000] | loss train:0.912820, test:0.364292 | lr:0.000000\n",
            "Epoch[9936/10000] | loss train:0.695516, test:0.875262 | lr:0.000000\n",
            "Epoch[9937/10000] | loss train:1.926816, test:0.207187 | lr:0.000000\n",
            "Epoch[9938/10000] | loss train:1.088448, test:0.410705 | lr:0.000000\n",
            "Epoch[9939/10000] | loss train:1.129482, test:0.663641 | lr:0.000000\n",
            "Epoch[9940/10000] | loss train:0.903643, test:0.286840 | lr:0.000000\n",
            "Epoch[9941/10000] | loss train:1.270280, test:1.091908 | lr:0.000000\n",
            "Epoch[9942/10000] | loss train:1.156029, test:0.864089 | lr:0.000000\n",
            "Epoch[9943/10000] | loss train:2.327985, test:1.060121 | lr:0.000000\n",
            "Epoch[9944/10000] | loss train:2.337343, test:0.260052 | lr:0.000000\n",
            "Epoch[9945/10000] | loss train:0.753596, test:0.783969 | lr:0.000000\n",
            "Epoch[9946/10000] | loss train:0.815257, test:1.827102 | lr:0.000000\n",
            "Epoch[9947/10000] | loss train:0.830695, test:0.566400 | lr:0.000000\n",
            "Epoch[9948/10000] | loss train:1.320415, test:1.266985 | lr:0.000000\n",
            "Epoch[9949/10000] | loss train:0.883479, test:0.321769 | lr:0.000000\n",
            "Epoch[9950/10000] | loss train:0.971592, test:0.708144 | lr:0.000000\n",
            "Epoch[9951/10000] | loss train:1.175942, test:0.280374 | lr:0.000000\n",
            "Epoch[9952/10000] | loss train:1.684038, test:0.616639 | lr:0.000000\n",
            "Epoch[9953/10000] | loss train:1.091715, test:0.515846 | lr:0.000000\n",
            "Epoch[9954/10000] | loss train:1.765759, test:0.291894 | lr:0.000000\n",
            "Epoch[9955/10000] | loss train:2.295154, test:1.300020 | lr:0.000000\n",
            "Epoch[9956/10000] | loss train:1.837969, test:0.537089 | lr:0.000000\n",
            "Epoch[9957/10000] | loss train:1.083991, test:1.022673 | lr:0.000000\n",
            "Epoch[9958/10000] | loss train:1.288285, test:1.079486 | lr:0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we re-initialize dataloader so the data doesn't shuffled, so we can plot the values by date\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# predict on the training data, to see how well the model managed to learn and memorize\n",
        "\n",
        "predicted_train = np.array([])\n",
        "\n",
        "for idx, (x, y) in enumerate(train_dataloader):\n",
        "    x = x.to(config[\"training\"][\"device\"])\n",
        "    out = model(x)\n",
        "    out = out.cpu().detach().numpy()\n",
        "    predicted_train = np.concatenate((predicted_train, out))\n",
        "\n",
        "# predict on the validation data, to see how the model does\n",
        "\n",
        "predicted_val = np.array([])\n",
        "\n",
        "for idx, (x, y) in enumerate(val_dataloader):\n",
        "    x = x.to(config[\"training\"][\"device\"])\n",
        "    out = model(x)\n",
        "    out = out.cpu().detach().numpy()\n",
        "    predicted_val = np.concatenate((predicted_val, out))\n",
        "\n",
        "# prepare data for plotting\n",
        "\n",
        "to_plot_data_y_train_pred = np.zeros(num_data_points)\n",
        "to_plot_data_y_val_pred = np.zeros(num_data_points)\n",
        "\n",
        "to_plot_data_y_train_pred[config[\"data\"][\"window_size\"]:split_index+config[\"data\"][\"window_size\"]] = scaler.inverse_transform(predicted_train)\n",
        "to_plot_data_y_val_pred[split_index+config[\"data\"][\"window_size\"]:] = scaler.inverse_transform(predicted_val)\n",
        "\n",
        "to_plot_data_y_train_pred = np.where(to_plot_data_y_train_pred == 0, None, to_plot_data_y_train_pred)\n",
        "to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
        "\n",
        "# plots\n",
        "\n",
        "fig = figure(figsize=(25, 5), dpi=80)\n",
        "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "plt.plot(data_date, data_close_price, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
        "plt.plot(data_date, to_plot_data_y_train_pred, label=\"Predicted prices (train)\", color=config[\"plots\"][\"color_pred_train\"])\n",
        "plt.plot(data_date, to_plot_data_y_val_pred, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
        "plt.title(\"Compare predicted prices to actual prices\")\n",
        "xticks = [data_date[i] if ((i%config[\"plots\"][\"xticks_interval\"]==0 and (num_data_points-i) > config[\"plots\"][\"xticks_interval\"]) or i==num_data_points-1) else None for i in range(num_data_points)] # make x ticks nice\n",
        "x = np.arange(0,len(xticks))\n",
        "plt.xticks(x, xticks, rotation='vertical')\n",
        "plt.grid(True, which='major', axis='y', linestyle='--')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "MXYNMOP6R6Nt",
        "outputId": "d3e673bd-1dc3-4300-8615-63981cb0ccb7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a9985953b408>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# here we re-initialize dataloader so the data doesn't shuffled, so we can plot the values by date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data for plotting the zoomed in view of the predicted prices (on validation set) vs. actual prices\n",
        "\n",
        "to_plot_data_y_val_subset = scaler.inverse_transform(data_y_val)\n",
        "to_plot_predicted_val = scaler.inverse_transform(predicted_val)\n",
        "to_plot_data_date = data_date[split_index+config[\"data\"][\"window_size\"]:]\n",
        "\n",
        "# plots\n",
        "\n",
        "fig = figure(figsize=(25, 5), dpi=80)\n",
        "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "plt.plot(to_plot_data_date, to_plot_data_y_val_subset, label=\"Actual prices\", color=config[\"plots\"][\"color_actual\"])\n",
        "plt.plot(to_plot_data_date, to_plot_predicted_val, label=\"Predicted prices (validation)\", color=config[\"plots\"][\"color_pred_val\"])\n",
        "plt.title(\"Zoom in to examine predicted price on validation data portion\")\n",
        "xticks = [to_plot_data_date[i] if ((i%int(config[\"plots\"][\"xticks_interval\"]/5)==0 and (len(to_plot_data_date)-i) > config[\"plots\"][\"xticks_interval\"]/6) or i==len(to_plot_data_date)-1) else None for i in range(len(to_plot_data_date))] # make x ticks nice\n",
        "xs = np.arange(0,len(xticks))\n",
        "plt.xticks(xs, xticks, rotation='vertical')\n",
        "plt.grid(True, which='major', axis='y', linestyle='--')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "07X7h4XXR_pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the closing price of the next trading day\n",
        "\n",
        "model.eval()\n",
        "\n",
        "x = torch.tensor(data_x_unseen).float().to(config[\"training\"][\"device\"]).unsqueeze(0).unsqueeze(2) # this is the data type and shape required, [batch, sequence, feature]\n",
        "prediction = model(x)\n",
        "prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "# prepare plots\n",
        "\n",
        "plot_range = 10\n",
        "to_plot_data_y_val = np.zeros(plot_range)\n",
        "to_plot_data_y_val_pred = np.zeros(plot_range)\n",
        "to_plot_data_y_test_pred = np.zeros(plot_range)\n",
        "\n",
        "to_plot_data_y_val[:plot_range-1] = scaler.inverse_transform(data_y_val)[-plot_range+1:]\n",
        "to_plot_data_y_val_pred[:plot_range-1] = scaler.inverse_transform(predicted_val)[-plot_range+1:]\n",
        "\n",
        "to_plot_data_y_test_pred[plot_range-1] = scaler.inverse_transform(prediction)\n",
        "\n",
        "to_plot_data_y_val = np.where(to_plot_data_y_val == 0, None, to_plot_data_y_val)\n",
        "to_plot_data_y_val_pred = np.where(to_plot_data_y_val_pred == 0, None, to_plot_data_y_val_pred)\n",
        "to_plot_data_y_test_pred = np.where(to_plot_data_y_test_pred == 0, None, to_plot_data_y_test_pred)\n",
        "\n",
        "# plot\n",
        "\n",
        "plot_date_test = data_date[-plot_range+1:]\n",
        "plot_date_test.append(\"tomorrow\")\n",
        "\n",
        "fig = figure(figsize=(25, 5), dpi=80)\n",
        "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
        "plt.plot(plot_date_test, to_plot_data_y_val, label=\"Actual prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_actual\"])\n",
        "plt.plot(plot_date_test, to_plot_data_y_val_pred, label=\"Past predicted prices\", marker=\".\", markersize=10, color=config[\"plots\"][\"color_pred_val\"])\n",
        "plt.plot(plot_date_test, to_plot_data_y_test_pred, label=\"Predicted price for next day\", marker=\".\", markersize=20, color=config[\"plots\"][\"color_pred_test\"])\n",
        "plt.title(\"Predicted close price of the next trading day\")\n",
        "plt.grid(True, which='major', axis='y', linestyle='--')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Predicted close price of the next trading day:\", round(to_plot_data_y_test_pred[plot_range-1], 2))"
      ],
      "metadata": {
        "id": "eTNhLE13SIMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}